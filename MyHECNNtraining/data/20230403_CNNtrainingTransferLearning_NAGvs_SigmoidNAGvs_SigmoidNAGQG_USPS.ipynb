{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q1DyAs0eC_84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3637af64-4c86-413c-addc-4c9e4234949d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.bz2 to data/usps.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6579383/6579383 [00:00<00:00, 16001371.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2 to data/usps.t.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1831726/1831726 [00:00<00:00, 5407977.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RegNet_X_400MF_Weights.IMAGENET1K_V1`. You can also use `weights=RegNet_X_400MF_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/regnet_x_400mf-adf1edd5.pth\" to /root/.cache/torch/hub/checkpoints/regnet_x_400mf-adf1edd5.pth\n",
            "100%|██████████| 21.3M/21.3M [00:00<00:00, 26.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegNet(\n",
            "  (stem): SimpleStemIN(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (trunk_output): Sequential(\n",
            "    (block1): AnyStage(\n",
            "      (block1-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block2): AnyStage(\n",
            "      (block2-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block2-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block3): AnyStage(\n",
            "      (block3-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-3): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-4): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-5): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-6): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block4): AnyStage(\n",
            "      (block4-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 400, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-3): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-4): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-5): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-6): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-7): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-8): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-9): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-10): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-11): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential()\n",
            ")\n",
            "Sequential()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 512, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 1024, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 1536, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 2048, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 2560, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 3072, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 3584, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 4096, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 4608, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 5120, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 5632, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 6144, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 6656, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 7168, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([123, 400])\n",
            "Shape of y: torch.Size([123]) torch.int64\n",
            "Shape of model(X): torch.Size([123, 400]) torch.float32\n",
            "Shape of y: torch.Size([123, 1]) torch.int64\n",
            "Shape of train_dataset: 7291, 401\n",
            "train_dataset :7291,\t401\n",
            "<class 'list'>\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 512, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 1024, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 1536, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([471, 400])\n",
            "Shape of y: torch.Size([471]) torch.int64\n",
            "Shape of model(X): torch.Size([471, 400]) torch.float32\n",
            "Shape of y: torch.Size([471, 1]) torch.int64\n",
            "Shape of test_dataset: 2007, 401\n",
            "test_dataset :2007,\t401\n",
            "<class 'list'>\n",
            " Testing Accuray at  1 iterations is 0.178873941206 with loss: 0.223837503155\n",
            " Testing Accuray at  2 iterations is 0.202790234180 with loss: 3.158808510371\n",
            " Testing Accuray at  3 iterations is 0.308918784255 with loss: 3.538580314005\n",
            " Testing Accuray at  4 iterations is 0.082710513204 with loss: 3.474838615032\n",
            " Testing Accuray at  5 iterations is 0.084703537618 with loss: 3.340077601979\n",
            " Testing Accuray at  6 iterations is 0.150473343298 with loss: 2.875393191075\n",
            " Testing Accuray at  7 iterations is 0.163926258097 with loss: 2.802544000047\n",
            " Testing Accuray at  8 iterations is 0.334828101644 with loss: 2.553450311168\n",
            " Testing Accuray at  9 iterations is 0.353761833582 with loss: 3.159626952511\n",
            " Testing Accuray at 10 iterations is 0.376681614350 with loss: 3.537496444943\n",
            " Testing Accuray at 11 iterations is 0.381165919283 with loss: 3.221002775867\n",
            " Testing Accuray at 12 iterations is 0.430493273543 with loss: 2.683341177229\n",
            " Testing Accuray at 13 iterations is 0.416043846537 with loss: 2.096977549315\n",
            " Testing Accuray at 14 iterations is 0.472346786248 with loss: 1.349751410431\n",
            " Testing Accuray at 15 iterations is 0.307922272048 with loss: 1.541344600257\n",
            " Testing Accuray at 16 iterations is 0.272047832586 with loss: 1.102245836380\n",
            " Testing Accuray at 17 iterations is 0.495764823119 with loss: 0.279722408024\n",
            " Testing Accuray at 18 iterations is 0.302939711011 with loss: 0.938697067420\n",
            " Testing Accuray at 19 iterations is 0.296960637768 with loss: 1.007078258005\n",
            " Testing Accuray at 20 iterations is 0.335326357748 with loss: 0.880492874728\n",
            " Testing Accuray at 21 iterations is 0.425012456403 with loss: 0.789987261003\n",
            " Testing Accuray at 22 iterations is 0.320378674639 with loss: 0.930673418935\n",
            " Testing Accuray at 23 iterations is 0.430991529646 with loss: 0.661897484078\n",
            " Testing Accuray at 24 iterations is 0.365719980070 with loss: 0.700543910459\n",
            " Testing Accuray at 25 iterations is 0.624314897857 with loss: 0.389117883050\n",
            " Testing Accuray at 26 iterations is 0.528151469856 with loss: 0.466265639273\n",
            " Testing Accuray at 27 iterations is 0.469855505730 with loss: 0.523520399902\n",
            " Testing Accuray at 28 iterations is 0.594917787743 with loss: 0.362665070214\n",
            " Testing Accuray at 29 iterations is 0.642252117588 with loss: 0.289924717527\n",
            " Testing Accuray at 30 iterations is 0.589935226707 with loss: 0.277168892597\n",
            " Testing Accuray at 31 iterations is 0.585949177877 with loss: 0.259357712393\n",
            " Testing Accuray at 32 iterations is 0.560538116592 with loss: 0.274084667923\n",
            " Testing Accuray at 33 iterations is 0.431489785750 with loss: 0.426414235485\n",
            " Testing Accuray at 34 iterations is 0.471350274041 with loss: 0.332505788054\n",
            " Testing Accuray at 35 iterations is 0.729945191829 with loss: 0.125539779519\n",
            " Testing Accuray at 36 iterations is 0.709018435476 with loss: 0.149587166016\n",
            " Testing Accuray at 37 iterations is 0.678624813154 with loss: 0.186985570392\n",
            " Testing Accuray at 38 iterations is 0.698555057299 with loss: 0.201368695831\n",
            " Testing Accuray at 39 iterations is 0.688091679123 with loss: 0.209131103830\n",
            " Testing Accuray at 40 iterations is 0.670652715496 with loss: 0.220846153813\n",
            " Testing Accuray at 41 iterations is 0.629795714998 with loss: 0.242389760107\n",
            " Testing Accuray at 42 iterations is 0.601395117090 with loss: 0.250886417828\n",
            " Testing Accuray at 43 iterations is 0.635774788241 with loss: 0.210617114440\n",
            " Testing Accuray at 44 iterations is 0.703537618336 with loss: 0.153393690682\n",
            " Testing Accuray at 45 iterations is 0.742899850523 with loss: 0.121517418262\n",
            " Testing Accuray at 46 iterations is 0.758345789736 with loss: 0.105080793507\n",
            " Testing Accuray at 47 iterations is 0.764823119083 with loss: 0.096350113627\n",
            " Testing Accuray at 48 iterations is 0.773791728949 with loss: 0.096888303385\n",
            " Testing Accuray at 49 iterations is 0.759840558047 with loss: 0.104873100198\n",
            " Testing Accuray at 50 iterations is 0.748878923767 with loss: 0.113860333179\n",
            " Testing Accuray at 51 iterations is 0.735924265072 with loss: 0.123945984932\n",
            " Testing Accuray at 52 iterations is 0.705032386647 with loss: 0.138291973564\n",
            " Testing Accuray at 53 iterations is 0.685600398605 with loss: 0.147203117351\n",
            " Testing Accuray at 54 iterations is 0.694070752367 with loss: 0.142125341454\n",
            " Testing Accuray at 55 iterations is 0.720478325859 with loss: 0.127092518650\n",
            " Testing Accuray at 56 iterations is 0.760338814150 with loss: 0.108126038828\n",
            " Testing Accuray at 57 iterations is 0.803687095167 with loss: 0.090989510132\n",
            " Testing Accuray at 58 iterations is 0.819133034380 with loss: 0.080556425563\n",
            " Testing Accuray at 59 iterations is 0.824115595416 with loss: 0.077058427596\n",
            " Testing Accuray at 60 iterations is 0.820129546587 with loss: 0.078027024644\n",
            " Testing Accuray at 61 iterations is 0.811160936721 with loss: 0.081308263664\n",
            " Testing Accuray at 62 iterations is 0.802192326856 with loss: 0.085390830640\n",
            " Testing Accuray at 63 iterations is 0.796213253612 with loss: 0.089125731062\n",
            " Testing Accuray at 64 iterations is 0.788739412058 with loss: 0.091449944638\n",
            " Testing Accuray at 65 iterations is 0.796213253612 with loss: 0.091614694705\n",
            " Testing Accuray at 66 iterations is 0.808171400100 with loss: 0.089701064308\n",
            " Testing Accuray at 67 iterations is 0.817140009965 with loss: 0.086719393776\n",
            " Testing Accuray at 68 iterations is 0.816143497758 with loss: 0.084043730888\n",
            " Testing Accuray at 69 iterations is 0.816143497758 with loss: 0.082536907335\n",
            " Testing Accuray at 70 iterations is 0.823119083209 with loss: 0.082089334667\n",
            " Testing Accuray at 71 iterations is 0.823617339312 with loss: 0.081862005101\n",
            " Testing Accuray at 72 iterations is 0.825112107623 with loss: 0.080938754594\n",
            " Testing Accuray at 73 iterations is 0.824115595416 with loss: 0.078824972043\n",
            " Testing Accuray at 74 iterations is 0.831091180867 with loss: 0.075731690040\n",
            " Testing Accuray at 75 iterations is 0.839063278525 with loss: 0.072630890095\n",
            " Testing Accuray at 76 iterations is 0.843547583458 with loss: 0.070762251223\n",
            " Testing Accuray at 77 iterations is 0.846038863976 with loss: 0.070914971810\n",
            " Testing Accuray at 78 iterations is 0.843547583458 with loss: 0.072979475638\n",
            " Testing Accuray at 79 iterations is 0.838565022422 with loss: 0.075750745614\n",
            " Testing Accuray at 80 iterations is 0.834080717489 with loss: 0.077398404905\n",
            " Testing Accuray at 81 iterations is 0.834578973592 with loss: 0.076589325680\n",
            " Testing Accuray at 82 iterations is 0.843049327354 with loss: 0.073357447850\n",
            " Testing Accuray at 83 iterations is 0.850523168909 with loss: 0.068941631969\n",
            " Testing Accuray at 84 iterations is 0.859990034878 with loss: 0.064790697846\n",
            " Testing Accuray at 85 iterations is 0.859990034878 with loss: 0.061787505044\n",
            " Testing Accuray at 86 iterations is 0.861983059292 with loss: 0.060147723852\n",
            " Testing Accuray at 87 iterations is 0.860986547085 with loss: 0.059601620770\n",
            " Testing Accuray at 88 iterations is 0.859491778774 with loss: 0.059686788678\n",
            " Testing Accuray at 89 iterations is 0.858495266567 with loss: 0.059933618245\n",
            " Testing Accuray at 90 iterations is 0.861484803189 with loss: 0.059956444582\n",
            " Testing Accuray at 91 iterations is 0.862481315396 with loss: 0.059528712189\n",
            " Testing Accuray at 92 iterations is 0.865969108122 with loss: 0.058615686670\n",
            " Testing Accuray at 93 iterations is 0.869456900847 with loss: 0.057370324277\n",
            " Testing Accuray at 94 iterations is 0.872446437469 with loss: 0.056079183981\n",
            " Testing Accuray at 95 iterations is 0.873941205780 with loss: 0.055045125846\n",
            " Testing Accuray at 96 iterations is 0.870453413054 with loss: 0.054471462347\n",
            " Testing Accuray at 97 iterations is 0.870951669158 with loss: 0.054417533808\n",
            " Testing Accuray at 98 iterations is 0.870453413054 with loss: 0.054815106015\n",
            " Testing Accuray at 99 iterations is 0.870453413054 with loss: 0.055502204951\n",
            " Testing Accuray at 100 iterations is 0.868460388640 with loss: 0.056271992581\n",
            " Testing Accuray at 101 iterations is 0.866965620329 with loss: 0.056942002859\n",
            " Testing Accuray at 102 iterations is 0.867463876432 with loss: 0.057407524141\n",
            " Testing Accuray at 103 iterations is 0.866965620329 with loss: 0.057649922730\n",
            " Testing Accuray at 104 iterations is 0.871449925262 with loss: 0.057707108363\n",
            " Testing Accuray at 105 iterations is 0.871449925262 with loss: 0.057630910990\n",
            " Testing Accuray at 106 iterations is 0.870951669158 with loss: 0.057455609069\n",
            " Testing Accuray at 107 iterations is 0.871449925262 with loss: 0.057186621247\n",
            " Testing Accuray at 108 iterations is 0.870453413054 with loss: 0.056804234840\n",
            " Testing Accuray at 109 iterations is 0.869955156951 with loss: 0.056276070082\n",
            " Testing Accuray at 110 iterations is 0.868958644743 with loss: 0.055575504184\n",
            " Testing Accuray at 111 iterations is 0.867962132536 with loss: 0.054701589160\n",
            " Testing Accuray at 112 iterations is 0.870453413054 with loss: 0.053690322698\n",
            " Testing Accuray at 113 iterations is 0.874937717987 with loss: 0.052607167408\n",
            " Testing Accuray at 114 iterations is 0.876930742402 with loss: 0.051526411698\n",
            " Testing Accuray at 115 iterations is 0.879422022920 with loss: 0.050517207106\n",
            " Testing Accuray at 116 iterations is 0.881913303438 with loss: 0.049642509399\n",
            " Testing Accuray at 117 iterations is 0.881913303438 with loss: 0.048957291250\n",
            " Testing Accuray at 118 iterations is 0.882411559542 with loss: 0.048497543001\n",
            " Testing Accuray at 119 iterations is 0.880418535127 with loss: 0.048267221712\n",
            " Testing Accuray at 120 iterations is 0.879422022920 with loss: 0.048232554444\n",
            " Testing Accuray at 121 iterations is 0.879920279023 with loss: 0.048326452534\n",
            " Testing Accuray at 122 iterations is 0.880418535127 with loss: 0.048465646643\n",
            " Testing Accuray at 123 iterations is 0.880418535127 with loss: 0.048580056395\n",
            " Testing Accuray at 124 iterations is 0.882411559542 with loss: 0.048640696907\n",
            " Testing Accuray at 125 iterations is 0.882411559542 with loss: 0.048668668906\n",
            " Testing Accuray at 126 iterations is 0.884404583956 with loss: 0.048719469669\n",
            " Testing Accuray at 127 iterations is 0.887394120578 with loss: 0.048851483955\n",
            " Testing Accuray at 128 iterations is 0.889387144993 with loss: 0.049094153125\n",
            " Testing Accuray at 129 iterations is 0.888888888889 with loss: 0.049428674436\n",
            " Testing Accuray at 130 iterations is 0.886397608371 with loss: 0.049786684679\n",
            " Testing Accuray at 131 iterations is 0.884902840060 with loss: 0.050065953274\n",
            " Testing Accuray at 132 iterations is 0.883408071749 with loss: 0.050158045755\n",
            " Testing Accuray at 133 iterations is 0.880418535127 with loss: 0.049979414404\n",
            " Testing Accuray at 134 iterations is 0.878923766816 with loss: 0.049495498620\n",
            " Testing Accuray at 135 iterations is 0.883408071749 with loss: 0.048729865982\n",
            " Testing Accuray at 136 iterations is 0.884902840060 with loss: 0.047756531573\n",
            " Testing Accuray at 137 iterations is 0.888390632785 with loss: 0.046679856174\n",
            " Testing Accuray at 138 iterations is 0.894867962133 with loss: 0.045609942215\n",
            " Testing Accuray at 139 iterations is 0.893373193822 with loss: 0.044641283959\n",
            " Testing Accuray at 140 iterations is 0.898355754858 with loss: 0.043839248464\n",
            " Testing Accuray at 141 iterations is 0.897359242651 with loss: 0.043234735773\n",
            " Testing Accuray at 142 iterations is 0.899850523169 with loss: 0.042824757236\n",
            " Testing Accuray at 143 iterations is 0.896860986547 with loss: 0.042577011486\n",
            " Testing Accuray at 144 iterations is 0.895366218236 with loss: 0.042438245302\n",
            " Testing Accuray at 145 iterations is 0.895366218236 with loss: 0.042346536154\n",
            " Testing Accuray at 146 iterations is 0.896362730443 with loss: 0.042245980154\n",
            " Testing Accuray at 147 iterations is 0.896860986547 with loss: 0.042100322858\n",
            " Testing Accuray at 148 iterations is 0.895864474340 with loss: 0.041901523215\n",
            " Testing Accuray at 149 iterations is 0.895864474340 with loss: 0.041670475536\n",
            " Testing Accuray at 150 iterations is 0.897359242651 with loss: 0.041449577105\n",
            " Testing Accuray at 151 iterations is 0.898854010962 with loss: 0.041289476154\n",
            " Testing Accuray at 152 iterations is 0.899850523169 with loss: 0.041234069385\n",
            " Testing Accuray at 153 iterations is 0.901345291480 with loss: 0.041307959452\n",
            " Testing Accuray at 154 iterations is 0.898854010962 with loss: 0.041509192166\n",
            " Testing Accuray at 155 iterations is 0.896860986547 with loss: 0.041808224389\n",
            " Testing Accuray at 156 iterations is 0.897857498754 with loss: 0.042152881783\n",
            " Testing Accuray at 157 iterations is 0.895366218236 with loss: 0.042478442956\n",
            " Testing Accuray at 158 iterations is 0.896362730443 with loss: 0.042721069195\n",
            " Testing Accuray at 159 iterations is 0.894369706029 with loss: 0.042831500049\n",
            " Testing Accuray at 160 iterations is 0.894369706029 with loss: 0.042785263865\n",
            " Testing Accuray at 161 iterations is 0.895864474340 with loss: 0.042586510055\n",
            " Testing Accuray at 162 iterations is 0.894867962133 with loss: 0.042264707794\n",
            " Testing Accuray at 163 iterations is 0.896860986547 with loss: 0.041865793586\n",
            " Testing Accuray at 164 iterations is 0.899850523169 with loss: 0.041440857202\n",
            " Testing Accuray at 165 iterations is 0.899850523169 with loss: 0.041035630687\n",
            " Testing Accuray at 166 iterations is 0.902840059791 with loss: 0.040683032261\n",
            " Testing Accuray at 167 iterations is 0.902840059791 with loss: 0.040399535372\n",
            " Testing Accuray at 168 iterations is 0.902840059791 with loss: 0.040185035664\n",
            " Testing Accuray at 169 iterations is 0.899352267065 with loss: 0.040025501395\n",
            " Testing Accuray at 170 iterations is 0.899850523169 with loss: 0.039897676995\n",
            " Testing Accuray at 171 iterations is 0.900847035376 with loss: 0.039775014456\n",
            " Testing Accuray at 172 iterations is 0.902840059791 with loss: 0.039633755412\n",
            " Testing Accuray at 173 iterations is 0.903836571998 with loss: 0.039457921125\n",
            " Testing Accuray at 174 iterations is 0.904334828102 with loss: 0.039242140704\n",
            " Testing Accuray at 175 iterations is 0.903338315894 with loss: 0.038991804044\n",
            " Testing Accuray at 176 iterations is 0.906826108620 with loss: 0.038720773929\n",
            " Testing Accuray at 177 iterations is 0.907324364723 with loss: 0.038447530989\n",
            " Testing Accuray at 178 iterations is 0.907324364723 with loss: 0.038190918828\n",
            " Testing Accuray at 179 iterations is 0.906826108620 with loss: 0.037966538786\n",
            " Testing Accuray at 180 iterations is 0.907324364723 with loss: 0.037784422169\n",
            " Testing Accuray at 181 iterations is 0.907324364723 with loss: 0.037648096340\n",
            " Testing Accuray at 182 iterations is 0.907324364723 with loss: 0.037554784973\n",
            " Testing Accuray at 183 iterations is 0.908320876931 with loss: 0.037496372913\n",
            " Testing Accuray at 184 iterations is 0.907324364723 with loss: 0.037460883186\n",
            " Testing Accuray at 185 iterations is 0.908320876931 with loss: 0.037434374556\n",
            " Testing Accuray at 186 iterations is 0.908819133034 with loss: 0.037403194234\n",
            " Testing Accuray at 187 iterations is 0.909815645242 with loss: 0.037356377453\n",
            " Testing Accuray at 188 iterations is 0.907822620827 with loss: 0.037287779079\n",
            " Testing Accuray at 189 iterations is 0.909815645242 with loss: 0.037197396217\n",
            " Testing Accuray at 190 iterations is 0.910313901345 with loss: 0.037091398101\n",
            " Testing Accuray at 191 iterations is 0.909815645242 with loss: 0.036980649549\n",
            " Testing Accuray at 192 iterations is 0.910313901345 with loss: 0.036877935483\n",
            " Testing Accuray at 193 iterations is 0.912306925760 with loss: 0.036794525182\n",
            " Testing Accuray at 194 iterations is 0.913303437967 with loss: 0.036736986563\n",
            " Testing Accuray at 195 iterations is 0.911310413553 with loss: 0.036705154249\n",
            " Testing Accuray at 196 iterations is 0.913303437967 with loss: 0.036691859990\n",
            " Testing Accuray at 197 iterations is 0.912805181863 with loss: 0.036684547067\n",
            " Testing Accuray at 198 iterations is 0.912306925760 with loss: 0.036668366218\n",
            " Testing Accuray at 199 iterations is 0.912306925760 with loss: 0.036629940291\n",
            " Testing Accuray at 200 iterations is 0.913801694071 with loss: 0.036560798690\n",
            " Testing Accuray at 201 iterations is 0.915296462382 with loss: 0.036459574187\n",
            " Testing Accuray at 202 iterations is 0.914299950174 with loss: 0.036332403332\n",
            " Testing Accuray at 203 iterations is 0.914299950174 with loss: 0.036191474790\n",
            " Testing Accuray at 204 iterations is 0.913801694071 with loss: 0.036052168800\n",
            " Testing Accuray at 205 iterations is 0.913303437967 with loss: 0.035929573369\n",
            " Testing Accuray at 206 iterations is 0.912805181863 with loss: 0.035835263091\n",
            " Testing Accuray at 207 iterations is 0.912306925760 with loss: 0.035775087812\n",
            " Testing Accuray at 208 iterations is 0.911808669656 with loss: 0.035748411122\n",
            " Testing Accuray at 209 iterations is 0.910812157449 with loss: 0.035748859054\n",
            " Testing Accuray at 210 iterations is 0.909815645242 with loss: 0.035766279756\n",
            " Testing Accuray at 211 iterations is 0.910812157449 with loss: 0.035789353641\n",
            " Testing Accuray at 212 iterations is 0.910812157449 with loss: 0.035808187731\n",
            " Testing Accuray at 213 iterations is 0.910313901345 with loss: 0.035816297550\n",
            " Testing Accuray at 214 iterations is 0.910812157449 with loss: 0.035811594798\n",
            " Testing Accuray at 215 iterations is 0.911310413553 with loss: 0.035796284683\n",
            " Testing Accuray at 216 iterations is 0.908819133034 with loss: 0.035775843646\n",
            " Testing Accuray at 217 iterations is 0.908819133034 with loss: 0.035757425585\n",
            " Testing Accuray at 218 iterations is 0.906826108620 with loss: 0.035748102994\n",
            " Testing Accuray at 219 iterations is 0.906826108620 with loss: 0.035753301910\n",
            " Testing Accuray at 220 iterations is 0.906327852516 with loss: 0.035775677411\n",
            " Testing Accuray at 221 iterations is 0.906327852516 with loss: 0.035814547115\n",
            " Testing Accuray at 222 iterations is 0.906826108620 with loss: 0.035865889046\n",
            " Testing Accuray at 223 iterations is 0.908819133034 with loss: 0.035922832457\n",
            " Testing Accuray at 224 iterations is 0.910313901345 with loss: 0.035976524515\n",
            " Testing Accuray at 225 iterations is 0.908819133034 with loss: 0.036017233073\n",
            " Testing Accuray at 226 iterations is 0.908320876931 with loss: 0.036035537932\n",
            " Testing Accuray at 227 iterations is 0.908320876931 with loss: 0.036023465422\n",
            " Testing Accuray at 228 iterations is 0.907324364723 with loss: 0.035975433865\n",
            " Testing Accuray at 229 iterations is 0.907324364723 with loss: 0.035888901935\n",
            " Testing Accuray at 230 iterations is 0.907324364723 with loss: 0.035764649014\n",
            " Testing Accuray at 231 iterations is 0.907822620827 with loss: 0.035606663497\n",
            " Testing Accuray at 232 iterations is 0.908320876931 with loss: 0.035421665612\n",
            " Testing Accuray at 233 iterations is 0.909815645242 with loss: 0.035218336907\n",
            " Testing Accuray at 234 iterations is 0.908819133034 with loss: 0.035006361325\n",
            " Testing Accuray at 235 iterations is 0.909317389138 with loss: 0.034795398045\n",
            " Testing Accuray at 236 iterations is 0.909815645242 with loss: 0.034594104087\n",
            " Testing Accuray at 237 iterations is 0.911310413553 with loss: 0.034409309482\n",
            " Testing Accuray at 238 iterations is 0.909815645242 with loss: 0.034245425625\n",
            " Testing Accuray at 239 iterations is 0.910812157449 with loss: 0.034104142977\n",
            " Testing Accuray at 240 iterations is 0.911808669656 with loss: 0.033984448839\n",
            " Testing Accuray at 241 iterations is 0.910313901345 with loss: 0.033882967504\n",
            " Testing Accuray at 242 iterations is 0.911808669656 with loss: 0.033794591092\n",
            " Testing Accuray at 243 iterations is 0.912306925760 with loss: 0.033713330348\n",
            " Testing Accuray at 244 iterations is 0.912805181863 with loss: 0.033633276286\n",
            " Testing Accuray at 245 iterations is 0.913303437967 with loss: 0.033549535846\n",
            " Testing Accuray at 246 iterations is 0.913801694071 with loss: 0.033458998241\n",
            " Testing Accuray at 247 iterations is 0.914299950174 with loss: 0.033360809729\n",
            " Testing Accuray at 248 iterations is 0.913801694071 with loss: 0.033256481756\n",
            " Testing Accuray at 249 iterations is 0.915296462382 with loss: 0.033149621388\n",
            " Testing Accuray at 250 iterations is 0.915794718485 with loss: 0.033045338871\n",
            " Testing Accuray at 251 iterations is 0.916791230693 with loss: 0.032949439832\n",
            " Testing Accuray at 252 iterations is 0.916292974589 with loss: 0.032867538209\n",
            " Testing Accuray at 253 iterations is 0.916791230693 with loss: 0.032804227197\n",
            " Testing Accuray at 254 iterations is 0.917289486796 with loss: 0.032762423494\n",
            " Testing Accuray at 255 iterations is 0.918784255107 with loss: 0.032742963580\n",
            " Testing Accuray at 256 iterations is 0.919282511211 with loss: 0.032744488962\n",
            " Testing Accuray at 257 iterations is 0.917787742900 with loss: 0.032763617142\n",
            " Testing Accuray at 258 iterations is 0.918285999003 with loss: 0.032795360231\n",
            " Testing Accuray at 259 iterations is 0.918285999003 with loss: 0.032833725429\n",
            " Testing Accuray at 260 iterations is 0.919282511211 with loss: 0.032872411995\n",
            " Testing Accuray at 261 iterations is 0.918784255107 with loss: 0.032905509735\n",
            " Testing Accuray at 262 iterations is 0.918784255107 with loss: 0.032928106360\n",
            " Testing Accuray at 263 iterations is 0.919282511211 with loss: 0.032936726620\n",
            " Testing Accuray at 264 iterations is 0.919282511211 with loss: 0.032929553632\n",
            " Testing Accuray at 265 iterations is 0.919780767314 with loss: 0.032906418242\n",
            " Testing Accuray at 266 iterations is 0.919282511211 with loss: 0.032868579010\n",
            " Testing Accuray at 267 iterations is 0.918784255107 with loss: 0.032818346529\n",
            " Testing Accuray at 268 iterations is 0.919780767314 with loss: 0.032758625248\n",
            " Testing Accuray at 269 iterations is 0.920279023418 with loss: 0.032692451030\n",
            " Testing Accuray at 270 iterations is 0.918784255107 with loss: 0.032622593508\n",
            " Testing Accuray at 271 iterations is 0.917787742900 with loss: 0.032551272340\n",
            " Testing Accuray at 272 iterations is 0.917289486796 with loss: 0.032480010808\n",
            " Testing Accuray at 273 iterations is 0.916791230693 with loss: 0.032409624414\n",
            " Testing Accuray at 274 iterations is 0.918285999003 with loss: 0.032340321117\n",
            " Testing Accuray at 275 iterations is 0.917289486796 with loss: 0.032271876723\n",
            " Testing Accuray at 276 iterations is 0.917787742900 with loss: 0.032203844732\n",
            " Testing Accuray at 277 iterations is 0.917289486796 with loss: 0.032135763586\n",
            " Testing Accuray at 278 iterations is 0.917289486796 with loss: 0.032067333217\n",
            " Testing Accuray at 279 iterations is 0.917289486796 with loss: 0.031998543755\n",
            " Testing Accuray at 280 iterations is 0.917289486796 with loss: 0.031929749422\n",
            " Testing Accuray at 281 iterations is 0.916292974589 with loss: 0.031861688145\n",
            " Testing Accuray at 282 iterations is 0.917289486796 with loss: 0.031795451858\n",
            " Testing Accuray at 283 iterations is 0.916791230693 with loss: 0.031732414513\n",
            " Testing Accuray at 284 iterations is 0.916791230693 with loss: 0.031674125832\n",
            " Testing Accuray at 285 iterations is 0.916791230693 with loss: 0.031622180011\n",
            " Testing Accuray at 286 iterations is 0.917787742900 with loss: 0.031578070454\n",
            " Testing Accuray at 287 iterations is 0.916791230693 with loss: 0.031543044046\n",
            " Testing Accuray at 288 iterations is 0.916791230693 with loss: 0.031517970395\n",
            " Testing Accuray at 289 iterations is 0.917289486796 with loss: 0.031503241906\n",
            " Testing Accuray at 290 iterations is 0.916791230693 with loss: 0.031498718541\n",
            " Testing Accuray at 291 iterations is 0.917787742900 with loss: 0.031503726445\n",
            " Testing Accuray at 292 iterations is 0.916791230693 with loss: 0.031517112843\n",
            " Testing Accuray at 293 iterations is 0.916791230693 with loss: 0.031537351729\n",
            " Testing Accuray at 294 iterations is 0.916791230693 with loss: 0.031562687482\n",
            " Testing Accuray at 295 iterations is 0.916292974589 with loss: 0.031591297882\n",
            " Testing Accuray at 296 iterations is 0.915794718485 with loss: 0.031621455229\n",
            " Testing Accuray at 297 iterations is 0.915794718485 with loss: 0.031651664870\n",
            " Testing Accuray at 298 iterations is 0.916292974589 with loss: 0.031680764158\n",
            " Testing Accuray at 299 iterations is 0.916791230693 with loss: 0.031707971076\n",
            " Testing Accuray at 300 iterations is 0.917289486796 with loss: 0.031732879248\n",
            " Testing Accuray at 301 iterations is 0.917787742900 with loss: 0.031755403509\n",
            " Testing Accuray at 302 iterations is 0.917289486796 with loss: 0.031775686551\n",
            " Testing Accuray at 303 iterations is 0.917787742900 with loss: 0.031793981453\n",
            " Testing Accuray at 304 iterations is 0.918285999003 with loss: 0.031810526848\n",
            " Testing Accuray at 305 iterations is 0.918784255107 with loss: 0.031825431136\n",
            " Testing Accuray at 306 iterations is 0.918784255107 with loss: 0.031838579850\n",
            " Testing Accuray at 307 iterations is 0.918784255107 with loss: 0.031849576790\n",
            " Testing Accuray at 308 iterations is 0.920777279522 with loss: 0.031857725181\n",
            " Testing Accuray at 309 iterations is 0.921275535625 with loss: 0.031862050707\n",
            " Testing Accuray at 310 iterations is 0.920777279522 with loss: 0.031861363890\n",
            " Testing Accuray at 311 iterations is 0.921773791729 with loss: 0.031854355415\n",
            " Testing Accuray at 312 iterations is 0.922272047833 with loss: 0.031839714696\n",
            " Testing Accuray at 313 iterations is 0.922272047833 with loss: 0.031816259591\n",
            " Testing Accuray at 314 iterations is 0.921773791729 with loss: 0.031783063846\n",
            " Testing Accuray at 315 iterations is 0.921773791729 with loss: 0.031739568846\n",
            " Testing Accuray at 316 iterations is 0.921773791729 with loss: 0.031685667693\n",
            " Testing Accuray at 317 iterations is 0.921773791729 with loss: 0.031621752372\n",
            " Testing Accuray at 318 iterations is 0.922272047833 with loss: 0.031548718618\n",
            " Testing Accuray at 319 iterations is 0.921773791729 with loss: 0.031467927517\n",
            " Testing Accuray at 320 iterations is 0.921275535625 with loss: 0.031381127294\n",
            " Testing Accuray at 321 iterations is 0.921773791729 with loss: 0.031290342645\n",
            " Testing Accuray at 322 iterations is 0.921773791729 with loss: 0.031197741781\n",
            " Testing Accuray at 323 iterations is 0.922272047833 with loss: 0.031105492964\n",
            " Testing Accuray at 324 iterations is 0.923766816143 with loss: 0.031015622535\n",
            " Testing Accuray at 325 iterations is 0.924265072247 with loss: 0.030929885559\n",
            " Testing Accuray at 326 iterations is 0.925261584454 with loss: 0.030849658492\n",
            " Testing Accuray at 327 iterations is 0.924763328351 with loss: 0.030775860991\n",
            " Testing Accuray at 328 iterations is 0.923766816143 with loss: 0.030708911614\n",
            " Testing Accuray at 329 iterations is 0.924265072247 with loss: 0.030648719680\n",
            " Testing Accuray at 330 iterations is 0.925261584454 with loss: 0.030594713218\n",
            " Testing Accuray at 331 iterations is 0.924763328351 with loss: 0.030545900736\n",
            " Testing Accuray at 332 iterations is 0.924763328351 with loss: 0.030500962371\n",
            " Testing Accuray at 333 iterations is 0.924265072247 with loss: 0.030458363986\n",
            " Testing Accuray at 334 iterations is 0.924265072247 with loss: 0.030416486021\n",
            " Testing Accuray at 335 iterations is 0.923766816143 with loss: 0.030373757470\n",
            " Testing Accuray at 336 iterations is 0.923766816143 with loss: 0.030328784605\n",
            " Testing Accuray at 337 iterations is 0.923766816143 with loss: 0.030280464067\n",
            " Testing Accuray at 338 iterations is 0.924763328351 with loss: 0.030228070928\n",
            " Testing Accuray at 339 iterations is 0.925261584454 with loss: 0.030171314259\n",
            " Testing Accuray at 340 iterations is 0.925759840558 with loss: 0.030110355503\n",
            " Testing Accuray at 341 iterations is 0.925261584454 with loss: 0.030045788281\n",
            " Testing Accuray at 342 iterations is 0.925261584454 with loss: 0.029978581769\n",
            " Testing Accuray at 343 iterations is 0.924763328351 with loss: 0.029909993067\n",
            " Testing Accuray at 344 iterations is 0.924265072247 with loss: 0.029841456682\n",
            " Testing Accuray at 345 iterations is 0.924265072247 with loss: 0.029774461091\n",
            " Testing Accuray at 346 iterations is 0.924763328351 with loss: 0.029710423193\n",
            " Testing Accuray at 347 iterations is 0.924763328351 with loss: 0.029650571307\n",
            " Testing Accuray at 348 iterations is 0.925759840558 with loss: 0.029595846344\n",
            " Testing Accuray at 349 iterations is 0.925759840558 with loss: 0.029546829031\n",
            " Testing Accuray at 350 iterations is 0.924763328351 with loss: 0.029503698760\n",
            " Testing Accuray at 351 iterations is 0.924763328351 with loss: 0.029466227021\n",
            " Testing Accuray at 352 iterations is 0.925261584454 with loss: 0.029433805528\n",
            " Testing Accuray at 353 iterations is 0.925261584454 with loss: 0.029405506282\n",
            " Testing Accuray at 354 iterations is 0.924763328351 with loss: 0.029380168112\n",
            " Testing Accuray at 355 iterations is 0.924763328351 with loss: 0.029356501843\n",
            " Testing Accuray at 356 iterations is 0.926756352765 with loss: 0.029333204532\n",
            " Testing Accuray at 357 iterations is 0.926756352765 with loss: 0.029309072236\n",
            " Testing Accuray at 358 iterations is 0.926258096662 with loss: 0.029283100948\n",
            " Testing Accuray at 359 iterations is 0.925759840558 with loss: 0.029254566468\n",
            " Testing Accuray at 360 iterations is 0.925759840558 with loss: 0.029223076226\n",
            " Testing Accuray at 361 iterations is 0.926258096662 with loss: 0.029188589021\n",
            " Testing Accuray at 362 iterations is 0.925759840558 with loss: 0.029151402018\n",
            " Testing Accuray at 363 iterations is 0.924763328351 with loss: 0.029112107711\n",
            " Testing Accuray at 364 iterations is 0.923766816143 with loss: 0.029071526437\n",
            " Testing Accuray at 365 iterations is 0.925261584454 with loss: 0.029030622147\n",
            " Testing Accuray at 366 iterations is 0.926258096662 with loss: 0.028990410254\n",
            " Testing Accuray at 367 iterations is 0.926258096662 with loss: 0.028951866417\n",
            " Testing Accuray at 368 iterations is 0.926258096662 with loss: 0.028915844292\n",
            " Testing Accuray at 369 iterations is 0.927254608869 with loss: 0.028883008652\n",
            " Testing Accuray at 370 iterations is 0.927254608869 with loss: 0.028853788318\n",
            " Testing Accuray at 371 iterations is 0.927254608869 with loss: 0.028828351153\n",
            " Testing Accuray at 372 iterations is 0.926756352765 with loss: 0.028806601338\n",
            " Testing Accuray at 373 iterations is 0.926258096662 with loss: 0.028788197359\n",
            " Testing Accuray at 374 iterations is 0.924763328351 with loss: 0.028772587679\n",
            " Testing Accuray at 375 iterations is 0.925261584454 with loss: 0.028759060077\n",
            " Testing Accuray at 376 iterations is 0.924763328351 with loss: 0.028746799979\n",
            " Testing Accuray at 377 iterations is 0.924763328351 with loss: 0.028734952833\n",
            " Testing Accuray at 378 iterations is 0.925261584454 with loss: 0.028722685710\n",
            " Testing Accuray at 379 iterations is 0.924763328351 with loss: 0.028709243666\n",
            " Testing Accuray at 380 iterations is 0.924763328351 with loss: 0.028693997083\n",
            " Testing Accuray at 381 iterations is 0.924265072247 with loss: 0.028676477146\n",
            " Testing Accuray at 382 iterations is 0.924265072247 with loss: 0.028656397604\n",
            " Testing Accuray at 383 iterations is 0.924265072247 with loss: 0.028633662181\n",
            " Testing Accuray at 384 iterations is 0.925261584454 with loss: 0.028608358080\n",
            " Testing Accuray at 385 iterations is 0.925759840558 with loss: 0.028580737080\n",
            " Testing Accuray at 386 iterations is 0.925261584454 with loss: 0.028551186569\n",
            " Testing Accuray at 387 iterations is 0.924763328351 with loss: 0.028520193426\n",
            " Testing Accuray at 388 iterations is 0.924763328351 with loss: 0.028488303975\n",
            " Testing Accuray at 389 iterations is 0.924265072247 with loss: 0.028456083226\n",
            " Testing Accuray at 390 iterations is 0.924265072247 with loss: 0.028424076374\n",
            " Testing Accuray at 391 iterations is 0.924763328351 with loss: 0.028392775028\n",
            " Testing Accuray at 392 iterations is 0.924763328351 with loss: 0.028362590048\n",
            " Testing Accuray at 393 iterations is 0.924763328351 with loss: 0.028333832183\n",
            " Testing Accuray at 394 iterations is 0.924763328351 with loss: 0.028306701013\n",
            " Testing Accuray at 395 iterations is 0.925261584454 with loss: 0.028281282098\n",
            " Testing Accuray at 396 iterations is 0.925759840558 with loss: 0.028257551710\n",
            " Testing Accuray at 397 iterations is 0.926258096662 with loss: 0.028235388115\n",
            " Testing Accuray at 398 iterations is 0.926756352765 with loss: 0.028214588125\n",
            " Testing Accuray at 399 iterations is 0.927254608869 with loss: 0.028194887449\n",
            " Testing Accuray at 400 iterations is 0.926756352765 with loss: 0.028175983324\n",
            " Testing Accuray at 401 iterations is 0.927254608869 with loss: 0.028157557921\n",
            " Testing Accuray at 402 iterations is 0.927254608869 with loss: 0.028139301093\n",
            " Testing Accuray at 403 iterations is 0.927254608869 with loss: 0.028120931167\n",
            " Testing Accuray at 404 iterations is 0.927254608869 with loss: 0.028102212628\n",
            " Testing Accuray at 405 iterations is 0.927752864973 with loss: 0.028082969774\n",
            " Testing Accuray at 406 iterations is 0.927752864973 with loss: 0.028063095652\n",
            " Testing Accuray at 407 iterations is 0.927254608869 with loss: 0.028042555853\n",
            " Testing Accuray at 408 iterations is 0.927254608869 with loss: 0.028021387083\n",
            " Testing Accuray at 409 iterations is 0.927752864973 with loss: 0.027999690716\n",
            " Testing Accuray at 410 iterations is 0.927752864973 with loss: 0.027977621906\n",
            " Testing Accuray at 411 iterations is 0.926756352765 with loss: 0.027955375094\n",
            " Testing Accuray at 412 iterations is 0.927254608869 with loss: 0.027933167047\n",
            " Testing Accuray at 413 iterations is 0.927752864973 with loss: 0.027911218713\n",
            " Testing Accuray at 414 iterations is 0.927752864973 with loss: 0.027889737305\n",
            " Testing Accuray at 415 iterations is 0.927752864973 with loss: 0.027868899976\n",
            " Testing Accuray at 416 iterations is 0.927254608869 with loss: 0.027848840364\n",
            " Testing Accuray at 417 iterations is 0.927752864973 with loss: 0.027829639034\n",
            " Testing Accuray at 418 iterations is 0.927752864973 with loss: 0.027811318554\n",
            " Testing Accuray at 419 iterations is 0.928251121076 with loss: 0.027793843558\n",
            " Testing Accuray at 420 iterations is 0.927752864973 with loss: 0.027777125763\n",
            " Testing Accuray at 421 iterations is 0.927254608869 with loss: 0.027761033491\n",
            " Testing Accuray at 422 iterations is 0.927254608869 with loss: 0.027745404871\n",
            " Testing Accuray at 423 iterations is 0.926756352765 with loss: 0.027730063608\n",
            " Testing Accuray at 424 iterations is 0.926756352765 with loss: 0.027714835956\n",
            " Testing Accuray at 425 iterations is 0.927254608869 with loss: 0.027699567443\n",
            " Testing Accuray at 426 iterations is 0.927254608869 with loss: 0.027684137898\n",
            " Testing Accuray at 427 iterations is 0.928251121076 with loss: 0.027668473435\n",
            " Testing Accuray at 428 iterations is 0.928251121076 with loss: 0.027652554339\n",
            " Testing Accuray at 429 iterations is 0.928251121076 with loss: 0.027636418098\n",
            " Testing Accuray at 430 iterations is 0.928251121076 with loss: 0.027620157256\n",
            " Testing Accuray at 431 iterations is 0.927752864973 with loss: 0.027603912198\n",
            " Testing Accuray at 432 iterations is 0.927752864973 with loss: 0.027587859437\n",
            " Testing Accuray at 433 iterations is 0.927752864973 with loss: 0.027572196324\n",
            " Testing Accuray at 434 iterations is 0.927752864973 with loss: 0.027557123482\n",
            " Testing Accuray at 435 iterations is 0.927254608869 with loss: 0.027542826413\n",
            " Testing Accuray at 436 iterations is 0.927254608869 with loss: 0.027529457855\n",
            " Testing Accuray at 437 iterations is 0.927254608869 with loss: 0.027517122378\n",
            " Testing Accuray at 438 iterations is 0.926756352765 with loss: 0.027505864553\n",
            " Testing Accuray at 439 iterations is 0.927254608869 with loss: 0.027495661710\n",
            " Testing Accuray at 440 iterations is 0.927254608869 with loss: 0.027486421937\n",
            " Testing Accuray at 441 iterations is 0.926756352765 with loss: 0.027477987499\n",
            " Testing Accuray at 442 iterations is 0.926258096662 with loss: 0.027470143458\n",
            " Testing Accuray at 443 iterations is 0.925261584454 with loss: 0.027462630776\n",
            " Testing Accuray at 444 iterations is 0.925759840558 with loss: 0.027455162877\n",
            " Testing Accuray at 445 iterations is 0.926258096662 with loss: 0.027447444318\n",
            " Testing Accuray at 446 iterations is 0.926756352765 with loss: 0.027439190102\n",
            " Testing Accuray at 447 iterations is 0.926756352765 with loss: 0.027430144105\n",
            " Testing Accuray at 448 iterations is 0.927254608869 with loss: 0.027420095218\n",
            " Testing Accuray at 449 iterations is 0.927254608869 with loss: 0.027408889999\n",
            " Testing Accuray at 450 iterations is 0.927254608869 with loss: 0.027396440952\n",
            " Testing Accuray at 451 iterations is 0.927254608869 with loss: 0.027382729936\n",
            " Testing Accuray at 452 iterations is 0.927254608869 with loss: 0.027367806565\n",
            " Testing Accuray at 453 iterations is 0.927752864973 with loss: 0.027351781883\n",
            " Testing Accuray at 454 iterations is 0.928749377180 with loss: 0.027334817912\n",
            " Testing Accuray at 455 iterations is 0.929247633284 with loss: 0.027317113945\n",
            " Testing Accuray at 456 iterations is 0.929247633284 with loss: 0.027298890650\n",
            " Testing Accuray at 457 iterations is 0.929247633284 with loss: 0.027280373126\n",
            " Testing Accuray at 458 iterations is 0.928749377180 with loss: 0.027261774073\n",
            " Testing Accuray at 459 iterations is 0.930244145491 with loss: 0.027243278164\n",
            " Testing Accuray at 460 iterations is 0.932237169905 with loss: 0.027225028563\n",
            " Testing Accuray at 461 iterations is 0.931738913802 with loss: 0.027207116363\n",
            " Testing Accuray at 462 iterations is 0.932237169905 with loss: 0.027189573515\n",
            " Testing Accuray at 463 iterations is 0.932735426009 with loss: 0.027172369578\n",
            " Testing Accuray at 464 iterations is 0.931240657698 with loss: 0.027155412412\n",
            " Testing Accuray at 465 iterations is 0.930244145491 with loss: 0.027138552730\n",
            " Testing Accuray at 466 iterations is 0.930244145491 with loss: 0.027121592185\n",
            " Testing Accuray at 467 iterations is 0.930244145491 with loss: 0.027104294545\n",
            " Testing Accuray at 468 iterations is 0.929745889387 with loss: 0.027086399308\n",
            " Testing Accuray at 469 iterations is 0.930244145491 with loss: 0.027067637017\n",
            " Testing Accuray at 470 iterations is 0.929745889387 with loss: 0.027047745445\n",
            " Testing Accuray at 471 iterations is 0.929745889387 with loss: 0.027026485754\n",
            " Testing Accuray at 472 iterations is 0.929745889387 with loss: 0.027003657765\n",
            " Testing Accuray at 473 iterations is 0.929745889387 with loss: 0.026979113479\n",
            " Testing Accuray at 474 iterations is 0.929247633284 with loss: 0.026952768104\n",
            " Testing Accuray at 475 iterations is 0.929247633284 with loss: 0.026924607955\n",
            " Testing Accuray at 476 iterations is 0.929745889387 with loss: 0.026894694770\n",
            " Testing Accuray at 477 iterations is 0.929745889387 with loss: 0.026863166156\n",
            " Testing Accuray at 478 iterations is 0.929745889387 with loss: 0.026830232125\n",
            " Testing Accuray at 479 iterations is 0.929745889387 with loss: 0.026796167841\n",
            " Testing Accuray at 480 iterations is 0.930244145491 with loss: 0.026761302963\n",
            " Testing Accuray at 481 iterations is 0.930742401594 with loss: 0.026726008107\n",
            " Testing Accuray at 482 iterations is 0.930244145491 with loss: 0.026690679129\n",
            " Testing Accuray at 483 iterations is 0.931240657698 with loss: 0.026655720039\n",
            " Testing Accuray at 484 iterations is 0.931240657698 with loss: 0.026621525423\n",
            " Testing Accuray at 485 iterations is 0.931240657698 with loss: 0.026588463270\n",
            " Testing Accuray at 486 iterations is 0.931738913802 with loss: 0.026556859079\n",
            " Testing Accuray at 487 iterations is 0.931240657698 with loss: 0.026526982049\n",
            " Testing Accuray at 488 iterations is 0.931240657698 with loss: 0.026499034027\n",
            " Testing Accuray at 489 iterations is 0.930742401594 with loss: 0.026473141775\n",
            " Testing Accuray at 490 iterations is 0.931240657698 with loss: 0.026449352905\n",
            " Testing Accuray at 491 iterations is 0.931738913802 with loss: 0.026427635688\n",
            " Testing Accuray at 492 iterations is 0.931738913802 with loss: 0.026407882695\n",
            " Testing Accuray at 493 iterations is 0.930244145491 with loss: 0.026389918073\n",
            " Testing Accuray at 494 iterations is 0.930244145491 with loss: 0.026373508039\n",
            " Testing Accuray at 495 iterations is 0.929745889387 with loss: 0.026358374009\n",
            " Testing Accuray at 496 iterations is 0.929247633284 with loss: 0.026344207663\n",
            " Testing Accuray at 497 iterations is 0.928749377180 with loss: 0.026330687087\n",
            " Testing Accuray at 498 iterations is 0.929247633284 with loss: 0.026317493139\n",
            " Testing Accuray at 499 iterations is 0.929247633284 with loss: 0.026304325120\n",
            " Testing Accuray at 500 iterations is 0.929745889387 with loss: 0.026290914911\n",
            "SigmoidNAG without QG Testing Accuray at   1 iterations is 0.178873941206 with loss: -7412.103037817641\n",
            "SigmoidNAG without QG Testing Accuray at   2 iterations is 0.178873941206 with loss: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-b2577c6fefeb>:389: RuntimeWarning: divide by zero encountered in log\n",
            "  loss =  np.sum( np.log( np.absolute(pp -1 + Y) )  )\n",
            "<ipython-input-1-b2577c6fefeb>:396: RuntimeWarning: divide by zero encountered in log\n",
            "  loss =  np.sum( np.log( np.absolute(pp -1 + Ytest) )  )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SigmoidNAG without QG Testing Accuray at   3 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   4 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   5 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   6 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   7 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   8 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   9 iterations is 0.178873941206 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  10 iterations is 0.292974588939 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  11 iterations is 0.309915296462 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  12 iterations is 0.335824613852 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  13 iterations is 0.368211260588 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  14 iterations is 0.369706028899 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  15 iterations is 0.329347284504 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  16 iterations is 0.289486796213 with loss: -46074.205620769877\n",
            "SigmoidNAG without QG Testing Accuray at  17 iterations is 0.356751370204 with loss: -39485.452648991472\n",
            "SigmoidNAG without QG Testing Accuray at  18 iterations is 0.398106626806 with loss: -33808.903852271782\n",
            "SigmoidNAG without QG Testing Accuray at  19 iterations is 0.512207274539 with loss: -30847.916849773170\n",
            "SigmoidNAG without QG Testing Accuray at  20 iterations is 0.533134030892 with loss: -39187.645648093086\n",
            "SigmoidNAG without QG Testing Accuray at  21 iterations is 0.461385151968 with loss: -32157.650125180124\n",
            "SigmoidNAG without QG Testing Accuray at  22 iterations is 0.514698555057 with loss: -15378.401922438239\n",
            "SigmoidNAG without QG Testing Accuray at  23 iterations is 0.576482311908 with loss: -17410.553061604904\n",
            "SigmoidNAG without QG Testing Accuray at  24 iterations is 0.619332336821 with loss: -17596.167693271400\n",
            "SigmoidNAG without QG Testing Accuray at  25 iterations is 0.498754359741 with loss: -16192.324874658143\n",
            "SigmoidNAG without QG Testing Accuray at  26 iterations is 0.441953163926 with loss: -14156.287232333891\n",
            "SigmoidNAG without QG Testing Accuray at  27 iterations is 0.423517688092 with loss: -14262.417685419416\n",
            "SigmoidNAG without QG Testing Accuray at  28 iterations is 0.405580468361 with loss: -16156.619329597997\n",
            "SigmoidNAG without QG Testing Accuray at  29 iterations is 0.462381664175 with loss: -15064.446891203581\n",
            "SigmoidNAG without QG Testing Accuray at  30 iterations is 0.473841554559 with loss: -10477.846434748977\n",
            "SigmoidNAG without QG Testing Accuray at  31 iterations is 0.491280518186 with loss: -10030.134730337315\n",
            "SigmoidNAG without QG Testing Accuray at  32 iterations is 0.459392127554 with loss: -10594.931181140491\n",
            "SigmoidNAG without QG Testing Accuray at  33 iterations is 0.588440458396 with loss: -7930.400651177375\n",
            "SigmoidNAG without QG Testing Accuray at  34 iterations is 0.597409068261 with loss: -8283.568452157286\n",
            "SigmoidNAG without QG Testing Accuray at  35 iterations is 0.533134030892 with loss: -9811.595878462704\n",
            "SigmoidNAG without QG Testing Accuray at  36 iterations is 0.523667164923 with loss: -10139.187450036752\n",
            "SigmoidNAG without QG Testing Accuray at  37 iterations is 0.550074738416 with loss: -8563.114550435417\n",
            "SigmoidNAG without QG Testing Accuray at  38 iterations is 0.642750373692 with loss: -6441.019544905341\n",
            "SigmoidNAG without QG Testing Accuray at  39 iterations is 0.664175386148 with loss: -5430.694052471343\n",
            "SigmoidNAG without QG Testing Accuray at  40 iterations is 0.650224215247 with loss: -5598.431334456196\n",
            "SigmoidNAG without QG Testing Accuray at  41 iterations is 0.637269556552 with loss: -5741.181279654032\n",
            "SigmoidNAG without QG Testing Accuray at  42 iterations is 0.679621325361 with loss: -5418.921820910849\n",
            "SigmoidNAG without QG Testing Accuray at  43 iterations is 0.671150971599 with loss: -5424.247730688944\n",
            "SigmoidNAG without QG Testing Accuray at  44 iterations is 0.636273044345 with loss: -5789.167829934297\n",
            "SigmoidNAG without QG Testing Accuray at  45 iterations is 0.635276532138 with loss: -6116.971618170060\n",
            "SigmoidNAG without QG Testing Accuray at  46 iterations is 0.644245142003 with loss: -6185.612324452977\n",
            "SigmoidNAG without QG Testing Accuray at  47 iterations is 0.649725959143 with loss: -5479.882489580183\n",
            "SigmoidNAG without QG Testing Accuray at  48 iterations is 0.696063776781 with loss: -4536.234505371828\n",
            "SigmoidNAG without QG Testing Accuray at  49 iterations is 0.748380667663 with loss: -4014.055637592267\n",
            "SigmoidNAG without QG Testing Accuray at  50 iterations is 0.766816143498 with loss: -3939.933759333107\n",
            "SigmoidNAG without QG Testing Accuray at  51 iterations is 0.768310911809 with loss: -4116.647782322047\n",
            "SigmoidNAG without QG Testing Accuray at  52 iterations is 0.748380667663 with loss: -4322.324568713346\n",
            "SigmoidNAG without QG Testing Accuray at  53 iterations is 0.731439960140 with loss: -4420.830582655983\n",
            "SigmoidNAG without QG Testing Accuray at  54 iterations is 0.731439960140 with loss: -4429.826453044174\n",
            "SigmoidNAG without QG Testing Accuray at  55 iterations is 0.733931240658 with loss: -4389.450213504499\n",
            "SigmoidNAG without QG Testing Accuray at  56 iterations is 0.750871948181 with loss: -4205.523063547642\n",
            "SigmoidNAG without QG Testing Accuray at  57 iterations is 0.783756851021 with loss: -3836.782729285996\n",
            "SigmoidNAG without QG Testing Accuray at  58 iterations is 0.805181863478 with loss: -3454.370765072379\n",
            "SigmoidNAG without QG Testing Accuray at  59 iterations is 0.814150473343 with loss: -3223.366493354808\n",
            "SigmoidNAG without QG Testing Accuray at  60 iterations is 0.818634778276 with loss: -3159.083137039529\n",
            "SigmoidNAG without QG Testing Accuray at  61 iterations is 0.807673143996 with loss: -3234.031655255811\n",
            "SigmoidNAG without QG Testing Accuray at  62 iterations is 0.805181863478 with loss: -3402.935829725885\n",
            "SigmoidNAG without QG Testing Accuray at  63 iterations is 0.788241155954 with loss: -3527.475395440586\n",
            "SigmoidNAG without QG Testing Accuray at  64 iterations is 0.784255107125 with loss: -3443.017885965464\n",
            "SigmoidNAG without QG Testing Accuray at  65 iterations is 0.792227204783 with loss: -3168.212595359031\n",
            "SigmoidNAG without QG Testing Accuray at  66 iterations is 0.812157448929 with loss: -2896.371060007231\n",
            "SigmoidNAG without QG Testing Accuray at  67 iterations is 0.831589436971 with loss: -2763.614864922251\n",
            "SigmoidNAG without QG Testing Accuray at  68 iterations is 0.851021425012 with loss: -2768.852632276411\n",
            "SigmoidNAG without QG Testing Accuray at  69 iterations is 0.845042351769 with loss: -2854.042398323656\n",
            "SigmoidNAG without QG Testing Accuray at  70 iterations is 0.829098156452 with loss: -2970.964976931506\n",
            "SigmoidNAG without QG Testing Accuray at  71 iterations is 0.803687095167 with loss: -3092.657112363633\n",
            "SigmoidNAG without QG Testing Accuray at  72 iterations is 0.788739412058 with loss: -3193.787677349562\n",
            "SigmoidNAG without QG Testing Accuray at  73 iterations is 0.782760338814 with loss: -3231.223904706845\n",
            "SigmoidNAG without QG Testing Accuray at  74 iterations is 0.785749875436 with loss: -3161.765146624356\n",
            "SigmoidNAG without QG Testing Accuray at  75 iterations is 0.795216741405 with loss: -2990.651264649224\n",
            "SigmoidNAG without QG Testing Accuray at  76 iterations is 0.809167912307 with loss: -2781.502680285643\n",
            "SigmoidNAG without QG Testing Accuray at  77 iterations is 0.824613851520 with loss: -2607.187218443195\n",
            "SigmoidNAG without QG Testing Accuray at  78 iterations is 0.832585949178 with loss: -2507.103237446275\n",
            "SigmoidNAG without QG Testing Accuray at  79 iterations is 0.845540607872 with loss: -2482.965491265687\n",
            "SigmoidNAG without QG Testing Accuray at  80 iterations is 0.851021425012 with loss: -2506.699703502500\n",
            "SigmoidNAG without QG Testing Accuray at  81 iterations is 0.849526656702 with loss: -2533.522398528960\n",
            "SigmoidNAG without QG Testing Accuray at  82 iterations is 0.851519681116 with loss: -2529.791363708441\n",
            "SigmoidNAG without QG Testing Accuray at  83 iterations is 0.851021425012 with loss: -2496.308243673222\n",
            "SigmoidNAG without QG Testing Accuray at  84 iterations is 0.854010961634 with loss: -2457.178904177257\n",
            "SigmoidNAG without QG Testing Accuray at  85 iterations is 0.849526656702 with loss: -2429.118018488634\n",
            "SigmoidNAG without QG Testing Accuray at  86 iterations is 0.850024912805 with loss: -2411.777437508596\n",
            "SigmoidNAG without QG Testing Accuray at  87 iterations is 0.854010961634 with loss: -2400.579360099588\n",
            "SigmoidNAG without QG Testing Accuray at  88 iterations is 0.855505729945 with loss: -2394.744789975962\n",
            "SigmoidNAG without QG Testing Accuray at  89 iterations is 0.856003986049 with loss: -2393.724649983626\n",
            "SigmoidNAG without QG Testing Accuray at  90 iterations is 0.854010961634 with loss: -2393.752294990899\n",
            "SigmoidNAG without QG Testing Accuray at  91 iterations is 0.849028400598 with loss: -2388.829834261554\n",
            "SigmoidNAG without QG Testing Accuray at  92 iterations is 0.847035376183 with loss: -2371.946513331421\n",
            "SigmoidNAG without QG Testing Accuray at  93 iterations is 0.845540607872 with loss: -2335.366434591491\n",
            "SigmoidNAG without QG Testing Accuray at  94 iterations is 0.850024912805 with loss: -2273.880904991341\n",
            "SigmoidNAG without QG Testing Accuray at  95 iterations is 0.854010961634 with loss: -2192.011698786621\n",
            "SigmoidNAG without QG Testing Accuray at  96 iterations is 0.866467364225 with loss: -2107.640987181850\n",
            "SigmoidNAG without QG Testing Accuray at  97 iterations is 0.867463876432 with loss: -2044.665003382227\n",
            "SigmoidNAG without QG Testing Accuray at  98 iterations is 0.871948181365 with loss: -2018.925517559122\n",
            "SigmoidNAG without QG Testing Accuray at  99 iterations is 0.875934230194 with loss: -2028.861643400526\n",
            "SigmoidNAG without QG Testing Accuray at 100 iterations is 0.873941205780 with loss: -2057.474306193588\n",
            "SigmoidNAG without QG Testing Accuray at 101 iterations is 0.874937717987 with loss: -2084.091531413539\n",
            "SigmoidNAG without QG Testing Accuray at 102 iterations is 0.872944693572 with loss: -2097.556505400636\n",
            "SigmoidNAG without QG Testing Accuray at 103 iterations is 0.869456900847 with loss: -2099.967647921541\n",
            "SigmoidNAG without QG Testing Accuray at 104 iterations is 0.864972595914 with loss: -2099.111778890923\n",
            "SigmoidNAG without QG Testing Accuray at 105 iterations is 0.859990034878 with loss: -2099.357929547587\n",
            "SigmoidNAG without QG Testing Accuray at 106 iterations is 0.856003986049 with loss: -2099.161504849902\n",
            "SigmoidNAG without QG Testing Accuray at 107 iterations is 0.853512705531 with loss: -2093.869112641985\n",
            "SigmoidNAG without QG Testing Accuray at 108 iterations is 0.854509217738 with loss: -2079.012416551404\n",
            "SigmoidNAG without QG Testing Accuray at 109 iterations is 0.853014449427 with loss: -2051.840055654869\n",
            "SigmoidNAG without QG Testing Accuray at 110 iterations is 0.862481315396 with loss: -2011.650977882371\n",
            "SigmoidNAG without QG Testing Accuray at 111 iterations is 0.864474339811 with loss: -1960.200205772257\n",
            "SigmoidNAG without QG Testing Accuray at 112 iterations is 0.871449925262 with loss: -1902.319395781586\n",
            "SigmoidNAG without QG Testing Accuray at 113 iterations is 0.876432486298 with loss: -1845.638871385130\n",
            "SigmoidNAG without QG Testing Accuray at 114 iterations is 0.884404583956 with loss: -1798.638050368807\n",
            "SigmoidNAG without QG Testing Accuray at 115 iterations is 0.884902840060 with loss: -1767.842174902752\n",
            "SigmoidNAG without QG Testing Accuray at 116 iterations is 0.880418535127 with loss: -1755.851826650108\n",
            "SigmoidNAG without QG Testing Accuray at 117 iterations is 0.881913303438 with loss: -1761.117142121172\n",
            "SigmoidNAG without QG Testing Accuray at 118 iterations is 0.876930742402 with loss: -1778.941412213123\n",
            "SigmoidNAG without QG Testing Accuray at 119 iterations is 0.876930742402 with loss: -1802.605423825501\n",
            "SigmoidNAG without QG Testing Accuray at 120 iterations is 0.878425510713 with loss: -1824.403350756735\n",
            "SigmoidNAG without QG Testing Accuray at 121 iterations is 0.876432486298 with loss: -1837.550798820639\n",
            "SigmoidNAG without QG Testing Accuray at 122 iterations is 0.875435974091 with loss: -1839.020833625314\n",
            "SigmoidNAG without QG Testing Accuray at 123 iterations is 0.881415047334 with loss: -1831.051494058889\n",
            "SigmoidNAG without QG Testing Accuray at 124 iterations is 0.883408071749 with loss: -1819.329095014059\n",
            "SigmoidNAG without QG Testing Accuray at 125 iterations is 0.887394120578 with loss: -1809.159649354681\n",
            "SigmoidNAG without QG Testing Accuray at 126 iterations is 0.885899352267 with loss: -1802.732862427142\n",
            "SigmoidNAG without QG Testing Accuray at 127 iterations is 0.887394120578 with loss: -1798.868746674933\n",
            "SigmoidNAG without QG Testing Accuray at 128 iterations is 0.889387144993 with loss: -1794.404779241272\n",
            "SigmoidNAG without QG Testing Accuray at 129 iterations is 0.887892376682 with loss: -1785.873508236199\n",
            "SigmoidNAG without QG Testing Accuray at 130 iterations is 0.884404583956 with loss: -1770.703251630193\n",
            "SigmoidNAG without QG Testing Accuray at 131 iterations is 0.885401096163 with loss: -1747.812930157141\n",
            "SigmoidNAG without QG Testing Accuray at 132 iterations is 0.882909815645 with loss: -1717.797669240487\n",
            "SigmoidNAG without QG Testing Accuray at 133 iterations is 0.883906327853 with loss: -1682.912617985927\n",
            "SigmoidNAG without QG Testing Accuray at 134 iterations is 0.884902840060 with loss: -1646.911486172686\n",
            "SigmoidNAG without QG Testing Accuray at 135 iterations is 0.889885401096 with loss: -1614.651479383373\n",
            "SigmoidNAG without QG Testing Accuray at 136 iterations is 0.892376681614 with loss: -1591.333469966603\n",
            "SigmoidNAG without QG Testing Accuray at 137 iterations is 0.894867962133 with loss: -1581.336337725626\n",
            "SigmoidNAG without QG Testing Accuray at 138 iterations is 0.894867962133 with loss: -1586.817892718771\n",
            "SigmoidNAG without QG Testing Accuray at 139 iterations is 0.891380169407 with loss: -1606.515733634074\n",
            "SigmoidNAG without QG Testing Accuray at 140 iterations is 0.891878425511 with loss: -1635.350697954231\n",
            "SigmoidNAG without QG Testing Accuray at 141 iterations is 0.887892376682 with loss: -1665.369556246124\n",
            "SigmoidNAG without QG Testing Accuray at 142 iterations is 0.885899352267 with loss: -1688.126768814549\n",
            "SigmoidNAG without QG Testing Accuray at 143 iterations is 0.886397608371 with loss: -1697.746172708097\n",
            "SigmoidNAG without QG Testing Accuray at 144 iterations is 0.885899352267 with loss: -1693.102618326923\n",
            "SigmoidNAG without QG Testing Accuray at 145 iterations is 0.885899352267 with loss: -1677.782533409224\n",
            "SigmoidNAG without QG Testing Accuray at 146 iterations is 0.887394120578 with loss: -1657.914144560724\n",
            "SigmoidNAG without QG Testing Accuray at 147 iterations is 0.887892376682 with loss: -1639.336721891510\n",
            "SigmoidNAG without QG Testing Accuray at 148 iterations is 0.890383657200 with loss: -1625.646758741445\n",
            "SigmoidNAG without QG Testing Accuray at 149 iterations is 0.890881913303 with loss: -1617.685118150447\n",
            "SigmoidNAG without QG Testing Accuray at 150 iterations is 0.894867962133 with loss: -1614.121132722917\n",
            "SigmoidNAG without QG Testing Accuray at 151 iterations is 0.896362730443 with loss: -1612.488122165295\n",
            "SigmoidNAG without QG Testing Accuray at 152 iterations is 0.899352267065 with loss: -1610.164167539267\n",
            "SigmoidNAG without QG Testing Accuray at 153 iterations is 0.901345291480 with loss: -1605.062181789023\n",
            "SigmoidNAG without QG Testing Accuray at 154 iterations is 0.903836571998 with loss: -1596.008264867074\n",
            "SigmoidNAG without QG Testing Accuray at 155 iterations is 0.904334828102 with loss: -1582.882377787763\n",
            "SigmoidNAG without QG Testing Accuray at 156 iterations is 0.903836571998 with loss: -1566.593369733991\n",
            "SigmoidNAG without QG Testing Accuray at 157 iterations is 0.904833084205 with loss: -1548.915574414144\n",
            "SigmoidNAG without QG Testing Accuray at 158 iterations is 0.904334828102 with loss: -1532.176285750648\n",
            "SigmoidNAG without QG Testing Accuray at 159 iterations is 0.901843547583 with loss: -1518.782311295935\n",
            "SigmoidNAG without QG Testing Accuray at 160 iterations is 0.904334828102 with loss: -1510.623505713743\n",
            "SigmoidNAG without QG Testing Accuray at 161 iterations is 0.903836571998 with loss: -1508.478104271501\n",
            "SigmoidNAG without QG Testing Accuray at 162 iterations is 0.905331340309 with loss: -1511.627634256787\n",
            "SigmoidNAG without QG Testing Accuray at 163 iterations is 0.906826108620 with loss: -1517.912338576321\n",
            "SigmoidNAG without QG Testing Accuray at 164 iterations is 0.908320876931 with loss: -1524.358848269993\n",
            "SigmoidNAG without QG Testing Accuray at 165 iterations is 0.908819133034 with loss: -1528.248127003181\n",
            "SigmoidNAG without QG Testing Accuray at 166 iterations is 0.909815645242 with loss: -1528.159924643858\n",
            "SigmoidNAG without QG Testing Accuray at 167 iterations is 0.910812157449 with loss: -1524.414725909931\n",
            "SigmoidNAG without QG Testing Accuray at 168 iterations is 0.909815645242 with loss: -1518.648951714484\n",
            "SigmoidNAG without QG Testing Accuray at 169 iterations is 0.911808669656 with loss: -1512.811951432916\n",
            "SigmoidNAG without QG Testing Accuray at 170 iterations is 0.911310413553 with loss: -1508.198566125899\n",
            "SigmoidNAG without QG Testing Accuray at 171 iterations is 0.909317389138 with loss: -1504.995333805887\n",
            "SigmoidNAG without QG Testing Accuray at 172 iterations is 0.908320876931 with loss: -1502.426275999290\n",
            "SigmoidNAG without QG Testing Accuray at 173 iterations is 0.906826108620 with loss: -1499.271057830835\n",
            "SigmoidNAG without QG Testing Accuray at 174 iterations is 0.904833084205 with loss: -1494.438698459030\n",
            "SigmoidNAG without QG Testing Accuray at 175 iterations is 0.904334828102 with loss: -1487.362778184212\n",
            "SigmoidNAG without QG Testing Accuray at 176 iterations is 0.905331340309 with loss: -1478.133615297709\n",
            "SigmoidNAG without QG Testing Accuray at 177 iterations is 0.908320876931 with loss: -1467.412661009892\n",
            "SigmoidNAG without QG Testing Accuray at 178 iterations is 0.908320876931 with loss: -1456.236845023021\n",
            "SigmoidNAG without QG Testing Accuray at 179 iterations is 0.907822620827 with loss: -1445.811692082890\n",
            "SigmoidNAG without QG Testing Accuray at 180 iterations is 0.907822620827 with loss: -1437.341726959454\n",
            "SigmoidNAG without QG Testing Accuray at 181 iterations is 0.906826108620 with loss: -1431.893854558750\n",
            "SigmoidNAG without QG Testing Accuray at 182 iterations is 0.908320876931 with loss: -1430.262453294764\n",
            "SigmoidNAG without QG Testing Accuray at 183 iterations is 0.909317389138 with loss: -1432.813230701982\n",
            "SigmoidNAG without QG Testing Accuray at 184 iterations is 0.906327852516 with loss: -1439.318268629619\n",
            "SigmoidNAG without QG Testing Accuray at 185 iterations is 0.905331340309 with loss: -1448.837931110473\n",
            "SigmoidNAG without QG Testing Accuray at 186 iterations is 0.901843547583 with loss: -1459.734043505380\n",
            "SigmoidNAG without QG Testing Accuray at 187 iterations is 0.901843547583 with loss: -1469.890583855448\n",
            "SigmoidNAG without QG Testing Accuray at 188 iterations is 0.901843547583 with loss: -1477.154675277793\n",
            "SigmoidNAG without QG Testing Accuray at 189 iterations is 0.902341803687 with loss: -1479.896352970363\n",
            "SigmoidNAG without QG Testing Accuray at 190 iterations is 0.899352267065 with loss: -1477.479060459917\n",
            "SigmoidNAG without QG Testing Accuray at 191 iterations is 0.899850523169 with loss: -1470.424874801293\n",
            "SigmoidNAG without QG Testing Accuray at 192 iterations is 0.901843547583 with loss: -1460.189645995359\n",
            "SigmoidNAG without QG Testing Accuray at 193 iterations is 0.904833084205 with loss: -1448.656793577352\n",
            "SigmoidNAG without QG Testing Accuray at 194 iterations is 0.906327852516 with loss: -1437.578481668408\n",
            "SigmoidNAG without QG Testing Accuray at 195 iterations is 0.905829596413 with loss: -1428.169520999719\n",
            "SigmoidNAG without QG Testing Accuray at 196 iterations is 0.903836571998 with loss: -1420.941390267909\n",
            "SigmoidNAG without QG Testing Accuray at 197 iterations is 0.902840059791 with loss: -1415.749157888745\n",
            "SigmoidNAG without QG Testing Accuray at 198 iterations is 0.901843547583 with loss: -1411.969207192912\n",
            "SigmoidNAG without QG Testing Accuray at 199 iterations is 0.901843547583 with loss: -1408.726180712757\n",
            "SigmoidNAG without QG Testing Accuray at 200 iterations is 0.899850523169 with loss: -1405.113694873727\n",
            "SigmoidNAG without QG Testing Accuray at 201 iterations is 0.900348779273 with loss: -1400.380368202212\n",
            "SigmoidNAG without QG Testing Accuray at 202 iterations is 0.902341803687 with loss: -1394.069519227352\n",
            "SigmoidNAG without QG Testing Accuray at 203 iterations is 0.903338315894 with loss: -1386.106147842188\n",
            "SigmoidNAG without QG Testing Accuray at 204 iterations is 0.905829596413 with loss: -1376.823689444084\n",
            "SigmoidNAG without QG Testing Accuray at 205 iterations is 0.906327852516 with loss: -1366.922597549953\n",
            "SigmoidNAG without QG Testing Accuray at 206 iterations is 0.908819133034 with loss: -1357.358575255647\n",
            "SigmoidNAG without QG Testing Accuray at 207 iterations is 0.909815645242 with loss: -1349.170970772934\n",
            "SigmoidNAG without QG Testing Accuray at 208 iterations is 0.912805181863 with loss: -1343.277704170661\n",
            "SigmoidNAG without QG Testing Accuray at 209 iterations is 0.912805181863 with loss: -1340.276169096583\n",
            "SigmoidNAG without QG Testing Accuray at 210 iterations is 0.913303437967 with loss: -1340.294927911805\n",
            "SigmoidNAG without QG Testing Accuray at 211 iterations is 0.911808669656 with loss: -1342.936885904848\n",
            "SigmoidNAG without QG Testing Accuray at 212 iterations is 0.912805181863 with loss: -1347.340188365486\n",
            "SigmoidNAG without QG Testing Accuray at 213 iterations is 0.912306925760 with loss: -1352.357179775576\n",
            "SigmoidNAG without QG Testing Accuray at 214 iterations is 0.911808669656 with loss: -1356.815403920620\n",
            "SigmoidNAG without QG Testing Accuray at 215 iterations is 0.909815645242 with loss: -1359.788433721462\n",
            "SigmoidNAG without QG Testing Accuray at 216 iterations is 0.908819133034 with loss: -1360.789105502055\n",
            "SigmoidNAG without QG Testing Accuray at 217 iterations is 0.908819133034 with loss: -1359.820908811307\n",
            "SigmoidNAG without QG Testing Accuray at 218 iterations is 0.909815645242 with loss: -1357.279874006467\n",
            "SigmoidNAG without QG Testing Accuray at 219 iterations is 0.910812157449 with loss: -1353.759250448930\n",
            "SigmoidNAG without QG Testing Accuray at 220 iterations is 0.909815645242 with loss: -1349.839181771050\n",
            "SigmoidNAG without QG Testing Accuray at 221 iterations is 0.909317389138 with loss: -1345.931744099501\n",
            "SigmoidNAG without QG Testing Accuray at 222 iterations is 0.911310413553 with loss: -1342.213766106877\n",
            "SigmoidNAG without QG Testing Accuray at 223 iterations is 0.911310413553 with loss: -1338.641593006223\n",
            "SigmoidNAG without QG Testing Accuray at 224 iterations is 0.912805181863 with loss: -1335.019836604835\n",
            "SigmoidNAG without QG Testing Accuray at 225 iterations is 0.913303437967 with loss: -1331.091727885091\n",
            "SigmoidNAG without QG Testing Accuray at 226 iterations is 0.913801694071 with loss: -1326.625242678246\n",
            "SigmoidNAG without QG Testing Accuray at 227 iterations is 0.914299950174 with loss: -1321.479111315815\n",
            "SigmoidNAG without QG Testing Accuray at 228 iterations is 0.913801694071 with loss: -1315.641877926493\n",
            "SigmoidNAG without QG Testing Accuray at 229 iterations is 0.913303437967 with loss: -1309.243492999343\n",
            "SigmoidNAG without QG Testing Accuray at 230 iterations is 0.913303437967 with loss: -1302.542532891434\n",
            "SigmoidNAG without QG Testing Accuray at 231 iterations is 0.913801694071 with loss: -1295.893538386278\n",
            "SigmoidNAG without QG Testing Accuray at 232 iterations is 0.912805181863 with loss: -1289.699465705692\n",
            "SigmoidNAG without QG Testing Accuray at 233 iterations is 0.913801694071 with loss: -1284.354646188350\n",
            "SigmoidNAG without QG Testing Accuray at 234 iterations is 0.912306925760 with loss: -1280.184491903361\n",
            "SigmoidNAG without QG Testing Accuray at 235 iterations is 0.913303437967 with loss: -1277.389476310786\n",
            "SigmoidNAG without QG Testing Accuray at 236 iterations is 0.913303437967 with loss: -1276.002023628928\n",
            "SigmoidNAG without QG Testing Accuray at 237 iterations is 0.913801694071 with loss: -1275.865205639057\n",
            "SigmoidNAG without QG Testing Accuray at 238 iterations is 0.912805181863 with loss: -1276.640995904835\n",
            "SigmoidNAG without QG Testing Accuray at 239 iterations is 0.912805181863 with loss: -1277.852588447415\n",
            "SigmoidNAG without QG Testing Accuray at 240 iterations is 0.911808669656 with loss: -1278.959445658300\n",
            "SigmoidNAG without QG Testing Accuray at 241 iterations is 0.911310413553 with loss: -1279.455151323414\n",
            "SigmoidNAG without QG Testing Accuray at 242 iterations is 0.910812157449 with loss: -1278.968614236827\n",
            "SigmoidNAG without QG Testing Accuray at 243 iterations is 0.911310413553 with loss: -1277.342823632986\n",
            "SigmoidNAG without QG Testing Accuray at 244 iterations is 0.911808669656 with loss: -1274.667161790495\n",
            "SigmoidNAG without QG Testing Accuray at 245 iterations is 0.912306925760 with loss: -1271.251122024443\n",
            "SigmoidNAG without QG Testing Accuray at 246 iterations is 0.912306925760 with loss: -1267.545645722249\n",
            "SigmoidNAG without QG Testing Accuray at 247 iterations is 0.913801694071 with loss: -1264.035058933846\n",
            "SigmoidNAG without QG Testing Accuray at 248 iterations is 0.914798206278 with loss: -1261.130201782107\n",
            "SigmoidNAG without QG Testing Accuray at 249 iterations is 0.914798206278 with loss: -1259.089283804822\n",
            "SigmoidNAG without QG Testing Accuray at 250 iterations is 0.914798206278 with loss: -1257.980841860750\n",
            "SigmoidNAG without QG Testing Accuray at 251 iterations is 0.915794718485 with loss: -1257.689378782493\n",
            "SigmoidNAG without QG Testing Accuray at 252 iterations is 0.915296462382 with loss: -1257.954077485366\n",
            "SigmoidNAG without QG Testing Accuray at 253 iterations is 0.913801694071 with loss: -1258.426473557425\n",
            "SigmoidNAG without QG Testing Accuray at 254 iterations is 0.914299950174 with loss: -1258.733295901208\n",
            "SigmoidNAG without QG Testing Accuray at 255 iterations is 0.912805181863 with loss: -1258.533805687524\n",
            "SigmoidNAG without QG Testing Accuray at 256 iterations is 0.913303437967 with loss: -1257.564948141875\n",
            "SigmoidNAG without QG Testing Accuray at 257 iterations is 0.914299950174 with loss: -1255.671320787651\n",
            "SigmoidNAG without QG Testing Accuray at 258 iterations is 0.916292974589 with loss: -1252.819548723652\n",
            "SigmoidNAG without QG Testing Accuray at 259 iterations is 0.916791230693 with loss: -1249.098208928813\n",
            "SigmoidNAG without QG Testing Accuray at 260 iterations is 0.917289486796 with loss: -1244.705074785246\n",
            "SigmoidNAG without QG Testing Accuray at 261 iterations is 0.918285999003 with loss: -1239.923603857682\n",
            "SigmoidNAG without QG Testing Accuray at 262 iterations is 0.917787742900 with loss: -1235.090696936732\n",
            "SigmoidNAG without QG Testing Accuray at 263 iterations is 0.917289486796 with loss: -1230.558100490183\n",
            "SigmoidNAG without QG Testing Accuray at 264 iterations is 0.917289486796 with loss: -1226.650512410904\n",
            "SigmoidNAG without QG Testing Accuray at 265 iterations is 0.916292974589 with loss: -1223.624380521970\n",
            "SigmoidNAG without QG Testing Accuray at 266 iterations is 0.916791230693 with loss: -1221.632247951501\n",
            "SigmoidNAG without QG Testing Accuray at 267 iterations is 0.916791230693 with loss: -1220.698026820735\n",
            "SigmoidNAG without QG Testing Accuray at 268 iterations is 0.916791230693 with loss: -1220.708283754117\n",
            "SigmoidNAG without QG Testing Accuray at 269 iterations is 0.917787742900 with loss: -1221.423187047905\n",
            "SigmoidNAG without QG Testing Accuray at 270 iterations is 0.917289486796 with loss: -1222.507940173139\n",
            "SigmoidNAG without QG Testing Accuray at 271 iterations is 0.917289486796 with loss: -1223.581487515552\n",
            "SigmoidNAG without QG Testing Accuray at 272 iterations is 0.917787742900 with loss: -1224.274908074921\n",
            "SigmoidNAG without QG Testing Accuray at 273 iterations is 0.919282511211 with loss: -1224.288612703162\n",
            "SigmoidNAG without QG Testing Accuray at 274 iterations is 0.918285999003 with loss: -1223.436729946289\n",
            "SigmoidNAG without QG Testing Accuray at 275 iterations is 0.917787742900 with loss: -1221.669672664337\n",
            "SigmoidNAG without QG Testing Accuray at 276 iterations is 0.918784255107 with loss: -1219.071220268923\n",
            "SigmoidNAG without QG Testing Accuray at 277 iterations is 0.919282511211 with loss: -1215.832746193044\n",
            "SigmoidNAG without QG Testing Accuray at 278 iterations is 0.919780767314 with loss: -1212.212258315456\n",
            "SigmoidNAG without QG Testing Accuray at 279 iterations is 0.918784255107 with loss: -1208.488204894176\n",
            "SigmoidNAG without QG Testing Accuray at 280 iterations is 0.917787742900 with loss: -1204.917299364086\n",
            "SigmoidNAG without QG Testing Accuray at 281 iterations is 0.917289486796 with loss: -1201.702841547638\n",
            "SigmoidNAG without QG Testing Accuray at 282 iterations is 0.918784255107 with loss: -1198.976525732416\n",
            "SigmoidNAG without QG Testing Accuray at 283 iterations is 0.918285999003 with loss: -1196.793644467410\n",
            "SigmoidNAG without QG Testing Accuray at 284 iterations is 0.919282511211 with loss: -1195.139484382620\n",
            "SigmoidNAG without QG Testing Accuray at 285 iterations is 0.919282511211 with loss: -1193.943647311446\n",
            "SigmoidNAG without QG Testing Accuray at 286 iterations is 0.918784255107 with loss: -1193.098774672673\n",
            "SigmoidNAG without QG Testing Accuray at 287 iterations is 0.918285999003 with loss: -1192.480466168608\n",
            "SigmoidNAG without QG Testing Accuray at 288 iterations is 0.918784255107 with loss: -1191.965811020307\n",
            "SigmoidNAG without QG Testing Accuray at 289 iterations is 0.918784255107 with loss: -1191.448685734742\n",
            "SigmoidNAG without QG Testing Accuray at 290 iterations is 0.920279023418 with loss: -1190.850719156372\n",
            "SigmoidNAG without QG Testing Accuray at 291 iterations is 0.919282511211 with loss: -1190.127446165446\n",
            "SigmoidNAG without QG Testing Accuray at 292 iterations is 0.918285999003 with loss: -1189.269645268888\n",
            "SigmoidNAG without QG Testing Accuray at 293 iterations is 0.918285999003 with loss: -1188.300204910653\n",
            "SigmoidNAG without QG Testing Accuray at 294 iterations is 0.919780767314 with loss: -1187.267127937183\n",
            "SigmoidNAG without QG Testing Accuray at 295 iterations is 0.918784255107 with loss: -1186.233510735570\n",
            "SigmoidNAG without QG Testing Accuray at 296 iterations is 0.918285999003 with loss: -1185.265570296531\n",
            "SigmoidNAG without QG Testing Accuray at 297 iterations is 0.917289486796 with loss: -1184.420050564423\n",
            "SigmoidNAG without QG Testing Accuray at 298 iterations is 0.916292974589 with loss: -1183.732585287240\n",
            "SigmoidNAG without QG Testing Accuray at 299 iterations is 0.917787742900 with loss: -1183.208743861458\n",
            "SigmoidNAG without QG Testing Accuray at 300 iterations is 0.918285999003 with loss: -1182.819443966874\n",
            "SigmoidNAG without QG Testing Accuray at 301 iterations is 0.917289486796 with loss: -1182.502064891605\n",
            "SigmoidNAG without QG Testing Accuray at 302 iterations is 0.919282511211 with loss: -1182.167843868816\n",
            "SigmoidNAG without QG Testing Accuray at 303 iterations is 0.918784255107 with loss: -1181.715018512888\n",
            "SigmoidNAG without QG Testing Accuray at 304 iterations is 0.918784255107 with loss: -1181.045852880731\n",
            "SigmoidNAG without QG Testing Accuray at 305 iterations is 0.917289486796 with loss: -1180.084508425868\n",
            "SigmoidNAG without QG Testing Accuray at 306 iterations is 0.916791230693 with loss: -1178.792096062329\n",
            "SigmoidNAG without QG Testing Accuray at 307 iterations is 0.918285999003 with loss: -1177.175510655354\n",
            "SigmoidNAG without QG Testing Accuray at 308 iterations is 0.918285999003 with loss: -1175.287854813312\n",
            "SigmoidNAG without QG Testing Accuray at 309 iterations is 0.918784255107 with loss: -1173.220153714184\n",
            "SigmoidNAG without QG Testing Accuray at 310 iterations is 0.917787742900 with loss: -1171.086079267244\n",
            "SigmoidNAG without QG Testing Accuray at 311 iterations is 0.918784255107 with loss: -1169.002936128553\n",
            "SigmoidNAG without QG Testing Accuray at 312 iterations is 0.918784255107 with loss: -1167.072805073694\n",
            "SigmoidNAG without QG Testing Accuray at 313 iterations is 0.919282511211 with loss: -1165.367383394836\n",
            "SigmoidNAG without QG Testing Accuray at 314 iterations is 0.920279023418 with loss: -1163.918932156879\n",
            "SigmoidNAG without QG Testing Accuray at 315 iterations is 0.920279023418 with loss: -1162.718255858621\n",
            "SigmoidNAG without QG Testing Accuray at 316 iterations is 0.919282511211 with loss: -1161.719227397478\n",
            "SigmoidNAG without QG Testing Accuray at 317 iterations is 0.919282511211 with loss: -1160.848313724665\n",
            "SigmoidNAG without QG Testing Accuray at 318 iterations is 0.919780767314 with loss: -1160.017004498269\n",
            "SigmoidNAG without QG Testing Accuray at 319 iterations is 0.921275535625 with loss: -1159.134978030238\n",
            "SigmoidNAG without QG Testing Accuray at 320 iterations is 0.920777279522 with loss: -1158.122130597194\n",
            "SigmoidNAG without QG Testing Accuray at 321 iterations is 0.921275535625 with loss: -1156.918127535045\n",
            "SigmoidNAG without QG Testing Accuray at 322 iterations is 0.921275535625 with loss: -1155.488717887797\n",
            "SigmoidNAG without QG Testing Accuray at 323 iterations is 0.922272047833 with loss: -1153.828612898091\n",
            "SigmoidNAG without QG Testing Accuray at 324 iterations is 0.922272047833 with loss: -1151.961139206982\n",
            "SigmoidNAG without QG Testing Accuray at 325 iterations is 0.922770303936 with loss: -1149.935146162773\n",
            "SigmoidNAG without QG Testing Accuray at 326 iterations is 0.922770303936 with loss: -1147.819766258353\n",
            "SigmoidNAG without QG Testing Accuray at 327 iterations is 0.923268560040 with loss: -1145.697641256370\n",
            "SigmoidNAG without QG Testing Accuray at 328 iterations is 0.923268560040 with loss: -1143.657192730072\n",
            "SigmoidNAG without QG Testing Accuray at 329 iterations is 0.922272047833 with loss: -1141.784472688507\n",
            "SigmoidNAG without QG Testing Accuray at 330 iterations is 0.922272047833 with loss: -1140.155119533881\n",
            "SigmoidNAG without QG Testing Accuray at 331 iterations is 0.923766816143 with loss: -1138.826953046445\n",
            "SigmoidNAG without QG Testing Accuray at 332 iterations is 0.924265072247 with loss: -1137.833783121559\n",
            "SigmoidNAG without QG Testing Accuray at 333 iterations is 0.924763328351 with loss: -1137.181028052172\n",
            "SigmoidNAG without QG Testing Accuray at 334 iterations is 0.924763328351 with loss: -1136.843721808672\n",
            "SigmoidNAG without QG Testing Accuray at 335 iterations is 0.925261584454 with loss: -1136.767395386283\n",
            "SigmoidNAG without QG Testing Accuray at 336 iterations is 0.924763328351 with loss: -1136.872111908242\n",
            "SigmoidNAG without QG Testing Accuray at 337 iterations is 0.925261584454 with loss: -1137.059610541718\n",
            "SigmoidNAG without QG Testing Accuray at 338 iterations is 0.925261584454 with loss: -1137.223085362545\n",
            "SigmoidNAG without QG Testing Accuray at 339 iterations is 0.924763328351 with loss: -1137.258658472224\n",
            "SigmoidNAG without QG Testing Accuray at 340 iterations is 0.925261584454 with loss: -1137.077195979929\n",
            "SigmoidNAG without QG Testing Accuray at 341 iterations is 0.925759840558 with loss: -1136.614877663165\n",
            "SigmoidNAG without QG Testing Accuray at 342 iterations is 0.926258096662 with loss: -1135.840961606120\n",
            "SigmoidNAG without QG Testing Accuray at 343 iterations is 0.926756352765 with loss: -1134.761528144984\n",
            "SigmoidNAG without QG Testing Accuray at 344 iterations is 0.926756352765 with loss: -1133.418592249478\n",
            "SigmoidNAG without QG Testing Accuray at 345 iterations is 0.927254608869 with loss: -1131.884717457790\n",
            "SigmoidNAG without QG Testing Accuray at 346 iterations is 0.926258096662 with loss: -1130.253976039809\n",
            "SigmoidNAG without QG Testing Accuray at 347 iterations is 0.925759840558 with loss: -1128.630625176103\n",
            "SigmoidNAG without QG Testing Accuray at 348 iterations is 0.926756352765 with loss: -1127.117103110115\n",
            "SigmoidNAG without QG Testing Accuray at 349 iterations is 0.926756352765 with loss: -1125.802886778743\n",
            "SigmoidNAG without QG Testing Accuray at 350 iterations is 0.926756352765 with loss: -1124.755449984350\n",
            "SigmoidNAG without QG Testing Accuray at 351 iterations is 0.927752864973 with loss: -1124.014134567821\n",
            "SigmoidNAG without QG Testing Accuray at 352 iterations is 0.926756352765 with loss: -1123.587292075961\n",
            "SigmoidNAG without QG Testing Accuray at 353 iterations is 0.924763328351 with loss: -1123.452655133825\n",
            "SigmoidNAG without QG Testing Accuray at 354 iterations is 0.924265072247 with loss: -1123.560590718500\n",
            "SigmoidNAG without QG Testing Accuray at 355 iterations is 0.923766816143 with loss: -1123.839690431678\n",
            "SigmoidNAG without QG Testing Accuray at 356 iterations is 0.923766816143 with loss: -1124.204029379843\n",
            "SigmoidNAG without QG Testing Accuray at 357 iterations is 0.924265072247 with loss: -1124.561374939472\n",
            "SigmoidNAG without QG Testing Accuray at 358 iterations is 0.924763328351 with loss: -1124.821614886550\n",
            "SigmoidNAG without QG Testing Accuray at 359 iterations is 0.925261584454 with loss: -1124.904707702668\n",
            "SigmoidNAG without QG Testing Accuray at 360 iterations is 0.925261584454 with loss: -1124.747511556610\n",
            "SigmoidNAG without QG Testing Accuray at 361 iterations is 0.925261584454 with loss: -1124.308946515383\n",
            "SigmoidNAG without QG Testing Accuray at 362 iterations is 0.924265072247 with loss: -1123.573078839348\n",
            "SigmoidNAG without QG Testing Accuray at 363 iterations is 0.925261584454 with loss: -1122.549882333645\n",
            "SigmoidNAG without QG Testing Accuray at 364 iterations is 0.925261584454 with loss: -1121.273626989294\n",
            "SigmoidNAG without QG Testing Accuray at 365 iterations is 0.925261584454 with loss: -1119.799051852010\n",
            "SigmoidNAG without QG Testing Accuray at 366 iterations is 0.925759840558 with loss: -1118.195682599075\n",
            "SigmoidNAG without QG Testing Accuray at 367 iterations is 0.924763328351 with loss: -1116.540829026919\n",
            "SigmoidNAG without QG Testing Accuray at 368 iterations is 0.925261584454 with loss: -1114.911923261639\n",
            "SigmoidNAG without QG Testing Accuray at 369 iterations is 0.924763328351 with loss: -1113.378932077956\n",
            "SigmoidNAG without QG Testing Accuray at 370 iterations is 0.924265072247 with loss: -1111.997577273216\n",
            "SigmoidNAG without QG Testing Accuray at 371 iterations is 0.923766816143 with loss: -1110.804030800296\n",
            "SigmoidNAG without QG Testing Accuray at 372 iterations is 0.923268560040 with loss: -1109.811620841600\n",
            "SigmoidNAG without QG Testing Accuray at 373 iterations is 0.922770303936 with loss: -1109.009900200322\n",
            "SigmoidNAG without QG Testing Accuray at 374 iterations is 0.922770303936 with loss: -1108.366196861413\n",
            "SigmoidNAG without QG Testing Accuray at 375 iterations is 0.922770303936 with loss: -1107.829508195263\n",
            "SigmoidNAG without QG Testing Accuray at 376 iterations is 0.922770303936 with loss: -1107.336338340511\n",
            "SigmoidNAG without QG Testing Accuray at 377 iterations is 0.922770303936 with loss: -1106.817837776770\n",
            "SigmoidNAG without QG Testing Accuray at 378 iterations is 0.922770303936 with loss: -1106.207429656852\n",
            "SigmoidNAG without QG Testing Accuray at 379 iterations is 0.922770303936 with loss: -1105.448030307618\n",
            "SigmoidNAG without QG Testing Accuray at 380 iterations is 0.923268560040 with loss: -1104.498017026364\n",
            "SigmoidNAG without QG Testing Accuray at 381 iterations is 0.923268560040 with loss: -1103.335260502890\n",
            "SigmoidNAG without QG Testing Accuray at 382 iterations is 0.923766816143 with loss: -1101.958817469105\n",
            "SigmoidNAG without QG Testing Accuray at 383 iterations is 0.924265072247 with loss: -1100.388204499294\n",
            "SigmoidNAG without QG Testing Accuray at 384 iterations is 0.924265072247 with loss: -1098.660500419145\n",
            "SigmoidNAG without QG Testing Accuray at 385 iterations is 0.924763328351 with loss: -1096.825789503918\n",
            "SigmoidNAG without QG Testing Accuray at 386 iterations is 0.926258096662 with loss: -1094.941620593666\n",
            "SigmoidNAG without QG Testing Accuray at 387 iterations is 0.926258096662 with loss: -1093.067200568676\n",
            "SigmoidNAG without QG Testing Accuray at 388 iterations is 0.926756352765 with loss: -1091.257976499276\n",
            "SigmoidNAG without QG Testing Accuray at 389 iterations is 0.928251121076 with loss: -1089.561119516226\n",
            "SigmoidNAG without QG Testing Accuray at 390 iterations is 0.928251121076 with loss: -1088.012242108843\n",
            "SigmoidNAG without QG Testing Accuray at 391 iterations is 0.928749377180 with loss: -1086.633493414120\n",
            "SigmoidNAG without QG Testing Accuray at 392 iterations is 0.929247633284 with loss: -1085.433016945909\n",
            "SigmoidNAG without QG Testing Accuray at 393 iterations is 0.927752864973 with loss: -1084.405630281374\n",
            "SigmoidNAG without QG Testing Accuray at 394 iterations is 0.928251121076 with loss: -1083.534503855610\n",
            "SigmoidNAG without QG Testing Accuray at 395 iterations is 0.927752864973 with loss: -1082.793574210071\n",
            "SigmoidNAG without QG Testing Accuray at 396 iterations is 0.928251121076 with loss: -1082.150415463070\n",
            "SigmoidNAG without QG Testing Accuray at 397 iterations is 0.928251121076 with loss: -1081.569304221858\n",
            "SigmoidNAG without QG Testing Accuray at 398 iterations is 0.928749377180 with loss: -1081.014238768040\n",
            "SigmoidNAG without QG Testing Accuray at 399 iterations is 0.929745889387 with loss: -1080.451710972955\n",
            "SigmoidNAG without QG Testing Accuray at 400 iterations is 0.930742401594 with loss: -1079.853067487189\n",
            "SigmoidNAG without QG Testing Accuray at 401 iterations is 0.930742401594 with loss: -1079.196338883592\n",
            "SigmoidNAG without QG Testing Accuray at 402 iterations is 0.930742401594 with loss: -1078.467455925178\n",
            "SigmoidNAG without QG Testing Accuray at 403 iterations is 0.930742401594 with loss: -1077.660809619677\n",
            "SigmoidNAG without QG Testing Accuray at 404 iterations is 0.929247633284 with loss: -1076.779149361553\n",
            "SigmoidNAG without QG Testing Accuray at 405 iterations is 0.929247633284 with loss: -1075.832849051643\n",
            "SigmoidNAG without QG Testing Accuray at 406 iterations is 0.928749377180 with loss: -1074.838606142175\n",
            "SigmoidNAG without QG Testing Accuray at 407 iterations is 0.929247633284 with loss: -1073.817672083025\n",
            "SigmoidNAG without QG Testing Accuray at 408 iterations is 0.929247633284 with loss: -1072.793747627518\n",
            "SigmoidNAG without QG Testing Accuray at 409 iterations is 0.929247633284 with loss: -1071.790706727694\n",
            "SigmoidNAG without QG Testing Accuray at 410 iterations is 0.929745889387 with loss: -1070.830338972819\n",
            "SigmoidNAG without QG Testing Accuray at 411 iterations is 0.930244145491 with loss: -1069.930312871870\n",
            "SigmoidNAG without QG Testing Accuray at 412 iterations is 0.930742401594 with loss: -1069.102560248449\n",
            "SigmoidNAG without QG Testing Accuray at 413 iterations is 0.930244145491 with loss: -1068.352258460610\n",
            "SigmoidNAG without QG Testing Accuray at 414 iterations is 0.930742401594 with loss: -1067.677539230152\n",
            "SigmoidNAG without QG Testing Accuray at 415 iterations is 0.930742401594 with loss: -1067.069978844316\n",
            "SigmoidNAG without QG Testing Accuray at 416 iterations is 0.931738913802 with loss: -1066.515833923186\n",
            "SigmoidNAG without QG Testing Accuray at 417 iterations is 0.932237169905 with loss: -1065.997888373143\n",
            "SigmoidNAG without QG Testing Accuray at 418 iterations is 0.933731938216 with loss: -1065.497688217364\n",
            "SigmoidNAG without QG Testing Accuray at 419 iterations is 0.933233682113 with loss: -1064.997874434277\n",
            "SigmoidNAG without QG Testing Accuray at 420 iterations is 0.933233682113 with loss: -1064.484300377624\n",
            "SigmoidNAG without QG Testing Accuray at 421 iterations is 0.933731938216 with loss: -1063.947642838125\n",
            "SigmoidNAG without QG Testing Accuray at 422 iterations is 0.932735426009 with loss: -1063.384285875644\n",
            "SigmoidNAG without QG Testing Accuray at 423 iterations is 0.932237169905 with loss: -1062.796362660504\n",
            "SigmoidNAG without QG Testing Accuray at 424 iterations is 0.933233682113 with loss: -1062.190965117104\n",
            "SigmoidNAG without QG Testing Accuray at 425 iterations is 0.931738913802 with loss: -1061.578649692142\n",
            "SigmoidNAG without QG Testing Accuray at 426 iterations is 0.930742401594 with loss: -1060.971464921916\n",
            "SigmoidNAG without QG Testing Accuray at 427 iterations is 0.930742401594 with loss: -1060.380779959446\n",
            "SigmoidNAG without QG Testing Accuray at 428 iterations is 0.930742401594 with loss: -1059.815205935180\n",
            "SigmoidNAG without QG Testing Accuray at 429 iterations is 0.930742401594 with loss: -1059.278869892982\n",
            "SigmoidNAG without QG Testing Accuray at 430 iterations is 0.930742401594 with loss: -1058.770242405673\n",
            "SigmoidNAG without QG Testing Accuray at 431 iterations is 0.931240657698 with loss: -1058.281636125856\n",
            "SigmoidNAG without QG Testing Accuray at 432 iterations is 0.930742401594 with loss: -1057.799409383477\n",
            "SigmoidNAG without QG Testing Accuray at 433 iterations is 0.930244145491 with loss: -1057.304832195329\n",
            "SigmoidNAG without QG Testing Accuray at 434 iterations is 0.930244145491 with loss: -1056.775508663583\n",
            "SigmoidNAG without QG Testing Accuray at 435 iterations is 0.929247633284 with loss: -1056.187205259972\n",
            "SigmoidNAG without QG Testing Accuray at 436 iterations is 0.929247633284 with loss: -1055.515909875528\n",
            "SigmoidNAG without QG Testing Accuray at 437 iterations is 0.928749377180 with loss: -1054.739939098871\n",
            "SigmoidNAG without QG Testing Accuray at 438 iterations is 0.928749377180 with loss: -1053.841919054893\n",
            "SigmoidNAG without QG Testing Accuray at 439 iterations is 0.928749377180 with loss: -1052.810483737550\n",
            "SigmoidNAG without QG Testing Accuray at 440 iterations is 0.929745889387 with loss: -1051.641562889379\n",
            "SigmoidNAG without QG Testing Accuray at 441 iterations is 0.930244145491 with loss: -1050.339165046421\n",
            "SigmoidNAG without QG Testing Accuray at 442 iterations is 0.929247633284 with loss: -1048.915598045159\n",
            "SigmoidNAG without QG Testing Accuray at 443 iterations is 0.930244145491 with loss: -1047.391108706320\n",
            "SigmoidNAG without QG Testing Accuray at 444 iterations is 0.930244145491 with loss: -1045.792959179454\n",
            "SigmoidNAG without QG Testing Accuray at 445 iterations is 0.930244145491 with loss: -1044.153995700344\n",
            "SigmoidNAG without QG Testing Accuray at 446 iterations is 0.929745889387 with loss: -1042.510797450138\n",
            "SigmoidNAG without QG Testing Accuray at 447 iterations is 0.929745889387 with loss: -1040.901521419789\n",
            "SigmoidNAG without QG Testing Accuray at 448 iterations is 0.930244145491 with loss: -1039.363582592268\n",
            "SigmoidNAG without QG Testing Accuray at 449 iterations is 0.929745889387 with loss: -1037.931323311084\n",
            "SigmoidNAG without QG Testing Accuray at 450 iterations is 0.929247633284 with loss: -1036.633831062620\n",
            "SigmoidNAG without QG Testing Accuray at 451 iterations is 0.929745889387 with loss: -1035.493061761112\n",
            "SigmoidNAG without QG Testing Accuray at 452 iterations is 0.928749377180 with loss: -1034.522410504931\n",
            "SigmoidNAG without QG Testing Accuray at 453 iterations is 0.928749377180 with loss: -1033.725846056585\n",
            "SigmoidNAG without QG Testing Accuray at 454 iterations is 0.929247633284 with loss: -1033.097689894735\n",
            "SigmoidNAG without QG Testing Accuray at 455 iterations is 0.931738913802 with loss: -1032.623076026468\n",
            "SigmoidNAG without QG Testing Accuray at 456 iterations is 0.932735426009 with loss: -1032.279076522155\n",
            "SigmoidNAG without QG Testing Accuray at 457 iterations is 0.932237169905 with loss: -1032.036424022326\n",
            "SigmoidNAG without QG Testing Accuray at 458 iterations is 0.932237169905 with loss: -1031.861709369349\n",
            "SigmoidNAG without QG Testing Accuray at 459 iterations is 0.932735426009 with loss: -1031.719887714080\n",
            "SigmoidNAG without QG Testing Accuray at 460 iterations is 0.933233682113 with loss: -1031.576892422712\n",
            "SigmoidNAG without QG Testing Accuray at 461 iterations is 0.932735426009 with loss: -1031.402138620567\n",
            "SigmoidNAG without QG Testing Accuray at 462 iterations is 0.933233682113 with loss: -1031.170702276376\n",
            "SigmoidNAG without QG Testing Accuray at 463 iterations is 0.932735426009 with loss: -1030.864986964659\n",
            "SigmoidNAG without QG Testing Accuray at 464 iterations is 0.932735426009 with loss: -1030.475735931414\n",
            "SigmoidNAG without QG Testing Accuray at 465 iterations is 0.933233682113 with loss: -1030.002310349028\n",
            "SigmoidNAG without QG Testing Accuray at 466 iterations is 0.932735426009 with loss: -1029.452225578459\n",
            "SigmoidNAG without QG Testing Accuray at 467 iterations is 0.932735426009 with loss: -1028.840009920625\n",
            "SigmoidNAG without QG Testing Accuray at 468 iterations is 0.932735426009 with loss: -1028.185514077505\n",
            "SigmoidNAG without QG Testing Accuray at 469 iterations is 0.932735426009 with loss: -1027.511846398432\n",
            "SigmoidNAG without QG Testing Accuray at 470 iterations is 0.932237169905 with loss: -1026.843136032078\n",
            "SigmoidNAG without QG Testing Accuray at 471 iterations is 0.932237169905 with loss: -1026.202328438185\n",
            "SigmoidNAG without QG Testing Accuray at 472 iterations is 0.932237169905 with loss: -1025.609200919354\n",
            "SigmoidNAG without QG Testing Accuray at 473 iterations is 0.933731938216 with loss: -1025.078749827498\n",
            "SigmoidNAG without QG Testing Accuray at 474 iterations is 0.933731938216 with loss: -1024.620056126138\n",
            "SigmoidNAG without QG Testing Accuray at 475 iterations is 0.933731938216 with loss: -1024.235685736515\n",
            "SigmoidNAG without QG Testing Accuray at 476 iterations is 0.934728450424 with loss: -1023.921631256490\n",
            "SigmoidNAG without QG Testing Accuray at 477 iterations is 0.935226706527 with loss: -1023.667759519412\n",
            "SigmoidNAG without QG Testing Accuray at 478 iterations is 0.934728450424 with loss: -1023.458694739932\n",
            "SigmoidNAG without QG Testing Accuray at 479 iterations is 0.934230194320 with loss: -1023.275041924397\n",
            "SigmoidNAG without QG Testing Accuray at 480 iterations is 0.934230194320 with loss: -1023.094842313452\n",
            "SigmoidNAG without QG Testing Accuray at 481 iterations is 0.934728450424 with loss: -1022.895146069074\n",
            "SigmoidNAG without QG Testing Accuray at 482 iterations is 0.934728450424 with loss: -1022.653590968360\n",
            "SigmoidNAG without QG Testing Accuray at 483 iterations is 0.934230194320 with loss: -1022.349885120874\n",
            "SigmoidNAG without QG Testing Accuray at 484 iterations is 0.934230194320 with loss: -1021.967106356991\n",
            "SigmoidNAG without QG Testing Accuray at 485 iterations is 0.936223218734 with loss: -1021.492747287205\n",
            "SigmoidNAG without QG Testing Accuray at 486 iterations is 0.936223218734 with loss: -1020.919453518753\n",
            "SigmoidNAG without QG Testing Accuray at 487 iterations is 0.936223218734 with loss: -1020.245423862772\n",
            "SigmoidNAG without QG Testing Accuray at 488 iterations is 0.935724962631 with loss: -1019.474460604515\n",
            "SigmoidNAG without QG Testing Accuray at 489 iterations is 0.935724962631 with loss: -1018.615676619571\n",
            "SigmoidNAG without QG Testing Accuray at 490 iterations is 0.934728450424 with loss: -1017.682885006519\n",
            "SigmoidNAG without QG Testing Accuray at 491 iterations is 0.933233682113 with loss: -1016.693712396242\n",
            "SigmoidNAG without QG Testing Accuray at 492 iterations is 0.933731938216 with loss: -1015.668491478156\n",
            "SigmoidNAG without QG Testing Accuray at 493 iterations is 0.933731938216 with loss: -1014.628999636339\n",
            "SigmoidNAG without QG Testing Accuray at 494 iterations is 0.933233682113 with loss: -1013.597118441399\n",
            "SigmoidNAG without QG Testing Accuray at 495 iterations is 0.933233682113 with loss: -1012.593495245898\n",
            "SigmoidNAG without QG Testing Accuray at 496 iterations is 0.933233682113 with loss: -1011.636287740106\n",
            "SigmoidNAG without QG Testing Accuray at 497 iterations is 0.934230194320 with loss: -1010.740070564663\n",
            "SigmoidNAG without QG Testing Accuray at 498 iterations is 0.934728450424 with loss: -1009.914975465503\n",
            "SigmoidNAG without QG Testing Accuray at 499 iterations is 0.933731938216 with loss: -1009.166124056412\n",
            "SigmoidNAG without QG Testing Accuray at 500 iterations is 0.933731938216 with loss: -1008.493396494389\n",
            "X := \n",
            "[[1.         1.6177212  1.6616923  ... 0.49861783 1.5859714  1.392807  ]\n",
            " [1.         1.874512   0.89853495 ... 0.2503301  0.9760564  1.0381263 ]\n",
            " [1.         1.9298625  0.2412753  ... 0.06155838 0.26860148 1.0859213 ]\n",
            " ...\n",
            " [1.         1.6800578  1.0208532  ... 0.02777384 0.8086515  0.74124235]\n",
            " [1.         1.5928924  4.9518023  ... 1.0660875  1.8381706  0.17902502]\n",
            " [1.         1.3745586  0.14240515 ... 0.02759701 0.24952406 0.5397608 ]]\n",
            "XTX := \n",
            "[[ 7291.         15170.8343665   8476.14895637 ...  2991.12854667\n",
            "   3649.72015792  6867.54388517]\n",
            " [15170.8343665  32346.30096758 18232.94304139 ...  6441.62365\n",
            "   7916.0177725  14348.28737669]\n",
            " [ 8476.14895637 18232.94304139 17054.72057696 ...  5580.48214993\n",
            "   6649.10094794  7083.46541836]\n",
            " ...\n",
            " [ 2991.12854667  6441.62365     5580.48214993 ...  2443.38726091\n",
            "   2143.48993612  2349.72683784]\n",
            " [ 3649.72015792  7916.0177725   6649.10094794 ...  2143.48993612\n",
            "   3522.03674723  3456.68796299]\n",
            " [ 6867.54388517 14348.28737669  7083.46541836 ...  2349.72683784\n",
            "   3456.68796299  9159.78908371]]\n",
            "invBrow := \n",
            "[[0.00000278 0.00000132 0.00000211 0.0000038  0.00000468 0.00000496\n",
            "  0.00033362 0.00000732 0.00000711 0.00001643 0.00000327 0.00002076\n",
            "  0.00000144 0.00000575 0.00001386 0.00005055 0.00002223 0.00001586\n",
            "  0.00001287 0.00000212 0.00001638 0.00003341 0.00002321 0.00000441\n",
            "  0.00000516 0.00001738 0.00000831 0.00000997 0.00005825 0.00007041\n",
            "  0.00000182 0.00000379 0.00000561 0.00001254 0.00000152 0.00000154\n",
            "  0.00000213 0.00000355 0.00004356 0.00008293 0.00005087 0.00000397\n",
            "  0.0000042  0.00002684 0.00002403 0.00000626 0.00013469 0.00003347\n",
            "  0.00007399 0.00000933 0.00009053 0.00000475 0.00000296 0.00002107\n",
            "  0.00001871 0.00000147 0.0000132  0.00009241 0.00000176 0.00000176\n",
            "  0.00001523 0.00000878 0.00002202 0.00011737 0.00001229 0.00000276\n",
            "  0.00000362 0.0000577  0.00004152 0.00000188 0.00000126 0.00001123\n",
            "  0.00002366 0.00002656 0.00000517 0.00000908 0.00000311 0.00002052\n",
            "  0.00002684 0.00049121 0.00000263 0.00000562 0.00001206 0.00001547\n",
            "  0.00001371 0.00012462 0.00004928 0.00000355 0.00000166 0.0000162\n",
            "  0.00001011 0.00000148 0.01021134 0.00002549 0.00001688 0.0000064\n",
            "  0.00001567 0.00000161 0.00012136 0.00000592 0.00001553 0.00000427\n",
            "  0.00011027 0.00002211 0.00001544 0.00000626 0.00000181 0.00000536\n",
            "  0.00001436 0.00000332 0.00000378 0.00000766 0.00000377 0.00000387\n",
            "  0.00000999 0.00000187 0.00000636 0.0000011  0.00000316 0.00001028\n",
            "  0.00000042 0.0000068  0.00000378 0.00000391 0.00000998 0.00002812\n",
            "  0.00001018 0.00000517 0.00002438 0.00000709 0.00000717 0.00000411\n",
            "  0.00000829 0.00003497 0.0000135  0.00000976 0.00001805 0.00000096\n",
            "  0.00000611 0.00000662 0.00000608 0.00001464 0.00006155 0.00000093\n",
            "  0.00000159 0.00001962 0.00001048 0.00001348 0.00000567 0.00000709\n",
            "  0.00003141 0.00000408 0.00003943 0.00013859 0.00014222 0.00000566\n",
            "  0.00002223 0.00000855 0.00009034 0.00000169 0.00019367 0.00021555\n",
            "  0.00000211 0.00001008 0.00000706 0.00001238 0.00004399 0.00000707\n",
            "  0.00012078 0.00000578 0.0000023  0.00001854 0.00000451 0.0001224\n",
            "  0.0000138  0.00000672 0.00013653 0.00002277 0.00000437 0.00000349\n",
            "  0.00001643 0.00004674 0.00000293 0.00000707 0.00005815 0.00000926\n",
            "  0.00002563 0.00001095 0.00000657 0.00012285 0.00001578 0.00000456\n",
            "  0.00006739 0.00000593 0.00001018 0.00000364 0.0000038  0.00001292\n",
            "  0.00000679 0.00001458 0.00000352 0.00000375 0.00000162 0.00005262\n",
            "  0.00002075 0.00000151 0.00003299 0.00003    0.00015462 0.00000839\n",
            "  0.00011811 0.00001936 0.00014963 0.00001482 0.000003   0.00001103\n",
            "  0.00001599 0.0000046  0.00004463 0.00003509 0.00000444 0.00000661\n",
            "  0.0000023  0.00004684 0.00001057 0.00000903 0.00005622 0.00000733\n",
            "  0.00000271 0.0000397  0.00004956 0.00000355 0.00000344 0.0000048\n",
            "  0.00000125 0.00013512 0.00001681 0.00007378 0.00001136 0.00000496\n",
            "  0.00000335 0.00000702 0.00001153 0.00000549 0.00000391 0.00003267\n",
            "  0.00000452 0.00000805 0.00000488 0.00004411 0.00000171 0.0000265\n",
            "  0.00004828 0.00000205 0.00000431 0.00000153 0.00049182 0.00222412\n",
            "  0.00001675 0.00012222 0.00000761 0.00002633 0.00001888 0.00008191\n",
            "  0.00000308 0.00000365 0.00000448 0.00000674 0.00000723 0.00189456\n",
            "  0.00001465 0.00000313 0.00000402 0.00002337 0.00000484 0.00000892\n",
            "  0.00005986 0.00001189 0.00000161 0.00001871 0.00000801 0.00000572\n",
            "  0.00000877 0.00000711 0.00002514 0.0000181  0.00000333 0.00001768\n",
            "  0.00001398 0.00017761 0.00004995 0.00002858 0.00000777 0.00000391\n",
            "  0.00001439 0.00000613 0.00001425 0.0000014  0.00003202 0.00003726\n",
            "  0.00018396 0.00000394 0.00003814 0.00000148 0.00009359 0.0000335\n",
            "  0.00044506 0.000017   0.00000889 0.0000052  0.00001569 0.00000261\n",
            "  0.00007549 0.00002957 0.00000406 0.00000694 0.0000056  0.00000173\n",
            "  0.00000255 0.00001394 0.00000206 0.00000171 0.00003566 0.00000831\n",
            "  0.00004024 0.00001271 0.00015769 0.00004811 0.00001076 0.00001483\n",
            "  0.00001545 0.00001504 0.00000599 0.00000559 0.00000599 0.00001987\n",
            "  0.00000461 0.00000729 0.00021087 0.00001492 0.00000332 0.00000789\n",
            "  0.00002301 0.00023131 0.00001754 0.0002201  0.00005958 0.00003831\n",
            "  0.00006174 0.00006031 0.00000775 0.00002657 0.00001627 0.00000215\n",
            "  0.00004035 0.00000239 0.00000739 0.00006082 0.00002551 0.00000967\n",
            "  0.00000681 0.00008164 0.00008912 0.00001622 0.00004729 0.00000096\n",
            "  0.00000202 0.00001073 0.00000136 0.00000475 0.00000514 0.00000982\n",
            "  0.00000301 0.00001672 0.00000391 0.00000235 0.00000187 0.0000479\n",
            "  0.00000702 0.00004446 0.00001839 0.0000003  0.0000134  0.00007638\n",
            "  0.00000349 0.00002642 0.00001904 0.00001074 0.00001548 0.00000929\n",
            "  0.00001092 0.00001088 0.00000475 0.00000719 0.00000573 0.00000892\n",
            "  0.00001162 0.00000233 0.00000597 0.00000492 0.00000297]]\n",
            "SigmoidNAG with QG Testing Accuray at   1 iterations is 0.285002491281 with loss: -13783.841138827993\n",
            "SigmoidNAG with QG Testing Accuray at   2 iterations is 0.310911808670 with loss: -11554.143596274527\n",
            "SigmoidNAG with QG Testing Accuray at   3 iterations is 0.308918784255 with loss: -6271.202285981237\n",
            "SigmoidNAG with QG Testing Accuray at   4 iterations is 0.308918784255 with loss: -5975.011987910000\n",
            "SigmoidNAG with QG Testing Accuray at   5 iterations is 0.309417040359 with loss: -5782.454151029471\n",
            "SigmoidNAG with QG Testing Accuray at   6 iterations is 0.310911808670 with loss: -5533.407145091725\n",
            "SigmoidNAG with QG Testing Accuray at   7 iterations is 0.328849028401 with loss: -5283.762814953870\n",
            "SigmoidNAG with QG Testing Accuray at   8 iterations is 0.395615346288 with loss: -5056.629586169245\n",
            "SigmoidNAG with QG Testing Accuray at   9 iterations is 0.544593921276 with loss: -4866.639551173077\n",
            "SigmoidNAG with QG Testing Accuray at  10 iterations is 0.656203288490 with loss: -4708.040519731754\n",
            "SigmoidNAG with QG Testing Accuray at  11 iterations is 0.730443447932 with loss: -4555.414209729161\n",
            "SigmoidNAG with QG Testing Accuray at  12 iterations is 0.759342301943 with loss: -4395.560973584072\n",
            "SigmoidNAG with QG Testing Accuray at  13 iterations is 0.768310911809 with loss: -4235.928738922195\n",
            "SigmoidNAG with QG Testing Accuray at  14 iterations is 0.765819631290 with loss: -4087.503409392097\n",
            "SigmoidNAG with QG Testing Accuray at  15 iterations is 0.775286497260 with loss: -3952.519657136357\n",
            "SigmoidNAG with QG Testing Accuray at  16 iterations is 0.781763826607 with loss: -3826.795980470069\n",
            "SigmoidNAG with QG Testing Accuray at  17 iterations is 0.789237668161 with loss: -3706.509172454141\n",
            "SigmoidNAG with QG Testing Accuray at  18 iterations is 0.798704534131 with loss: -3590.882744862547\n",
            "SigmoidNAG with QG Testing Accuray at  19 iterations is 0.804185351271 with loss: -3480.686397900266\n",
            "SigmoidNAG with QG Testing Accuray at  20 iterations is 0.812157448929 with loss: -3376.152445542017\n",
            "SigmoidNAG with QG Testing Accuray at  21 iterations is 0.817638266069 with loss: -3276.605773172605\n",
            "SigmoidNAG with QG Testing Accuray at  22 iterations is 0.819631290483 with loss: -3181.349547556222\n",
            "SigmoidNAG with QG Testing Accuray at  23 iterations is 0.821624314898 with loss: -3090.322488521045\n",
            "SigmoidNAG with QG Testing Accuray at  24 iterations is 0.822122571001 with loss: -3003.956822203461\n",
            "SigmoidNAG with QG Testing Accuray at  25 iterations is 0.826108619831 with loss: -2922.647733925845\n",
            "SigmoidNAG with QG Testing Accuray at  26 iterations is 0.830592924763 with loss: -2846.400431409427\n",
            "SigmoidNAG with QG Testing Accuray at  27 iterations is 0.831589436971 with loss: -2774.860222062587\n",
            "SigmoidNAG with QG Testing Accuray at  28 iterations is 0.833582461385 with loss: -2707.546290409854\n",
            "SigmoidNAG with QG Testing Accuray at  29 iterations is 0.835077229696 with loss: -2644.028537220269\n",
            "SigmoidNAG with QG Testing Accuray at  30 iterations is 0.838066766318 with loss: -2583.961290538420\n",
            "SigmoidNAG with QG Testing Accuray at  31 iterations is 0.841554559043 with loss: -2527.048748355746\n",
            "SigmoidNAG with QG Testing Accuray at  32 iterations is 0.847035376183 with loss: -2473.030038152775\n",
            "SigmoidNAG with QG Testing Accuray at  33 iterations is 0.851519681116 with loss: -2421.699877399827\n",
            "SigmoidNAG with QG Testing Accuray at  34 iterations is 0.853014449427 with loss: -2372.927717483399\n",
            "SigmoidNAG with QG Testing Accuray at  35 iterations is 0.855505729945 with loss: -2326.639793782100\n",
            "SigmoidNAG with QG Testing Accuray at  36 iterations is 0.857498754360 with loss: -2282.764644956762\n",
            "SigmoidNAG with QG Testing Accuray at  37 iterations is 0.859491778774 with loss: -2241.178426518997\n",
            "SigmoidNAG with QG Testing Accuray at  38 iterations is 0.860986547085 with loss: -2201.690772538165\n",
            "SigmoidNAG with QG Testing Accuray at  39 iterations is 0.861983059292 with loss: -2164.079459454094\n",
            "SigmoidNAG with QG Testing Accuray at  40 iterations is 0.864972595914 with loss: -2128.143650800470\n",
            "SigmoidNAG with QG Testing Accuray at  41 iterations is 0.867962132536 with loss: -2093.736599632460\n",
            "SigmoidNAG with QG Testing Accuray at  42 iterations is 0.869955156951 with loss: -2060.761644826736\n",
            "SigmoidNAG with QG Testing Accuray at  43 iterations is 0.871449925262 with loss: -2029.144247819783\n",
            "SigmoidNAG with QG Testing Accuray at  44 iterations is 0.871948181365 with loss: -1998.805228404143\n",
            "SigmoidNAG with QG Testing Accuray at  45 iterations is 0.873941205780 with loss: -1969.652640748617\n",
            "SigmoidNAG with QG Testing Accuray at  46 iterations is 0.876432486298 with loss: -1941.593024087420\n",
            "SigmoidNAG with QG Testing Accuray at  47 iterations is 0.877428998505 with loss: -1914.549452339704\n",
            "SigmoidNAG with QG Testing Accuray at  48 iterations is 0.877927254609 with loss: -1888.471108830469\n",
            "SigmoidNAG with QG Testing Accuray at  49 iterations is 0.880418535127 with loss: -1863.326919456890\n",
            "SigmoidNAG with QG Testing Accuray at  50 iterations is 0.880916791231 with loss: -1839.087885111115\n",
            "SigmoidNAG with QG Testing Accuray at  51 iterations is 0.883408071749 with loss: -1815.710637666566\n",
            "SigmoidNAG with QG Testing Accuray at  52 iterations is 0.884902840060 with loss: -1793.133067040929\n",
            "SigmoidNAG with QG Testing Accuray at  53 iterations is 0.886895864474 with loss: -1771.283981801454\n",
            "SigmoidNAG with QG Testing Accuray at  54 iterations is 0.888390632785 with loss: -1750.099666369808\n",
            "SigmoidNAG with QG Testing Accuray at  55 iterations is 0.890383657200 with loss: -1729.536986971122\n",
            "SigmoidNAG with QG Testing Accuray at  56 iterations is 0.892874937718 with loss: -1709.576323361765\n",
            "SigmoidNAG with QG Testing Accuray at  57 iterations is 0.893871449925 with loss: -1690.214346515840\n",
            "SigmoidNAG with QG Testing Accuray at  58 iterations is 0.894867962133 with loss: -1671.451998002764\n",
            "SigmoidNAG with QG Testing Accuray at  59 iterations is 0.895366218236 with loss: -1653.284242008602\n",
            "SigmoidNAG with QG Testing Accuray at  60 iterations is 0.896362730443 with loss: -1635.695552405592\n",
            "SigmoidNAG with QG Testing Accuray at  61 iterations is 0.897359242651 with loss: -1618.660961635162\n",
            "SigmoidNAG with QG Testing Accuray at  62 iterations is 0.897857498754 with loss: -1602.149658467808\n",
            "SigmoidNAG with QG Testing Accuray at  63 iterations is 0.898355754858 with loss: -1586.128042469848\n",
            "SigmoidNAG with QG Testing Accuray at  64 iterations is 0.898355754858 with loss: -1570.561108448244\n",
            "SigmoidNAG with QG Testing Accuray at  65 iterations is 0.898854010962 with loss: -1555.413144512459\n",
            "SigmoidNAG with QG Testing Accuray at  66 iterations is 0.899352267065 with loss: -1540.649293760910\n",
            "SigmoidNAG with QG Testing Accuray at  67 iterations is 0.901843547583 with loss: -1526.238493666088\n",
            "SigmoidNAG with QG Testing Accuray at  68 iterations is 0.903338315894 with loss: -1512.156787236252\n",
            "SigmoidNAG with QG Testing Accuray at  69 iterations is 0.903836571998 with loss: -1498.389310454573\n",
            "SigmoidNAG with QG Testing Accuray at  70 iterations is 0.903836571998 with loss: -1484.929864022456\n",
            "SigmoidNAG with QG Testing Accuray at  71 iterations is 0.904334828102 with loss: -1471.778319052126\n",
            "SigmoidNAG with QG Testing Accuray at  72 iterations is 0.905829596413 with loss: -1458.937224805285\n",
            "SigmoidNAG with QG Testing Accuray at  73 iterations is 0.907324364723 with loss: -1446.409139085925\n",
            "SigmoidNAG with QG Testing Accuray at  74 iterations is 0.907822620827 with loss: -1434.195384686608\n",
            "SigmoidNAG with QG Testing Accuray at  75 iterations is 0.908320876931 with loss: -1422.295772364807\n",
            "SigmoidNAG with QG Testing Accuray at  76 iterations is 0.908320876931 with loss: -1410.708254622681\n",
            "SigmoidNAG with QG Testing Accuray at  77 iterations is 0.908819133034 with loss: -1399.427801606271\n",
            "SigmoidNAG with QG Testing Accuray at  78 iterations is 0.909815645242 with loss: -1388.444802940114\n",
            "SigmoidNAG with QG Testing Accuray at  79 iterations is 0.909815645242 with loss: -1377.744099053818\n",
            "SigmoidNAG with QG Testing Accuray at  80 iterations is 0.909815645242 with loss: -1367.305708429353\n",
            "SigmoidNAG with QG Testing Accuray at  81 iterations is 0.910812157449 with loss: -1357.107436761129\n",
            "SigmoidNAG with QG Testing Accuray at  82 iterations is 0.912306925760 with loss: -1347.128453897700\n",
            "SigmoidNAG with QG Testing Accuray at  83 iterations is 0.912306925760 with loss: -1337.352349759251\n",
            "SigmoidNAG with QG Testing Accuray at  84 iterations is 0.912805181863 with loss: -1327.768467082752\n",
            "SigmoidNAG with QG Testing Accuray at  85 iterations is 0.914299950174 with loss: -1318.371219078349\n",
            "SigmoidNAG with QG Testing Accuray at  86 iterations is 0.914798206278 with loss: -1309.158067600077\n",
            "SigmoidNAG with QG Testing Accuray at  87 iterations is 0.914798206278 with loss: -1300.127334416370\n",
            "SigmoidNAG with QG Testing Accuray at  88 iterations is 0.915296462382 with loss: -1291.276802895610\n",
            "SigmoidNAG with QG Testing Accuray at  89 iterations is 0.916791230693 with loss: -1282.603417785308\n",
            "SigmoidNAG with QG Testing Accuray at  90 iterations is 0.916791230693 with loss: -1274.103673946855\n",
            "SigmoidNAG with QG Testing Accuray at  91 iterations is 0.917289486796 with loss: -1265.774009984568\n",
            "SigmoidNAG with QG Testing Accuray at  92 iterations is 0.918784255107 with loss: -1257.610730105508\n",
            "SigmoidNAG with QG Testing Accuray at  93 iterations is 0.918784255107 with loss: -1249.609502216718\n",
            "SigmoidNAG with QG Testing Accuray at  94 iterations is 0.919780767314 with loss: -1241.764884154589\n",
            "SigmoidNAG with QG Testing Accuray at  95 iterations is 0.920777279522 with loss: -1234.070372784733\n",
            "SigmoidNAG with QG Testing Accuray at  96 iterations is 0.921773791729 with loss: -1226.519136063870\n",
            "SigmoidNAG with QG Testing Accuray at  97 iterations is 0.921773791729 with loss: -1219.105160635426\n",
            "SigmoidNAG with QG Testing Accuray at  98 iterations is 0.922770303936 with loss: -1211.824270158756\n",
            "SigmoidNAG with QG Testing Accuray at  99 iterations is 0.923268560040 with loss: -1204.674530168342\n",
            "SigmoidNAG with QG Testing Accuray at 100 iterations is 0.923766816143 with loss: -1197.655855171253\n",
            "SigmoidNAG with QG Testing Accuray at 101 iterations is 0.923766816143 with loss: -1190.769013497220\n",
            "SigmoidNAG with QG Testing Accuray at 102 iterations is 0.923268560040 with loss: -1184.014448528328\n",
            "SigmoidNAG with QG Testing Accuray at 103 iterations is 0.923268560040 with loss: -1177.391332835316\n",
            "SigmoidNAG with QG Testing Accuray at 104 iterations is 0.923766816143 with loss: -1170.897076604256\n",
            "SigmoidNAG with QG Testing Accuray at 105 iterations is 0.923766816143 with loss: -1164.527274773769\n",
            "SigmoidNAG with QG Testing Accuray at 106 iterations is 0.923766816143 with loss: -1158.275935753309\n",
            "SigmoidNAG with QG Testing Accuray at 107 iterations is 0.923766816143 with loss: -1152.135842937900\n",
            "SigmoidNAG with QG Testing Accuray at 108 iterations is 0.924265072247 with loss: -1146.099004137218\n",
            "SigmoidNAG with QG Testing Accuray at 109 iterations is 0.924265072247 with loss: -1140.157230459354\n",
            "SigmoidNAG with QG Testing Accuray at 110 iterations is 0.924265072247 with loss: -1134.302876337787\n",
            "SigmoidNAG with QG Testing Accuray at 111 iterations is 0.923766816143 with loss: -1128.529675867855\n",
            "SigmoidNAG with QG Testing Accuray at 112 iterations is 0.924265072247 with loss: -1122.833489200118\n",
            "SigmoidNAG with QG Testing Accuray at 113 iterations is 0.923766816143 with loss: -1117.212730461221\n",
            "SigmoidNAG with QG Testing Accuray at 114 iterations is 0.924265072247 with loss: -1111.668314007443\n",
            "SigmoidNAG with QG Testing Accuray at 115 iterations is 0.924265072247 with loss: -1106.203115950230\n",
            "SigmoidNAG with QG Testing Accuray at 116 iterations is 0.924763328351 with loss: -1100.821106493447\n",
            "SigmoidNAG with QG Testing Accuray at 117 iterations is 0.925261584454 with loss: -1095.526406782056\n",
            "SigmoidNAG with QG Testing Accuray at 118 iterations is 0.925261584454 with loss: -1090.322505851592\n",
            "SigmoidNAG with QG Testing Accuray at 119 iterations is 0.925759840558 with loss: -1085.211771521585\n",
            "SigmoidNAG with QG Testing Accuray at 120 iterations is 0.926258096662 with loss: -1080.195251039003\n",
            "SigmoidNAG with QG Testing Accuray at 121 iterations is 0.926258096662 with loss: -1075.272654509538\n",
            "SigmoidNAG with QG Testing Accuray at 122 iterations is 0.926258096662 with loss: -1070.442401356861\n",
            "SigmoidNAG with QG Testing Accuray at 123 iterations is 0.927254608869 with loss: -1065.701668371234\n",
            "SigmoidNAG with QG Testing Accuray at 124 iterations is 0.927752864973 with loss: -1061.046458248197\n",
            "SigmoidNAG with QG Testing Accuray at 125 iterations is 0.928251121076 with loss: -1056.471764197140\n",
            "SigmoidNAG with QG Testing Accuray at 126 iterations is 0.928251121076 with loss: -1051.971899346945\n",
            "SigmoidNAG with QG Testing Accuray at 127 iterations is 0.929247633284 with loss: -1047.540993930099\n",
            "SigmoidNAG with QG Testing Accuray at 128 iterations is 0.929247633284 with loss: -1043.173578261043\n",
            "SigmoidNAG with QG Testing Accuray at 129 iterations is 0.929247633284 with loss: -1038.865115742844\n",
            "SigmoidNAG with QG Testing Accuray at 130 iterations is 0.930244145491 with loss: -1034.612350333985\n",
            "SigmoidNAG with QG Testing Accuray at 131 iterations is 0.930244145491 with loss: -1030.413390443958\n",
            "SigmoidNAG with QG Testing Accuray at 132 iterations is 0.932237169905 with loss: -1026.267536366877\n",
            "SigmoidNAG with QG Testing Accuray at 133 iterations is 0.932237169905 with loss: -1022.174933596962\n",
            "SigmoidNAG with QG Testing Accuray at 134 iterations is 0.932237169905 with loss: -1018.136170268359\n",
            "SigmoidNAG with QG Testing Accuray at 135 iterations is 0.932735426009 with loss: -1014.151924682665\n",
            "SigmoidNAG with QG Testing Accuray at 136 iterations is 0.933731938216 with loss: -1010.222722027157\n",
            "SigmoidNAG with QG Testing Accuray at 137 iterations is 0.934230194320 with loss: -1006.348802096080\n",
            "SigmoidNAG with QG Testing Accuray at 138 iterations is 0.934728450424 with loss: -1002.530067072005\n",
            "SigmoidNAG with QG Testing Accuray at 139 iterations is 0.934728450424 with loss: -998.766066530585\n",
            "SigmoidNAG with QG Testing Accuray at 140 iterations is 0.934728450424 with loss: -995.055995947486\n",
            "SigmoidNAG with QG Testing Accuray at 141 iterations is 0.934728450424 with loss: -991.398713791793\n",
            "SigmoidNAG with QG Testing Accuray at 142 iterations is 0.935226706527 with loss: -987.792794733666\n",
            "SigmoidNAG with QG Testing Accuray at 143 iterations is 0.935226706527 with loss: -984.236637068552\n",
            "SigmoidNAG with QG Testing Accuray at 144 iterations is 0.935226706527 with loss: -980.728615765353\n",
            "SigmoidNAG with QG Testing Accuray at 145 iterations is 0.935226706527 with loss: -977.267255581989\n",
            "SigmoidNAG with QG Testing Accuray at 146 iterations is 0.936223218734 with loss: -973.851376520909\n",
            "SigmoidNAG with QG Testing Accuray at 147 iterations is 0.936721474838 with loss: -970.480166661093\n",
            "SigmoidNAG with QG Testing Accuray at 148 iterations is 0.936721474838 with loss: -967.153158520748\n",
            "SigmoidNAG with QG Testing Accuray at 149 iterations is 0.937219730942 with loss: -963.870117282076\n",
            "SigmoidNAG with QG Testing Accuray at 150 iterations is 0.937219730942 with loss: -960.630872542812\n",
            "SigmoidNAG with QG Testing Accuray at 151 iterations is 0.937219730942 with loss: -957.435141736467\n",
            "SigmoidNAG with QG Testing Accuray at 152 iterations is 0.936721474838 with loss: -954.282391013462\n",
            "SigmoidNAG with QG Testing Accuray at 153 iterations is 0.936721474838 with loss: -951.171759204999\n",
            "SigmoidNAG with QG Testing Accuray at 154 iterations is 0.936721474838 with loss: -948.102050465678\n",
            "SigmoidNAG with QG Testing Accuray at 155 iterations is 0.937219730942 with loss: -945.071779688873\n",
            "SigmoidNAG with QG Testing Accuray at 156 iterations is 0.938714499253 with loss: -942.079249700782\n",
            "SigmoidNAG with QG Testing Accuray at 157 iterations is 0.938714499253 with loss: -939.122640781015\n",
            "SigmoidNAG with QG Testing Accuray at 158 iterations is 0.938714499253 with loss: -936.200100767286\n",
            "SigmoidNAG with QG Testing Accuray at 159 iterations is 0.939212755356 with loss: -933.309840133696\n",
            "SigmoidNAG with QG Testing Accuray at 160 iterations is 0.941205779771 with loss: -930.450234342013\n",
            "SigmoidNAG with QG Testing Accuray at 161 iterations is 0.941704035874 with loss: -927.619933739959\n",
            "SigmoidNAG with QG Testing Accuray at 162 iterations is 0.941704035874 with loss: -924.817972714817\n",
            "SigmoidNAG with QG Testing Accuray at 163 iterations is 0.941704035874 with loss: -922.043856809766\n",
            "SigmoidNAG with QG Testing Accuray at 164 iterations is 0.941704035874 with loss: -919.297606830338\n",
            "SigmoidNAG with QG Testing Accuray at 165 iterations is 0.941704035874 with loss: -916.579741996828\n",
            "SigmoidNAG with QG Testing Accuray at 166 iterations is 0.941205779771 with loss: -913.891194997363\n",
            "SigmoidNAG with QG Testing Accuray at 167 iterations is 0.941704035874 with loss: -911.233168550260\n",
            "SigmoidNAG with QG Testing Accuray at 168 iterations is 0.942202291978 with loss: -908.606956304173\n",
            "SigmoidNAG with QG Testing Accuray at 169 iterations is 0.942202291978 with loss: -906.013758492678\n",
            "SigmoidNAG with QG Testing Accuray at 170 iterations is 0.942202291978 with loss: -903.454520297394\n",
            "SigmoidNAG with QG Testing Accuray at 171 iterations is 0.942202291978 with loss: -900.929813624622\n",
            "SigmoidNAG with QG Testing Accuray at 172 iterations is 0.942202291978 with loss: -898.439767983959\n",
            "SigmoidNAG with QG Testing Accuray at 173 iterations is 0.942202291978 with loss: -895.984049594812\n",
            "SigmoidNAG with QG Testing Accuray at 174 iterations is 0.942202291978 with loss: -893.561877462480\n",
            "SigmoidNAG with QG Testing Accuray at 175 iterations is 0.942202291978 with loss: -891.172065881173\n",
            "SigmoidNAG with QG Testing Accuray at 176 iterations is 0.942202291978 with loss: -888.813087679697\n",
            "SigmoidNAG with QG Testing Accuray at 177 iterations is 0.943198804185 with loss: -886.483153636248\n",
            "SigmoidNAG with QG Testing Accuray at 178 iterations is 0.943697060289 with loss: -884.180310051786\n",
            "SigmoidNAG with QG Testing Accuray at 179 iterations is 0.944195316393 with loss: -881.902554327308\n",
            "SigmoidNAG with QG Testing Accuray at 180 iterations is 0.943697060289 with loss: -879.647963967520\n",
            "SigmoidNAG with QG Testing Accuray at 181 iterations is 0.943697060289 with loss: -877.414829210207\n",
            "SigmoidNAG with QG Testing Accuray at 182 iterations is 0.943198804185 with loss: -875.201772679759\n",
            "SigmoidNAG with QG Testing Accuray at 183 iterations is 0.943697060289 with loss: -873.007838791990\n",
            "SigmoidNAG with QG Testing Accuray at 184 iterations is 0.943697060289 with loss: -870.832537782838\n",
            "SigmoidNAG with QG Testing Accuray at 185 iterations is 0.943697060289 with loss: -868.675838101636\n",
            "SigmoidNAG with QG Testing Accuray at 186 iterations is 0.943697060289 with loss: -866.538109132241\n",
            "SigmoidNAG with QG Testing Accuray at 187 iterations is 0.943697060289 with loss: -864.420023963038\n",
            "SigmoidNAG with QG Testing Accuray at 188 iterations is 0.943697060289 with loss: -862.322441270752\n",
            "SigmoidNAG with QG Testing Accuray at 189 iterations is 0.943697060289 with loss: -860.246281936919\n",
            "SigmoidNAG with QG Testing Accuray at 190 iterations is 0.943697060289 with loss: -858.192416789577\n",
            "SigmoidNAG with QG Testing Accuray at 191 iterations is 0.943697060289 with loss: -856.161575295880\n",
            "SigmoidNAG with QG Testing Accuray at 192 iterations is 0.943697060289 with loss: -854.154277963304\n",
            "SigmoidNAG with QG Testing Accuray at 193 iterations is 0.943198804185 with loss: -852.170790914700\n",
            "SigmoidNAG with QG Testing Accuray at 194 iterations is 0.943198804185 with loss: -850.211100910221\n",
            "SigmoidNAG with QG Testing Accuray at 195 iterations is 0.943198804185 with loss: -848.274906989033\n",
            "SigmoidNAG with QG Testing Accuray at 196 iterations is 0.943198804185 with loss: -846.361628168132\n",
            "SigmoidNAG with QG Testing Accuray at 197 iterations is 0.943198804185 with loss: -844.470426900216\n",
            "SigmoidNAG with QG Testing Accuray at 198 iterations is 0.943198804185 with loss: -842.600251986135\n",
            "SigmoidNAG with QG Testing Accuray at 199 iterations is 0.944195316393 with loss: -840.749900731205\n",
            "SigmoidNAG with QG Testing Accuray at 200 iterations is 0.944195316393 with loss: -838.918096336314\n",
            "SigmoidNAG with QG Testing Accuray at 201 iterations is 0.944195316393 with loss: -837.103575085362\n",
            "SigmoidNAG with QG Testing Accuray at 202 iterations is 0.944693572496 with loss: -835.305172468478\n",
            "SigmoidNAG with QG Testing Accuray at 203 iterations is 0.945191828600 with loss: -833.521899505403\n",
            "SigmoidNAG with QG Testing Accuray at 204 iterations is 0.945191828600 with loss: -831.752998884815\n",
            "SigmoidNAG with QG Testing Accuray at 205 iterations is 0.945191828600 with loss: -829.997974784396\n",
            "SigmoidNAG with QG Testing Accuray at 206 iterations is 0.945191828600 with loss: -828.256594324187\n",
            "SigmoidNAG with QG Testing Accuray at 207 iterations is 0.945191828600 with loss: -826.528864077961\n",
            "SigmoidNAG with QG Testing Accuray at 208 iterations is 0.945191828600 with loss: -824.814986817028\n",
            "SigmoidNAG with QG Testing Accuray at 209 iterations is 0.945191828600 with loss: -823.115307045579\n",
            "SigmoidNAG with QG Testing Accuray at 210 iterations is 0.945191828600 with loss: -821.430252770041\n",
            "SigmoidNAG with QG Testing Accuray at 211 iterations is 0.945191828600 with loss: -819.760279379958\n",
            "SigmoidNAG with QG Testing Accuray at 212 iterations is 0.945191828600 with loss: -818.105819737219\n",
            "SigmoidNAG with QG Testing Accuray at 213 iterations is 0.945191828600 with loss: -816.467242362942\n",
            "SigmoidNAG with QG Testing Accuray at 214 iterations is 0.945191828600 with loss: -814.844816572596\n",
            "SigmoidNAG with QG Testing Accuray at 215 iterations is 0.945191828600 with loss: -813.238687793440\n",
            "SigmoidNAG with QG Testing Accuray at 216 iterations is 0.945191828600 with loss: -811.648862232030\n",
            "SigmoidNAG with QG Testing Accuray at 217 iterations is 0.945191828600 with loss: -810.075201499733\n",
            "SigmoidNAG with QG Testing Accuray at 218 iterations is 0.945191828600 with loss: -808.517429165480\n",
            "SigmoidNAG with QG Testing Accuray at 219 iterations is 0.945191828600 with loss: -806.975148708480\n",
            "SigmoidNAG with QG Testing Accuray at 220 iterations is 0.945191828600 with loss: -805.447872144626\n",
            "SigmoidNAG with QG Testing Accuray at 221 iterations is 0.945690084704 with loss: -803.935056403909\n",
            "SigmoidNAG with QG Testing Accuray at 222 iterations is 0.946188340807 with loss: -802.436143190714\n",
            "SigmoidNAG with QG Testing Accuray at 223 iterations is 0.946188340807 with loss: -800.950598548277\n",
            "SigmoidNAG with QG Testing Accuray at 224 iterations is 0.946686596911 with loss: -799.477947081023\n",
            "SigmoidNAG with QG Testing Accuray at 225 iterations is 0.947184853014 with loss: -798.017795993270\n",
            "SigmoidNAG with QG Testing Accuray at 226 iterations is 0.947683109118 with loss: -796.569849162044\n",
            "SigmoidNAG with QG Testing Accuray at 227 iterations is 0.947683109118 with loss: -795.133910380696\n",
            "SigmoidNAG with QG Testing Accuray at 228 iterations is 0.948181365222 with loss: -793.709877252190\n",
            "SigmoidNAG with QG Testing Accuray at 229 iterations is 0.948679621325 with loss: -792.297728629972\n",
            "SigmoidNAG with QG Testing Accuray at 230 iterations is 0.948679621325 with loss: -790.897507723008\n",
            "SigmoidNAG with QG Testing Accuray at 231 iterations is 0.948679621325 with loss: -789.509304453197\n",
            "SigmoidNAG with QG Testing Accuray at 232 iterations is 0.949177877429 with loss: -788.133237295449\n",
            "SigmoidNAG with QG Testing Accuray at 233 iterations is 0.949177877429 with loss: -786.769435305993\n",
            "SigmoidNAG with QG Testing Accuray at 234 iterations is 0.949177877429 with loss: -785.418021236392\n",
            "SigmoidNAG with QG Testing Accuray at 235 iterations is 0.949676133533 with loss: -784.079095262354\n",
            "SigmoidNAG with QG Testing Accuray at 236 iterations is 0.949676133533 with loss: -782.752719666789\n",
            "SigmoidNAG with QG Testing Accuray at 237 iterations is 0.949676133533 with loss: -781.438906195484\n",
            "SigmoidNAG with QG Testing Accuray at 238 iterations is 0.949676133533 with loss: -780.137606917440\n",
            "SigmoidNAG with QG Testing Accuray at 239 iterations is 0.950174389636 with loss: -778.848710150320\n",
            "SigmoidNAG with QG Testing Accuray at 240 iterations is 0.950174389636 with loss: -777.572043625259\n",
            "SigmoidNAG with QG Testing Accuray at 241 iterations is 0.950174389636 with loss: -776.307383393605\n",
            "SigmoidNAG with QG Testing Accuray at 242 iterations is 0.950174389636 with loss: -775.054469006943\n",
            "SigmoidNAG with QG Testing Accuray at 243 iterations is 0.950174389636 with loss: -773.813021797794\n",
            "SigmoidNAG with QG Testing Accuray at 244 iterations is 0.949676133533 with loss: -772.582763616232\n",
            "SigmoidNAG with QG Testing Accuray at 245 iterations is 0.949676133533 with loss: -771.363433495049\n",
            "SigmoidNAG with QG Testing Accuray at 246 iterations is 0.949676133533 with loss: -770.154799683987\n",
            "SigmoidNAG with QG Testing Accuray at 247 iterations is 0.949676133533 with loss: -768.956665795777\n",
            "SigmoidNAG with QG Testing Accuray at 248 iterations is 0.949676133533 with loss: -767.768870964799\n",
            "SigmoidNAG with QG Testing Accuray at 249 iterations is 0.949676133533 with loss: -766.591284606865\n",
            "SigmoidNAG with QG Testing Accuray at 250 iterations is 0.950174389636 with loss: -765.423798790221\n",
            "SigmoidNAG with QG Testing Accuray at 251 iterations is 0.950672645740 with loss: -764.266319112110\n",
            "SigmoidNAG with QG Testing Accuray at 252 iterations is 0.950672645740 with loss: -763.118757245908\n",
            "SigmoidNAG with QG Testing Accuray at 253 iterations is 0.950672645740 with loss: -761.981025543779\n",
            "SigmoidNAG with QG Testing Accuray at 254 iterations is 0.951170901844 with loss: -760.853034139620\n",
            "SigmoidNAG with QG Testing Accuray at 255 iterations is 0.951669157947 with loss: -759.734690182457\n",
            "SigmoidNAG with QG Testing Accuray at 256 iterations is 0.951669157947 with loss: -758.625898730930\n",
            "SigmoidNAG with QG Testing Accuray at 257 iterations is 0.951669157947 with loss: -757.526563939917\n",
            "SigmoidNAG with QG Testing Accuray at 258 iterations is 0.951669157947 with loss: -756.436589630539\n",
            "SigmoidNAG with QG Testing Accuray at 259 iterations is 0.951669157947 with loss: -755.355879157825\n",
            "SigmoidNAG with QG Testing Accuray at 260 iterations is 0.951669157947 with loss: -754.284335783295\n",
            "SigmoidNAG with QG Testing Accuray at 261 iterations is 0.951669157947 with loss: -753.221862590665\n",
            "SigmoidNAG with QG Testing Accuray at 262 iterations is 0.951669157947 with loss: -752.168363027166\n",
            "SigmoidNAG with QG Testing Accuray at 263 iterations is 0.951170901844 with loss: -751.123743506444\n",
            "SigmoidNAG with QG Testing Accuray at 264 iterations is 0.951669157947 with loss: -750.087917240519\n",
            "SigmoidNAG with QG Testing Accuray at 265 iterations is 0.952665670154 with loss: -749.060808745806\n",
            "SigmoidNAG with QG Testing Accuray at 266 iterations is 0.952665670154 with loss: -748.042357928634\n",
            "SigmoidNAG with QG Testing Accuray at 267 iterations is 0.952665670154 with loss: -747.032522729108\n",
            "SigmoidNAG with QG Testing Accuray at 268 iterations is 0.952665670154 with loss: -746.031279404614\n",
            "SigmoidNAG with QG Testing Accuray at 269 iterations is 0.952665670154 with loss: -745.038619190926\n",
            "SigmoidNAG with QG Testing Accuray at 270 iterations is 0.952665670154 with loss: -744.054542079736\n",
            "SigmoidNAG with QG Testing Accuray at 271 iterations is 0.952665670154 with loss: -743.079047646167\n",
            "SigmoidNAG with QG Testing Accuray at 272 iterations is 0.952665670154 with loss: -742.112123892465\n",
            "SigmoidNAG with QG Testing Accuray at 273 iterations is 0.952665670154 with loss: -741.153735896072\n",
            "SigmoidNAG with QG Testing Accuray at 274 iterations is 0.952665670154 with loss: -740.203816070422\n",
            "SigmoidNAG with QG Testing Accuray at 275 iterations is 0.952665670154 with loss: -739.262257031485\n",
            "SigmoidNAG with QG Testing Accuray at 276 iterations is 0.952665670154 with loss: -738.328908302142\n",
            "SigmoidNAG with QG Testing Accuray at 277 iterations is 0.952665670154 with loss: -737.403576756491\n",
            "SigmoidNAG with QG Testing Accuray at 278 iterations is 0.952665670154 with loss: -736.486030813752\n",
            "SigmoidNAG with QG Testing Accuray at 279 iterations is 0.952665670154 with loss: -735.576007476738\n",
            "SigmoidNAG with QG Testing Accuray at 280 iterations is 0.952665670154 with loss: -734.673221929700\n",
            "SigmoidNAG with QG Testing Accuray at 281 iterations is 0.952665670154 with loss: -733.777378722460\n",
            "SigmoidNAG with QG Testing Accuray at 282 iterations is 0.952665670154 with loss: -732.888183356074\n",
            "SigmoidNAG with QG Testing Accuray at 283 iterations is 0.952665670154 with loss: -732.005354180922\n",
            "SigmoidNAG with QG Testing Accuray at 284 iterations is 0.952665670154 with loss: -731.128633929551\n",
            "SigmoidNAG with QG Testing Accuray at 285 iterations is 0.952665670154 with loss: -730.257800697977\n",
            "SigmoidNAG with QG Testing Accuray at 286 iterations is 0.952665670154 with loss: -729.392678222526\n",
            "SigmoidNAG with QG Testing Accuray at 287 iterations is 0.952665670154 with loss: -728.533144649337\n",
            "SigmoidNAG with QG Testing Accuray at 288 iterations is 0.952665670154 with loss: -727.679138834551\n",
            "SigmoidNAG with QG Testing Accuray at 289 iterations is 0.953163926258 with loss: -726.830664403972\n",
            "SigmoidNAG with QG Testing Accuray at 290 iterations is 0.953662182362 with loss: -725.987789893742\n",
            "SigmoidNAG with QG Testing Accuray at 291 iterations is 0.953662182362 with loss: -725.150644970921\n",
            "SigmoidNAG with QG Testing Accuray at 292 iterations is 0.953662182362 with loss: -724.319413136978\n",
            "SigmoidNAG with QG Testing Accuray at 293 iterations is 0.953662182362 with loss: -723.494319642534\n",
            "SigmoidNAG with QG Testing Accuray at 294 iterations is 0.953662182362 with loss: -722.675615969258\n",
            "SigmoidNAG with QG Testing Accuray at 295 iterations is 0.953662182362 with loss: -721.863562367541\n",
            "SigmoidNAG with QG Testing Accuray at 296 iterations is 0.954160438465 with loss: -721.058409296973\n",
            "SigmoidNAG with QG Testing Accuray at 297 iterations is 0.955156950673 with loss: -720.260379678019\n",
            "SigmoidNAG with QG Testing Accuray at 298 iterations is 0.955156950673 with loss: -719.469652707917\n",
            "SigmoidNAG with QG Testing Accuray at 299 iterations is 0.955156950673 with loss: -718.686350585406\n",
            "SigmoidNAG with QG Testing Accuray at 300 iterations is 0.955156950673 with loss: -717.910529707279\n",
            "SigmoidNAG with QG Testing Accuray at 301 iterations is 0.955156950673 with loss: -717.142176141521\n",
            "SigmoidNAG with QG Testing Accuray at 302 iterations is 0.955156950673 with loss: -716.381205477518\n",
            "SigmoidNAG with QG Testing Accuray at 303 iterations is 0.955156950673 with loss: -715.627466685403\n",
            "SigmoidNAG with QG Testing Accuray at 304 iterations is 0.955156950673 with loss: -714.880749737206\n",
            "SigmoidNAG with QG Testing Accuray at 305 iterations is 0.955156950673 with loss: -714.140795951247\n",
            "SigmoidNAG with QG Testing Accuray at 306 iterations is 0.955156950673 with loss: -713.407310400516\n",
            "SigmoidNAG with QG Testing Accuray at 307 iterations is 0.955156950673 with loss: -712.679976045164\n",
            "SigmoidNAG with QG Testing Accuray at 308 iterations is 0.955156950673 with loss: -711.958468546547\n",
            "SigmoidNAG with QG Testing Accuray at 309 iterations is 0.955655206776 with loss: -711.242471357893\n",
            "SigmoidNAG with QG Testing Accuray at 310 iterations is 0.955655206776 with loss: -710.531689813147\n",
            "SigmoidNAG with QG Testing Accuray at 311 iterations is 0.955655206776 with loss: -709.825864253792\n",
            "SigmoidNAG with QG Testing Accuray at 312 iterations is 0.955655206776 with loss: -709.124780972905\n",
            "SigmoidNAG with QG Testing Accuray at 313 iterations is 0.955655206776 with loss: -708.428280504748\n",
            "SigmoidNAG with QG Testing Accuray at 314 iterations is 0.955655206776 with loss: -707.736263177989\n",
            "SigmoidNAG with QG Testing Accuray at 315 iterations is 0.955655206776 with loss: -707.048690573737\n",
            "SigmoidNAG with QG Testing Accuray at 316 iterations is 0.955655206776 with loss: -706.365583379714\n",
            "SigmoidNAG with QG Testing Accuray at 317 iterations is 0.955655206776 with loss: -705.687015664024\n",
            "SigmoidNAG with QG Testing Accuray at 318 iterations is 0.955655206776 with loss: -705.013106046887\n",
            "SigmoidNAG with QG Testing Accuray at 319 iterations is 0.955655206776 with loss: -704.344006486634\n",
            "SigmoidNAG with QG Testing Accuray at 320 iterations is 0.955655206776 with loss: -703.679889106335\n",
            "SigmoidNAG with QG Testing Accuray at 321 iterations is 0.955655206776 with loss: -703.020932607522\n",
            "SigmoidNAG with QG Testing Accuray at 322 iterations is 0.955655206776 with loss: -702.367308998670\n",
            "SigmoidNAG with QG Testing Accuray at 323 iterations is 0.955655206776 with loss: -701.719171119817\n",
            "SigmoidNAG with QG Testing Accuray at 324 iterations is 0.955655206776 with loss: -701.076642695279\n",
            "SigmoidNAG with QG Testing Accuray at 325 iterations is 0.956651718984 with loss: -700.439810511892\n",
            "SigmoidNAG with QG Testing Accuray at 326 iterations is 0.956651718984 with loss: -699.808719041398\n",
            "SigmoidNAG with QG Testing Accuray at 327 iterations is 0.956651718984 with loss: -699.183367882166\n",
            "SigmoidNAG with QG Testing Accuray at 328 iterations is 0.956651718984 with loss: -698.563712513680\n",
            "SigmoidNAG with QG Testing Accuray at 329 iterations is 0.956651718984 with loss: -697.949667428596\n",
            "SigmoidNAG with QG Testing Accuray at 330 iterations is 0.956651718984 with loss: -697.341111716091\n",
            "SigmoidNAG with QG Testing Accuray at 331 iterations is 0.956651718984 with loss: -696.737896504475\n",
            "SigmoidNAG with QG Testing Accuray at 332 iterations is 0.956651718984 with loss: -696.139854280182\n",
            "SigmoidNAG with QG Testing Accuray at 333 iterations is 0.956651718984 with loss: -695.546808545396\n",
            "SigmoidNAG with QG Testing Accuray at 334 iterations is 0.956651718984 with loss: -694.958584438893\n",
            "SigmoidNAG with QG Testing Accuray at 335 iterations is 0.957149975087 with loss: -694.375018735762\n",
            "SigmoidNAG with QG Testing Accuray at 336 iterations is 0.957149975087 with loss: -693.795969163979\n",
            "SigmoidNAG with QG Testing Accuray at 337 iterations is 0.957149975087 with loss: -693.221321941519\n",
            "SigmoidNAG with QG Testing Accuray at 338 iterations is 0.957149975087 with loss: -692.650997252765\n",
            "SigmoidNAG with QG Testing Accuray at 339 iterations is 0.957149975087 with loss: -692.084952072451\n",
            "SigmoidNAG with QG Testing Accuray at 340 iterations is 0.957149975087 with loss: -691.523180052851\n",
            "SigmoidNAG with QG Testing Accuray at 341 iterations is 0.957149975087 with loss: -690.965708703764\n",
            "SigmoidNAG with QG Testing Accuray at 342 iterations is 0.957149975087 with loss: -690.412594064799\n",
            "SigmoidNAG with QG Testing Accuray at 343 iterations is 0.957149975087 with loss: -689.863913009332\n",
            "SigmoidNAG with QG Testing Accuray at 344 iterations is 0.957149975087 with loss: -689.319753985871\n",
            "SigmoidNAG with QG Testing Accuray at 345 iterations is 0.957149975087 with loss: -688.780207392596\n",
            "SigmoidNAG with QG Testing Accuray at 346 iterations is 0.957149975087 with loss: -688.245355451451\n",
            "SigmoidNAG with QG Testing Accuray at 347 iterations is 0.957648231191 with loss: -687.715262801640\n",
            "SigmoidNAG with QG Testing Accuray at 348 iterations is 0.957648231191 with loss: -687.189968271080\n",
            "SigmoidNAG with QG Testing Accuray at 349 iterations is 0.957648231191 with loss: -686.669478790831\n",
            "SigmoidNAG with QG Testing Accuray at 350 iterations is 0.957149975087 with loss: -686.153765460516\n",
            "SigmoidNAG with QG Testing Accuray at 351 iterations is 0.957149975087 with loss: -685.642761619680\n",
            "SigmoidNAG with QG Testing Accuray at 352 iterations is 0.957149975087 with loss: -685.136363503176\n",
            "SigmoidNAG with QG Testing Accuray at 353 iterations is 0.957149975087 with loss: -684.634433303410\n",
            "SigmoidNAG with QG Testing Accuray at 354 iterations is 0.957149975087 with loss: -684.136803965946\n",
            "SigmoidNAG with QG Testing Accuray at 355 iterations is 0.957149975087 with loss: -683.643285962361\n",
            "SigmoidNAG with QG Testing Accuray at 356 iterations is 0.957149975087 with loss: -683.153675959247\n",
            "SigmoidNAG with QG Testing Accuray at 357 iterations is 0.957648231191 with loss: -682.667766191375\n",
            "SigmoidNAG with QG Testing Accuray at 358 iterations is 0.957149975087 with loss: -682.185354927796\n",
            "SigmoidNAG with QG Testing Accuray at 359 iterations is 0.957149975087 with loss: -681.706256448886\n",
            "SigmoidNAG with QG Testing Accuray at 360 iterations is 0.957149975087 with loss: -681.230311035956\n",
            "SigmoidNAG with QG Testing Accuray at 361 iterations is 0.957648231191 with loss: -680.757393872682\n",
            "SigmoidNAG with QG Testing Accuray at 362 iterations is 0.957648231191 with loss: -680.287422103955\n",
            "SigmoidNAG with QG Testing Accuray at 363 iterations is 0.957648231191 with loss: -679.820360003218\n",
            "SigmoidNAG with QG Testing Accuray at 364 iterations is 0.957648231191 with loss: -679.356221540380\n",
            "SigmoidNAG with QG Testing Accuray at 365 iterations is 0.957648231191 with loss: -678.895070125974\n",
            "SigmoidNAG with QG Testing Accuray at 366 iterations is 0.957648231191 with loss: -678.437015247401\n",
            "SigmoidNAG with QG Testing Accuray at 367 iterations is 0.957648231191 with loss: -677.982206460144\n",
            "SigmoidNAG with QG Testing Accuray at 368 iterations is 0.957648231191 with loss: -677.530824866317\n",
            "SigmoidNAG with QG Testing Accuray at 369 iterations is 0.957648231191 with loss: -677.083072596304\n",
            "SigmoidNAG with QG Testing Accuray at 370 iterations is 0.957648231191 with loss: -676.639161036669\n",
            "SigmoidNAG with QG Testing Accuray at 371 iterations is 0.957648231191 with loss: -676.199298341917\n",
            "SigmoidNAG with QG Testing Accuray at 372 iterations is 0.957648231191 with loss: -675.763677150070\n",
            "SigmoidNAG with QG Testing Accuray at 373 iterations is 0.957648231191 with loss: -675.332463163829\n",
            "SigmoidNAG with QG Testing Accuray at 374 iterations is 0.957648231191 with loss: -674.905784859635\n",
            "SigmoidNAG with QG Testing Accuray at 375 iterations is 0.957648231191 with loss: -674.483725671252\n",
            "SigmoidNAG with QG Testing Accuray at 376 iterations is 0.957648231191 with loss: -674.066317811967\n",
            "SigmoidNAG with QG Testing Accuray at 377 iterations is 0.957648231191 with loss: -673.653539271642\n",
            "SigmoidNAG with QG Testing Accuray at 378 iterations is 0.957149975087 with loss: -673.245313283201\n",
            "SigmoidNAG with QG Testing Accuray at 379 iterations is 0.957149975087 with loss: -672.841510764667\n",
            "SigmoidNAG with QG Testing Accuray at 380 iterations is 0.957149975087 with loss: -672.441954815083\n",
            "SigmoidNAG with QG Testing Accuray at 381 iterations is 0.957149975087 with loss: -672.046427471023\n",
            "SigmoidNAG with QG Testing Accuray at 382 iterations is 0.957149975087 with loss: -671.654678843938\n",
            "SigmoidNAG with QG Testing Accuray at 383 iterations is 0.957149975087 with loss: -671.266437736718\n",
            "SigmoidNAG with QG Testing Accuray at 384 iterations is 0.957149975087 with loss: -670.881423302124\n",
            "SigmoidNAG with QG Testing Accuray at 385 iterations is 0.957149975087 with loss: -670.499357693920\n",
            "SigmoidNAG with QG Testing Accuray at 386 iterations is 0.957648231191 with loss: -670.119978259174\n",
            "SigmoidNAG with QG Testing Accuray at 387 iterations is 0.957648231191 with loss: -669.743049390525\n",
            "SigmoidNAG with QG Testing Accuray at 388 iterations is 0.957648231191 with loss: -669.368373138074\n",
            "SigmoidNAG with QG Testing Accuray at 389 iterations is 0.957648231191 with loss: -668.995798036517\n",
            "SigmoidNAG with QG Testing Accuray at 390 iterations is 0.957648231191 with loss: -668.625225888657\n",
            "SigmoidNAG with QG Testing Accuray at 391 iterations is 0.957648231191 with loss: -668.256615618889\n",
            "SigmoidNAG with QG Testing Accuray at 392 iterations is 0.957648231191 with loss: -667.889984406826\n",
            "SigmoidNAG with QG Testing Accuray at 393 iterations is 0.957648231191 with loss: -667.525405884751\n",
            "SigmoidNAG with QG Testing Accuray at 394 iterations is 0.957648231191 with loss: -667.163005358191\n",
            "SigmoidNAG with QG Testing Accuray at 395 iterations is 0.957648231191 with loss: -666.802952474411\n",
            "SigmoidNAG with QG Testing Accuray at 396 iterations is 0.957648231191 with loss: -666.445451862249\n",
            "SigmoidNAG with QG Testing Accuray at 397 iterations is 0.957648231191 with loss: -666.090732085931\n",
            "SigmoidNAG with QG Testing Accuray at 398 iterations is 0.957648231191 with loss: -665.739033618040\n",
            "SigmoidNAG with QG Testing Accuray at 399 iterations is 0.957648231191 with loss: -665.390596565757\n",
            "SigmoidNAG with QG Testing Accuray at 400 iterations is 0.958146487294 with loss: -665.045648322257\n",
            "SigmoidNAG with QG Testing Accuray at 401 iterations is 0.958146487294 with loss: -664.704392284786\n",
            "SigmoidNAG with QG Testing Accuray at 402 iterations is 0.958146487294 with loss: -664.366998034272\n",
            "SigmoidNAG with QG Testing Accuray at 403 iterations is 0.958146487294 with loss: -664.033593045504\n",
            "SigmoidNAG with QG Testing Accuray at 404 iterations is 0.958146487294 with loss: -663.704256263572\n",
            "SigmoidNAG with QG Testing Accuray at 405 iterations is 0.958146487294 with loss: -663.379014313868\n",
            "SigmoidNAG with QG Testing Accuray at 406 iterations is 0.958146487294 with loss: -663.057840009013\n",
            "SigmoidNAG with QG Testing Accuray at 407 iterations is 0.958146487294 with loss: -662.740653168299\n",
            "SigmoidNAG with QG Testing Accuray at 408 iterations is 0.958146487294 with loss: -662.427323614232\n",
            "SigmoidNAG with QG Testing Accuray at 409 iterations is 0.958146487294 with loss: -662.117676198364\n",
            "SigmoidNAG with QG Testing Accuray at 410 iterations is 0.958146487294 with loss: -661.811498106488\n",
            "SigmoidNAG with QG Testing Accuray at 411 iterations is 0.958644743398 with loss: -661.508547479721\n",
            "SigmoidNAG with QG Testing Accuray at 412 iterations is 0.958644743398 with loss: -661.208563282174\n",
            "SigmoidNAG with QG Testing Accuray at 413 iterations is 0.958644743398 with loss: -660.911276016175\n",
            "SigmoidNAG with QG Testing Accuray at 414 iterations is 0.958644743398 with loss: -660.616418872873\n",
            "SigmoidNAG with QG Testing Accuray at 415 iterations is 0.958644743398 with loss: -660.323738610639\n",
            "SigmoidNAG with QG Testing Accuray at 416 iterations is 0.958644743398 with loss: -660.033005688881\n",
            "SigmoidNAG with QG Testing Accuray at 417 iterations is 0.958644743398 with loss: -659.744023128361\n",
            "SigmoidNAG with QG Testing Accuray at 418 iterations is 0.958644743398 with loss: -659.456633686863\n",
            "SigmoidNAG with QG Testing Accuray at 419 iterations is 0.958644743398 with loss: -659.170725109793\n",
            "SigmoidNAG with QG Testing Accuray at 420 iterations is 0.958644743398 with loss: -658.886233006408\n",
            "SigmoidNAG with QG Testing Accuray at 421 iterations is 0.958644743398 with loss: -658.603141350517\n",
            "SigmoidNAG with QG Testing Accuray at 422 iterations is 0.958644743398 with loss: -658.321481096266\n",
            "SigmoidNAG with QG Testing Accuray at 423 iterations is 0.958644743398 with loss: -658.041326034813\n",
            "SigmoidNAG with QG Testing Accuray at 424 iterations is 0.958644743398 with loss: -657.762786909386\n",
            "SigmoidNAG with QG Testing Accuray at 425 iterations is 0.958644743398 with loss: -657.486004189495\n",
            "SigmoidNAG with QG Testing Accuray at 426 iterations is 0.958644743398 with loss: -657.211139429847\n",
            "SigmoidNAG with QG Testing Accuray at 427 iterations is 0.958644743398 with loss: -656.938366090719\n",
            "SigmoidNAG with QG Testing Accuray at 428 iterations is 0.958644743398 with loss: -656.667860360384\n",
            "SigmoidNAG with QG Testing Accuray at 429 iterations is 0.958644743398 with loss: -656.399791875162\n",
            "SigmoidNAG with QG Testing Accuray at 430 iterations is 0.958644743398 with loss: -656.134315347292\n",
            "SigmoidNAG with QG Testing Accuray at 431 iterations is 0.958644743398 with loss: -655.871563191681\n",
            "SigmoidNAG with QG Testing Accuray at 432 iterations is 0.958146487294 with loss: -655.611639340512\n",
            "SigmoidNAG with QG Testing Accuray at 433 iterations is 0.958146487294 with loss: -655.354614790486\n",
            "SigmoidNAG with QG Testing Accuray at 434 iterations is 0.958146487294 with loss: -655.100524390265\n",
            "SigmoidNAG with QG Testing Accuray at 435 iterations is 0.958146487294 with loss: -654.849365476475\n",
            "SigmoidNAG with QG Testing Accuray at 436 iterations is 0.958146487294 with loss: -654.601098421913\n",
            "SigmoidNAG with QG Testing Accuray at 437 iterations is 0.958146487294 with loss: -654.355648472895\n",
            "SigmoidNAG with QG Testing Accuray at 438 iterations is 0.958644743398 with loss: -654.112909498964\n",
            "SigmoidNAG with QG Testing Accuray at 439 iterations is 0.958644743398 with loss: -653.872748744889\n",
            "SigmoidNAG with QG Testing Accuray at 440 iterations is 0.958644743398 with loss: -653.635013013055\n",
            "SigmoidNAG with QG Testing Accuray at 441 iterations is 0.958644743398 with loss: -653.399535525582\n",
            "SigmoidNAG with QG Testing Accuray at 442 iterations is 0.958644743398 with loss: -653.166143359054\n",
            "SigmoidNAG with QG Testing Accuray at 443 iterations is 0.958644743398 with loss: -652.934664741818\n",
            "SigmoidNAG with QG Testing Accuray at 444 iterations is 0.958644743398 with loss: -652.704936357272\n",
            "SigmoidNAG with QG Testing Accuray at 445 iterations is 0.958644743398 with loss: -652.476810127898\n",
            "SigmoidNAG with QG Testing Accuray at 446 iterations is 0.958644743398 with loss: -652.250159108133\n",
            "SigmoidNAG with QG Testing Accuray at 447 iterations is 0.958644743398 with loss: -652.024881910610\n",
            "SigmoidNAG with QG Testing Accuray at 448 iterations is 0.958644743398 with loss: -651.800906058697\n",
            "SigmoidNAG with QG Testing Accuray at 449 iterations is 0.958644743398 with loss: -651.578189805340\n",
            "SigmoidNAG with QG Testing Accuray at 450 iterations is 0.959142999502 with loss: -651.356722109666\n",
            "SigmoidNAG with QG Testing Accuray at 451 iterations is 0.959142999502 with loss: -651.136521206369\n",
            "SigmoidNAG with QG Testing Accuray at 452 iterations is 0.959142999502 with loss: -650.917631909545\n",
            "SigmoidNAG with QG Testing Accuray at 453 iterations is 0.959142999502 with loss: -650.700121579437\n",
            "SigmoidNAG with QG Testing Accuray at 454 iterations is 0.959142999502 with loss: -650.484075176526\n",
            "SigmoidNAG with QG Testing Accuray at 455 iterations is 0.959142999502 with loss: -650.269589634784\n",
            "SigmoidNAG with QG Testing Accuray at 456 iterations is 0.959142999502 with loss: -650.056768114589\n",
            "SigmoidNAG with QG Testing Accuray at 457 iterations is 0.959142999502 with loss: -649.845714100569\n",
            "SigmoidNAG with QG Testing Accuray at 458 iterations is 0.959641255605 with loss: -649.636525710487\n",
            "SigmoidNAG with QG Testing Accuray at 459 iterations is 0.959641255605 with loss: -649.429290509207\n",
            "SigmoidNAG with QG Testing Accuray at 460 iterations is 0.959641255605 with loss: -649.224081016066\n",
            "SigmoidNAG with QG Testing Accuray at 461 iterations is 0.959641255605 with loss: -649.020951004921\n",
            "SigmoidNAG with QG Testing Accuray at 462 iterations is 0.959641255605 with loss: -648.819932951836\n",
            "SigmoidNAG with QG Testing Accuray at 463 iterations is 0.959641255605 with loss: -648.621036399854\n",
            "SigmoidNAG with QG Testing Accuray at 464 iterations is 0.959641255605 with loss: -648.424247522670\n",
            "SigmoidNAG with QG Testing Accuray at 465 iterations is 0.959641255605 with loss: -648.229530053669\n",
            "SigmoidNAG with QG Testing Accuray at 466 iterations is 0.959641255605 with loss: -648.036826825384\n",
            "SigmoidNAG with QG Testing Accuray at 467 iterations is 0.959641255605 with loss: -647.846062377562\n",
            "SigmoidNAG with QG Testing Accuray at 468 iterations is 0.959641255605 with loss: -647.657146576688\n",
            "SigmoidNAG with QG Testing Accuray at 469 iterations is 0.959641255605 with loss: -647.469978659890\n",
            "SigmoidNAG with QG Testing Accuray at 470 iterations is 0.959641255605 with loss: -647.284451941013\n",
            "SigmoidNAG with QG Testing Accuray at 471 iterations is 0.959641255605 with loss: -647.100458955955\n",
            "SigmoidNAG with QG Testing Accuray at 472 iterations is 0.959641255605 with loss: -646.917896388874\n",
            "SigmoidNAG with QG Testing Accuray at 473 iterations is 0.959641255605 with loss: -646.736669745997\n",
            "SigmoidNAG with QG Testing Accuray at 474 iterations is 0.959641255605 with loss: -646.556697535919\n",
            "SigmoidNAG with QG Testing Accuray at 475 iterations is 0.959641255605 with loss: -646.377914862917\n",
            "SigmoidNAG with QG Testing Accuray at 476 iterations is 0.959641255605 with loss: -646.200276029241\n",
            "SigmoidNAG with QG Testing Accuray at 477 iterations is 0.960139511709 with loss: -646.023756421922\n",
            "SigmoidNAG with QG Testing Accuray at 478 iterations is 0.960139511709 with loss: -645.848353159930\n",
            "SigmoidNAG with QG Testing Accuray at 479 iterations is 0.960139511709 with loss: -645.674084518843\n",
            "SigmoidNAG with QG Testing Accuray at 480 iterations is 0.960139511709 with loss: -645.500988557650\n",
            "SigmoidNAG with QG Testing Accuray at 481 iterations is 0.960139511709 with loss: -645.329120666889\n",
            "SigmoidNAG with QG Testing Accuray at 482 iterations is 0.960139511709 with loss: -645.158550080646\n",
            "SigmoidNAG with QG Testing Accuray at 483 iterations is 0.960139511709 with loss: -644.989355970512\n",
            "SigmoidNAG with QG Testing Accuray at 484 iterations is 0.960139511709 with loss: -644.821623276494\n",
            "SigmoidNAG with QG Testing Accuray at 485 iterations is 0.960139511709 with loss: -644.655438016331\n",
            "SigmoidNAG with QG Testing Accuray at 486 iterations is 0.960139511709 with loss: -644.490882809991\n",
            "SigmoidNAG with QG Testing Accuray at 487 iterations is 0.960139511709 with loss: -644.328032561629\n",
            "SigmoidNAG with QG Testing Accuray at 488 iterations is 0.960139511709 with loss: -644.166950563834\n",
            "SigmoidNAG with QG Testing Accuray at 489 iterations is 0.960139511709 with loss: -644.007685179590\n",
            "SigmoidNAG with QG Testing Accuray at 490 iterations is 0.960139511709 with loss: -643.850267357696\n",
            "SigmoidNAG with QG Testing Accuray at 491 iterations is 0.960139511709 with loss: -643.694708867287\n",
            "SigmoidNAG with QG Testing Accuray at 492 iterations is 0.960139511709 with loss: -643.541001263874\n",
            "SigmoidNAG with QG Testing Accuray at 493 iterations is 0.960139511709 with loss: -643.389115957143\n",
            "SigmoidNAG with QG Testing Accuray at 494 iterations is 0.960139511709 with loss: -643.239005132906\n",
            "SigmoidNAG with QG Testing Accuray at 495 iterations is 0.960139511709 with loss: -643.090603365505\n",
            "SigmoidNAG with QG Testing Accuray at 496 iterations is 0.960139511709 with loss: -642.943830217765\n",
            "SigmoidNAG with QG Testing Accuray at 497 iterations is 0.960139511709 with loss: -642.798593289939\n",
            "SigmoidNAG with QG Testing Accuray at 498 iterations is 0.960139511709 with loss: -642.654791864305\n",
            "SigmoidNAG with QG Testing Accuray at 499 iterations is 0.960139511709 with loss: -642.512320973026\n",
            "SigmoidNAG with QG Testing Accuray at 500 iterations is 0.960139511709 with loss: -642.371075694868\n",
            "TotalEnAdagradTimeDiff = \n",
            "59.75577688217163\n",
            "AveraEnAdagradTimeDiff = \n",
            "0.11951155376434326\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACCLUlEQVR4nO3dd3hUVfrA8e+dlkpCCSSBBOlNKRICIqIiISCKImIv2LCh4KJSLCgbimtbUFH3hyDu2kV0XUWUqtgQCVEURKqESEJoCaROZs7vj5uZzCQzySSZSSHv53nyJHPvufeeOZR5856mKaUUQgghhBD1xFDfFRBCCCFE0ybBiBBCCCHqlQQjQgghhKhXEowIIYQQol5JMCKEEEKIeiXBiBBCCCHqlQQjQgghhKhXEowIIYQQol5JMCKEEEKIeiXBiBDitHLhhRdy4YUXVuuaZcuWoWka+/fvD0idhBCVk2BEiEbiu+++48knn+TEiRMBfc68efP4+OOPA/oMIYRwpcneNEI0Ds8++ywPP/ww+/bto0OHDgF7Tnh4OOPHj2fZsmUBe0YgFRcXA2CxWHy+xmazYbVaCQoKQtO0QFVNCOGFqb4rIIRouvLz8wkNDfXrPasThDgYjUaMRqNf6yGE8J100wjRCDz55JM8/PDDAHTs2BFN0yqMcXjzzTdJSEggJCSEli1bcu2115Kenu52n127dnHllVcSExNDcHAwcXFxXHvtteTk5ACgaRp5eXm88cYbzmfccsstXuu1YcMGNE3jvffe45FHHiEmJoawsDAuu+yyCs++8MILOeuss9iyZQvnn38+oaGhPPLIIwAUFRXxxBNP0KVLF4KCgoiPj2fatGkUFRVVeOabb77JwIEDCQ0NpUWLFpx//vl8+eWXbs8pP2bkxRdf5Mwzz3ReM2DAAN5++23neW9jRl5++WXOPPNMgoKCaNu2LZMmTarQTeZ4X9u3b2fYsGGEhobSrl07nn76aa/tJoRwJ5kRIRqBcePG8ccff/DOO+/wz3/+k6ioKABat24NwNy5c3n88ce5+uqrueOOO8jOzubFF1/k/PPPZ+vWrTRv3pzi4mJGjhxJUVER999/PzExMWRkZPDpp59y4sQJIiMj+c9//sMdd9zBwIEDufPOOwHo3LlzlfWbO3cumqYxffp0Dh8+zIIFC0hKSiItLY2QkBBnuaNHj3LxxRdz7bXXcuONNxIdHY3dbueyyy7jm2++4c4776Rnz55s27aNf/7zn/zxxx9u41dmz57Nk08+ybnnnsvf//53LBYLmzZtYt26dSQnJ3us2+LFi5k8eTLjx49nypQpFBYW8ssvv7Bp0yauv/56r+/pySefZPbs2SQlJXHPPfewc+dOXnnlFTZv3sy3336L2Wx2lj1+/DijRo1i3LhxXH311Sxfvpzp06fTu3dvLr744irbT4gmTwkhGoVnnnlGAWrfvn1ux/fv36+MRqOaO3eu2/Ft27Ypk8nkPL5161YFqA8++KDS54SFhakJEyb4VKf169crQLVr107l5uY6j7///vsKUAsXLnQeu+CCCxSgXn31Vbd7/Oc//1EGg0Ft3LjR7firr76qAPXtt98qpZTatWuXMhgM6oorrlA2m82trN1ud3vOBRdc4Hx9+eWXqzPPPLPS9/H666+7te3hw4eVxWJRycnJbs966aWXFKCWLl1a4X39+9//dh4rKipSMTEx6sorr6z0uUIInXTTCNHIrVixArvdztVXX82RI0ecXzExMXTt2pX169cDEBkZCcAXX3xBfn6+X+tw880306xZM+fr8ePHExsby8qVK93KBQUFceutt7od++CDD+jZsyc9evRwq/9FF10E4Kz/xx9/jN1uZ9asWRgM7v91VTbotHnz5hw8eJDNmzf7/H7WrFlDcXExDzzwgNuzJk6cSEREBJ999plb+fDwcG688Ubna4vFwsCBA9m7d6/PzxSiKZNgRIhGbteuXSil6Nq1K61bt3b72rFjB4cPHwb0sSZTp07ltddeIyoqipEjR7Jo0SLneJHa6Nq1q9trTdPo0qVLhTEY7dq1qzDAdNeuXfz2228V6t6tWzcAZ/337NmDwWCgV69e1arb9OnTCQ8PZ+DAgXTt2pVJkybx7bffVnrNn3/+CUD37t3djlssFjp16uQ87xAXF1chIGrRogXHjx+vVl2FaKpkzIgQjZzdbkfTND7//HOPM0LCw8OdPz/33HPccsst/Pe//+XLL79k8uTJzJ8/nx9++IG4uLiA19V1/IiD3W6nd+/ePP/88x6viY+Pr9Uze/bsyc6dO/n0009ZtWoVH374IS+//DKzZs1i9uzZtbq3g7eZOEpWThDCJxKMCNFIeOuK6Ny5M0opOnbs6MwmVKZ379707t2bxx57jO+++44hQ4bw6quvMmfOnEqfU5ldu3a5vVZKsXv3bvr06VPltZ07d+bnn39m+PDhlT67c+fO2O12tm/fTr9+/apVv7CwMK655hquueYaiouLGTduHHPnzmXmzJkEBwdXKH/GGWcAsHPnTjp16uQ8XlxczL59+0hKSqrW84UQlZNuGiEaibCwMIAKU0vHjRuH0Whk9uzZFX4TV0px9OhRAHJzcykpKXE737t3bwwGg9sU2rCwsGqv8vrvf/+bkydPOl8vX76cQ4cO+TST5OqrryYjI4PFixdXOFdQUEBeXh4AY8eOxWAw8Pe//x273e5WrrIMhOP9O1gsFnr16oVSCqvV6vGapKQkLBYLL7zwgtu9lyxZQk5ODpdcckmV70sI4TvJjAjRSCQkJADw6KOPcu2112I2mxkzZgydO3dmzpw5zJw5k/379zN27FiaNWvGvn37+Oijj7jzzjt56KGHWLduHffddx9XXXUV3bp1o6SkhP/85z8YjUauvPJKt+esWbOG559/nrZt29KxY0cGDRpUad1atmzJeeedx6233kpWVhYLFiygS5cuTJw4scr3ddNNN/H+++9z9913s379eoYMGYLNZuP333/n/fff54svvmDAgAF06dKFRx99lJSUFIYOHcq4ceMICgpi8+bNtG3blvnz53u8f3JyMjExMQwZMoTo6Gh27NjBSy+9xCWXXOI26NZV69atmTlzJrNnz2bUqFFcdtll7Ny5k5dffpnExES3wapCCD+ot3k8QohqS0lJUe3atVMGg6HCNN8PP/xQnXfeeSosLEyFhYWpHj16qEmTJqmdO3cqpZTau3evuu2221Tnzp1VcHCwatmypRo2bJhas2aN2zN+//13df7556uQkBAFVDrN1zG195133lEzZ85Ubdq0USEhIeqSSy5Rf/75p1vZCy64wOsU2+LiYvWPf/xDnXnmmSooKEi1aNFCJSQkqNmzZ6ucnBy3skuXLlVnn322s9wFF1ygVq9e7fYc16m9//rXv9T555+vWrVqpYKCglTnzp3Vww8/7Hbf8lN7HV566SXVo0cPZTabVXR0tLrnnnvU8ePHfXpfEyZMUGeccYbXthNClJG9aYQQNbZhwwaGDRvGBx98wPjx4+u7OkKIRkrGjAghhBCiXkkwIoQQQoh6JcGIEEIIIeqVjBkRQgghRL2qdmbk66+/ZsyYMbRt2xZN09x21PRmw4YN9O/fn6CgILp06cKyZctqUFUhhBBCnI6qHYzk5eXRt29fFi1a5FP5ffv2cckllzBs2DDS0tJ44IEHuOOOO/jiiy+qXVkhhBBCnH5q1U2jaRofffQRY8eO9Vpm+vTpfPbZZ/z666/OY9deey0nTpxg1apVPj3Hbrfz119/0axZsxotVS2EEEKIuqeU4uTJk7Rt27bCbtuuAr4C6/fff19hH4eRI0fywAMPeL2mqKjIbXnqjIyMau/UKYQQQoiGIT09vdLNOAMejGRmZhIdHe12LDo6mtzcXAoKCjzu4jl//nyPu2m+9tprhIaGBqyuQgghhPCf/Px87rjjDq9bLzg0yL1pZs6cydSpU52vc3NziY+PZ+zYsURERPjtOVarldWrVzNixAjMZrPf7ivcSTvXHWnruiHtXDeknetGINs5NzeXO+64o8ohFgEPRmJiYsjKynI7lpWVRUREhMesCEBQUBBBQUEVjpvN5oD8hQzUfYU7aee6I21dN6Sd64a0c90IRDv7er+AL3o2ePBg1q5d63Zs9erVDB48ONCPFkIIIUQjUO1g5NSpU6SlpZGWlgboU3fT0tI4cOAAoHex3Hzzzc7yd999N3v37mXatGn8/vvvvPzyy7z//vv87W9/8887EEIIIUSjVu1g5KeffuLss8/m7LPPBmDq1KmcffbZzJo1C4BDhw45AxOAjh078tlnn7F69Wr69u3Lc889x2uvvcbIkSP99BaEEEII0ZhVe8zIhRdeSGVLk3haXfXCCy9k69at1X2UEEIIIZoA2ShPCCGEEPVKghEhhBBC1CsJRoQQQghRrxrkomdCCCGEKMdmgw0bYN062L8fPI3ftNvhyBEoKICQEGjdGsovOFaujKF1a7qXlKCFhMDw4WA01sW7cSPBiBBCnI5cP7gOHID27eGii+DCC8s+bGw22LgRDh2C2Fg491z99bp1sHcvZGf7/qEWGgqJifqHmeszytfF04eolw9Qg93O2X/9heGdd8BgqNEHbaMo40u59HT48UcoLq54bS0ZgR4Ay5dDq1bwf/8H48b5/TmVkWBECCGqUu7D1GCz6R+Sb70Fx441nA81R5mDB2HPHigpcT8/bx6YzTBwIOTmws6d/v1wW7MG5s/XnzFoEMTH64HQpk0V6+IDI9Def7UTvjh6FK68Ej78sE4DEglGhBCNS2W/ZQfiN1UPH+yN+kPSaoVvvw38M775JrDPEIE1ZQpcfnmdddlIMCKEqL26CBDsdti+HXbsqNFv2UKIajh4UO+yu/DCOnmcBCNCiMp5CzSq6hIQQjRuhw7V2aMkGBHidGKz0ernnzF8/70+4K22o+0l0BCi6YqNrbNHSTAiRCA4sglr1sDmzXU22t7044+cF4DR9kKIJiYuDoYOrbPHSTAiRE3YbLB2Lbzxht514RocBHAKXlU8hDBCCFF9CxfW6XojEowI4eA6NqKyNRbS0+GHH6TrQghx+pF1RoQIoKoCjYMH6y2bIYQQNVGkQVqHIA610DMYSilQiqhTdoKtGiVBRnIjQzCbLISaQwkxhwAQZDATkVOEsagYW7CFwhYR7DbaCb9yDO3H3kRcizPq/L1IMCJOP+Vnfxw4IIGGENVlMkGPHhAR4f+Bzj16wNlnV7xPuUykzW4n46+/aNe2LcYqVmA9Zc3nROEJThblYjh8BArzOWVUHAnTKFZW/YMaMGgGTJqRNnkQVqJBSCiqTWuaBUXQPDiSMHNopXXy+P49lMnOP8qRgiPkF+VhOXYc8orIwU5mCNiUDaVAw4jCBig0FK0L7ITaFEUWA8ciHFvHaeRZ852PVBr82RzWdYSvOoDdUFRFY+dXcd7FgR+JePUZ/n3Fv0lom0BcRJzv19aSBCOi8XMNPr76qsarPQrhE7MZ+8CBHDQYaBcTg7EhrsBafnn2oUPLlnnfv1//N3PkCBQW6svE9+sHx4/rQYWnZeN9UdkU8KNHISwMhg4l/eaxbDuxk+OFx90uP5p/lPScdE4WnQQgvySf7FPZ7Ms8jBacTZHN04fuXkAPMPad2Icdu+/1LXsykK7fBwMdmndwBi6enmUymEBBifL0f4xepqREIz1vbw3qUv9yi3MZ+95YooKjOfjgnwSZgurkuRKMiMbB23909ThYVDQABoO+n0p8vP46UHuFlNt3xWa3s3XlSmJHj8ZoNgf+fVYiPSeddfvW8evhX8nKy6LA2oJ8axA5hTmcLP6Mkh3/xfSHiQhLBJG9IlFdQyg4GQp5/QkpiqeV1oXQI70xnIqDZhBuhfBvgW/h5EnIyoL8fL0ZcnL0YwYDhIdDZKQ+xCA6GuLjjXTpMpze9wwnLq6sbtsOb2P3sd2k56Tz18lUlr/6CMX2av57rcYv97Vhx87eE40ziPArBScOxKNKLHUWJUgwIgLLZkNbt44eb72FYdOmstX8vvqqLKioxw2iRAC47ksC/v+tv7AQOnSACRP03+DrYYdR7DX5Dbyi9HTYtg1279Z/zsrSkwg5OXC0JJ280G2citxMUdgebEFHUZYc7KaTKFMBihIUChXxJxg8/SbvIwVYNDC2B7sF8oACl9/6I0u/AOxmKIqEvDZQ0AryouH3ePiuCxzuDblxEJlOTN9tFLb6nhNnPgumwprXTdQPDTrum0NQUN3Nz5NgRPifI4vx8svw6aeYiovp7jg3f349VkzUmmug4euOrU1Eero+LjozUw8ufvtN7/VwZBNKSiDfnE6xKRtbcCYlEbs5qv0GkQchKAcsJyGsBJpZwWCFFgfA6J+gp0pmBVF/1u4eVg1y4qHFQTLrqt7C/xTw1wBemJzsMWEYKBKMiNpz7ULZuFEfsyFZjIbBZIJzzinLUkDtxh4EKNBwZAiOuwwjOHpUP753L5w4oR8rKtI/2AsKyoYFhYRAWGw6QS2ziYyE4KhMaLEbItIhPAvNUkCoKRSlKY7mH6XQqv+mHmIOIdgYTIGtgJzCHIpLigkyBWExWgDQNI1gUzCtQloRHR5NfGQ8LUNbYrPZOHzqMN/s3sYHr//M8eMGjh+HH3/OwWbIA+xQHK4HF5EHoU1poGEohta7wGjze/s1CGYFUQfquxaitjToenAOI0fW7apFEoyImisuhjvvhLff1nfpFJ4ZjdC5sx4QBHIFVtBnHxw6RLtzz8WYlNRgsxTp6bDup3S++yWbA3/qC9U6xxyHZULL3RB8Qv8Qb7EX2mfpP5sKwFBu4KDdAK32u3/IF5R+ZQX4jZwq/R4CnBPgZwkRaPWUFQEJRkR1uGZAPvpI3z1V6KP5evWCs84qCw4MBjjjjJrNSvDCtRugfAbht9/073l5VjKOHyNqU0sMm80wH4KDocUZ6cR2ySY+Hrp00QccumoT1qbCNL7ygw+z8rI4mn+0dGDkSQwYMBvKBm8GmYKIDI50ZhIigiOIDIok0qaPJ9i3X/FL5jb25+4mde8+GPAvMBfAGcDttW4eIURt1VNWBCQYEZVpyt0vVa2x4CHYSM9JJzs/m8xTmew+tpvcolzge/j2ewAigyJpGdqSlsEt6R3du1pz+Hfv1odqHDtWVUkz4BJpRKRDTCr0ngC5OfAb+lc5BlsQ/Yw30aFFPKEhENz8OG/ufJVCm58GH1rR2yzErmcRoqu6QAjhlQIKm4PN4vm8sRgsuVAcATaznmU0ecleK8r2kcion6wISDAiHMpPnf3zz9N3vQ5vgUYNshnpOels2/sFvx/5nVnrZ5FnzfOpCiGmEOYMm4PJaOK39HSOncojPw8KToZDTjyGwpYUFkLRiZbYDvXml2/isFVnqIEjCBl3MwTnVlncbiwilddIPQ4cB/6qxrN8YQZqtAaEELVgM0FBSw8nFIQcq9vxOx4CCM2gH3cua+IWRHgJNEqC4ZMlsDfJ92d3WgOX3V5xZlNJMGyeBImLAOh6YG69ZEVAgpGmrdysl9M269GjByQk+LXbJD0nndRDqdz80c3kFlf9YV9eQUkBD65+0PPJ4NIvgBjgjAj469+QFwuhRyDkuOfrClpCfisIP+RzECJEvSsp/RgylfvFp8QMhS0qlvflAxuq/tD29gFd3Wf5GEBo/1tC5NEkLBa963TJEkgqrdqaNXD77ZCbq39FRIDFy62Ki0vLNPdeprzgkiSWXKLPlrr9dn12vPM+EWD+42GUKuCF/1jqJSsCEow0PcXF8NJL8O67sHXr6Zf5MJmgZ0/o1ElfdfL++33/F1uOpzETBdYCsvOy+Sb9G2yqjn6rCsmFG8bqiQVDFWVdU66iabIZAQXFzfQxOabich/sCoKPV/zwrwt2IL9N2WtHwAAw7gYIOaJ/qBdH0PyrJZjTh1NUVERQUBBa6aek64dolR/YEWBp46XMsSRyX/jT9/u4lFFKn+HlOm6/eXPP93EGHv/0/AzQg5I/azmz2leenmO1lrBy5WqGDx9dN5XwQIKRpuThh+G551xygo2Y65TVAAwW3fjrbi7970ByS7xkIeqaoupABCQQOZ3ZzFAc5vwtXFMVP/k0WzAhXy6h4LckIiKATms4ed5kmn3zApaDZRmC4rg1nBh+AwQfIdgYQUSYheIiyNVXYickRJ+0ZUf/rd9RxkEpxYnCE1jtPsyic9b7FMHfzSVi2zSPxYpfyyI3F6Ki4K23IOl5sFqtrFz5BaNHj8ZczyvdlufIZoB7lkPUjAQjp6vyY0C++goyMuq7Vu4cC2i1a+fb1NZaBh2e1rJw1bKlvrT1ln27uXfrQO/dIfVBgozTk9JAU/oHtjUMzLmEWSIIC3YPNIJNwSy5bAlJnar7iZcEbPdyvHbzntfsXcPt/72d3OJccotyiQiKcK7R4lDzejd8dZnNaAokGDmdNMQuGLMZ+6BB/BEdTdfERIy5uXpQceGFdbIGRnpOOut+28b+zOM89Q8oLChXoKBl2TLWAHEb4cZL9a4RcXpwdlGoirMKbCYoaAHBOeW6M8qVraz7y2YAg93DeQ1QmDATHhRGbrH7B3awKZhJiZNYlraMFy5+odF9YCd1SuLPv8mnsfAPCUZOBzYbXH89vP9+fddEz2icd54+XqM0g2Gz29m5ciWd63hTsd1HdzNw8UCOF5VmOLx1h56Khn/+CcYiuO2C2u3zIWrO2we+zYyhuAURzQBTsdffwgGKiyAnF5Rdv5fBHkzE+iXOLoriuDXkXng7dmMhWIMJW7uEsKwkiuMqdmcUx60h58LbUXYI3jaJ4r6LUI7BjgoUCoMthJDVSygohIgbbscSpp+vTqAxbYjnbgshmhIJRhq75cvhhhvqfyaMxQLTp8MTT1TMdvhpU7Hq2H10NwNfcwlEvFFAcQic+a7+wm4Grfj07xapyUDXCrMblN6VZSwp624oMevTFytb18DBZkYraoGmQVRkMJedmczraa+jaRol9hLMBjOx4bEsudyfaf4kwNNv8566M8qXLQsa9LEMK/WxDM85AuyK95VAQwjfSDDSmD38MDz7bP0822zWB5C6ZEDqatlxx+Ji2/Zl8t3vu9l1OJ1TRWXre5gI5if+hdWXfcc1oOV+GHeL/ytq1/QsS0Oa4WIzw6lY2J0M/ZbpAwvN+RUDB9eZOzYTnGzreZpkpzVw8WRIu0W/3+cv6GXKT5t0TH+0RtA83EJEmOexBIsvW8yavWuY/PnkRtl1IYSoGQlGGiObDa69Vs+K1KWePeGKKwIWfDim0h4v9JzNaBnckm6tujFk6RCy8gK96UgNObIHjsWE+i3TP6gTX4Jmh/QsgiubUc8qOKZZ2gG7ye/TLl2zDOxNYvJkuOW8xSxbBrf8fQ3P7bqdIzmF2G1UWAiJT5bQ5pQeFKjW5aY07k2CRdsxmaDlLj0LENweJt2VxLJlf/LCC3qxyZPhhRd8m3GQ1CmJ7ZM8DboUQpyuJBhpbJYvh5tu0letCRSzGQYOLN0ONazW63X4oqikiAH/N4DD+YcrLWexR2C2twQjDSfbAHr2I6d9xezBt9PKvndaDdeNAXORfswaTOTnn6ChlU6zPEbYprlcd2F/luZcjz0ku8rHmjUzVuW9O8SgGYhrFufe1dEJtpd+1k+bBpDEtNIuBsd0xcJCKP5tGqdOwdy5jnJUKAMVF3BycL1mu8QWQohKSDDSWAR6kKrFApdeCvfeWy87vVqMFtpHtq8yGCk25FJsqKeZLjYjFLQqfaHKZmAoDdbMh2+nuxUPDYV8156ivSMI++RTCkbcjmaAeYOWMG2O4xPcPdPzfyqLgYsH8tOhn7xWZ95F80hsl8htH99GZl5mhTUfNDQ+v/5zkrsk+/wWfZmuKFMahRD+JsFIY7B8Odx4IxQV+f/eAwfCvHn1vtW8pmnc22MOtx0aVW91qJTdAG99DntHlB1zjJdwjJNwMWCAvrXPoEHwU2k80a0b/P5zEppW9Se5pmnMT5rP7f+9nUJbYYVFprq16saM82agaRoHph5gzd41bkGJhsb84fOrFYgIIUR9kWCkIQtkNiQiAl57Da66yi+3c2xv77Dt+CZ+Pb6JvJJc7DY7WVl7+PmbnzEY9VGRZ0SewbCOw5w71278OZ3JE6MgqQe0/r3BdcHcYlrJu3+NwK1zrHS8hCuzGWJjYf58fTmV+fPLVmlctMjzWm7elF/HwbHIFBosGr3IuTy2o+yBqQdY9ccqJq6YyOJxixnVrYEGdkIIUY4EIw2RzQYpKXpnvT8WLnOsdHrGGX5fNh08bG8f9Rvce06F5cs//tr9dTAtuEfbjNWueKlwEFx/jICzoY83qYaR0bfx+j0juWGwPhDzllv0teUyM8sGcppM0LZtxbET/uzS8GWRqeEdh/NSz5cY3nG4fx4qhBB1QIKRhmb5crj5Zn1p9NowGODyy2HSpIB2wezerff0OJdYNxbBLcN82kelkOP889RAQIOwOghElKZ3tYy+D6J2+3TJgLYD+PyO1wA9sHAd+Cl7UwghhH9IMNKQ+GvdkKuugnfeCfgYkKIiGDLEJRCJSIc2v0BxOKhs37pawo7p61g41uQIpDVzYe9I2v78MoeTRlOivGedHFNh5w+f79Yd4koGcgohhH9IMNJQPPggPP+8f+5TRwuhZWXpO2wePoyeEblzAIRXPhumAgXkt4Jmflg3pMQMRZEQeqRiIHSkG3w7A5MJlj0+AjqtZMzbYyiyuw8KDsyqn0IIISojwUhD8Le/wYIFtbtHSAi88YbfBqSW57rj7dGjsG8f/OtfLr1JNou+zkbY4eoNPtWofSByqhVaYRvmn/8C069KYlTKP/jCNqOsHtZgWPkSmqbx2WcwYgTACD694VPnbBU4vXcYFUKIhkyCkfp22WXwv//V7h4B7JZJT4fUVH0YS26ly3tosG4O3OTnGRxVdd/YNaK+eZt3UpKdYzZWPT6df3yQwIzvSgd0lC5ENnceJLvMdJVdR4UQomGQYKQ++SMQCWC3TFGRvl7G4fI9LxHpEOZhddD8KDjcE1rv8N/U3F8mEH/ODwSFlLD7eMVBp7d1mMuS7yuupTH9qiT6N/+Tyy7TVwpNTIQZM/xUJyGEEH4lwUh9sNngmmtqF4gEB8O//x2wbhnQF2WN6ZbOYWNp4BGWCVG/w7DHIKiWs318YTPx+V1LGDXKwJq9a7h++fVkF5QFQQPaDuC1W7xHGCNG6E08ebK+rlt11vgQQghRdyQYqWu13VvGbIZHHoHHH69Wt4xjp1tv2oS1IS4izlku81Qm3//xO78nzYKkPK/X+UyhbwJXjZ4kk9HCsCQrEERSpyQOTzvstvBXZTNdHFyn4wohhGiYJBipS9OmwTPP1OzaGgYhoG9Cl7g4sdKdbmPCY9g5aWeV5Wostx389zW46WLfunAU9I3ticXovjmfjPMQQojTjw9LUwm/+OCDmgciV12lT1t58skaDVJ1bEJn8PLHbcBAm+B4/vg1nHCtdc3qWJVPX4G9o2DrBN/KazB3+NwqMx9CCCEaPwlG6oLNBnfcUbNrH3hA35umFjNlNE1j8sDJ2LF7PG/Hzu43J5N4jpU92ek1fo43ZoJoefxCWrdWRP2wFEosVV6TEJtAcmfZ5E0IIZoCCUbqwty5Vc2L9WzMGPjnP2v9+KKSIh5a/VClZfKHPAwoONZVH9/hR4+d/whLX1tHRkYJ2VkG5iY/UeU1cy+SrIgQQjQVEowEms1Ws+6ZMWPgk0/8UgVHN43mbbCG0iA3HmxB+lohfowBgoxBTD93utuxmefNpGuLrl6vGdB2gGRFhBCiCZFgJNCuvx5OnareNQ884LdABPRumpRhKShvKQ9NwboUQIM9yZAxwG/ZkceHPo7B4P7XTNM0Fl2yCLPB7PGaOcPmSFZECCGaEAlGAumhh/TxHtXx4IN+6ZopL7lzMoltEyueUAbISNSDkIh0iN0KaRP8kh0JMgYxc+hMj+dGdB7BZ9d/RpAhyO24ZEWEEKLpkam9gfLee/Dcc76Xt1jgzTcDsoiZY+2Qm/vezOa/Nruf1Ozww2QwFsOdiRBevWm9IaYQCko8L4D2xAVPYDAYsNlsHs+P6Oy+P0ywKdintUOEEEKcXiQYCYQPPoBrr/W9fHAw5OToAYmf+bLGCKOmwLHOcCoGQrPB4GHWjQJsZjjRAaJ2AXoWY9Ptm+i5qCd/HPvDrXi3lt2YcV7V66/LuiFCCCGkm8bfVqyAq6+u3jUzZwYkEAEfBq8ChB2DiedC872eAxHQu23e+R+sfJnW5va0j2zP/OHzMRgMvDT6JbfulmBTMC+NfkkyHEIIIXwimRF/stlg4sTqXRMRAY8+WqvHpqdDtteV3jUm907hpr+q2E1XAcEnvZ+3mWD/BST0C2bzzD/d9nlx7W5BgyWXLSGpU1I134UQQoimSoIRf7HZ9I1Qjh2r3nVLltRqQbOiIujfH44c8V4msnkyZ81O5NejP4HB24wa9Cm+mpfzxzuBLYi5cz1vOCfdLUIIIWpKghF/qOnmd1dfDePH1+rRSsHx4+gzYcI8p0dyAOs7k2HUTZ5vYjfqY0ai/vB8HuDzhQwYoJEsE12EEEL4mQQjtVXTze+Cg+Htt2v9+KAgiOuzmz9HDIJQ71mZ/JPRcKo1hHsIWAw2+HwhXDQLYrdUHDdypBvsGcmcVZ6zIkIIIURtSDBSG7XZ/O4//6lV94xDsa2IE+OGgK2S7iEFFLTUMyDlgxGlwV8DYM9IQIObPIwtkayIEEKIAJLZNDVVm83vHn641t0zDhajha7RZ+hBhTca0GYHxPzq4ZyCH+/RFzvLj4K8Vm6nDSfbE2s+k/nzJSsihBAiMCQzUlM13fzu3Xfhmmv8Vg1N05gzLIVRb1UyW0bhfUVVOzBiptfFzuzNDqDuGMjQC/cDQR7LCCGEELUhmZGasNlg4cLqX+fnQAT0ab0lmT3pENbD+34ylWU0ikMgv5XXzIqGRnxEPBZjYNZBEUIIISQzUhMbN1Z/Cu9DD/k9ECkqggGDijh8w0A9s1GTbpTgAgje7vW0QpEyLEUWMBNCCBEwkhmpif/+t3rlH3yw5gNdK2GxQPs4C+S0B7v/gwWjZiSxbaJsXCeEECKgahSMLFq0iA4dOhAcHMygQYP48ccfKy2/YMECunfvTkhICPHx8fztb3+jsLprcjQUNpu+oZ0vLBZ9195nnw1IVTQN5qRosC7F+2JmtWBTNsmKCCGECLhqByPvvfceU6dO5YknniA1NZW+ffsycuRIDh8+7LH822+/zYwZM3jiiSfYsWMHS5Ys4b333uORRx6pdeXrxcaNlS936hASAidPBmQXXlfJyTCgZTJkJOqDUb0pH6vY3f/oNTSMWtlUY4NmoFfrXvRq3ct/lRVCCCE8qHYw8vzzzzNx4kRuvfVWevXqxauvvkpoaChLly71WP67775jyJAhXH/99XTo0IHk5GSuu+66KrMpDVZGhm/l7rwzYJvfuXLPjlRW0OXnE+0rLGymUNiUzfnaruxsz97OwNcGUlRS5N9KCyGEEC6qNYC1uLiYLVu2MHPmTOcxg8FAUlIS33//vcdrzj33XN58801+/PFHBg4cyN69e1m5ciU33eRlaXKgqKiIoqKyD8Dc0im0VqsVq9VanSpXynGv6tzTkJmJL0uV2eLjsfuxrpUZNgziikdwML8FhB6v+oLmB3y6r4ZGu2bt0Oxardq9Ju0sakbaum5IO9cNaee6Ech29vWe1QpGjhw5gs1mIzo62u14dHQ0v//+u8drrr/+eo4cOcJ5552HUoqSkhLuvvvuSrtp5s+fz+zZsysc//LLLwkNDa1OlX2yevVqn8u2O3iQAT6U23rwIBkrV9a8UtXUpfPZHMyL8S0Y8ZFCcWnIpXz++ed+uV912lnUjrR13ZB2rhvSznUjEO2cn5/vU7mAT+3dsGED8+bN4+WXX2bQoEHs3r2bKVOmkJKSwuOPP+7xmpkzZzJ16lTn69zcXOLj40lOTiYiIsJvdbNaraxevZoRI0ZgNpt9usaQmupTuX6XXELfCy6oTfV8kp6bzpH8I8T2zwLtaNmJyhY685HJYOLBKx8k2Bxcq/vUpJ1FzUhb1w1p57oh7Vw3AtnOuT4uDlqtYCQqKgqj0UhWlvtqnVlZWcTExHi85vHHH+emm27ijtKl03v37k1eXh533nknjz76KAZDxYEOQUFBBAVVXO3TbDYH5C+kz/e12WDJkqrLxcVhGjbML3vPVKaopIhzXz+XrLwsKB+j+WECTIfmHQgPCffbbJpA/fmJiqSt64a0c92Qdq4bgWhnn3/Rr85NLRYLCQkJrF271nnMbrezdu1aBg8e7PGa/Pz8CgGHsfRDWin/T0cNqI0bfRvAOnFiwAMR0PelaR/ZHoO3P8ZKmlfzIVp5YeQLMq1XCCFEwFV7Ns3UqVNZvHgxb7zxBjt27OCee+4hLy+PW2+9FYCbb77ZbYDrmDFjeOWVV3j33XfZt28fq1ev5vHHH2fMmDHOoKTR8HWxs65dA1uPUpqmkTIsBbu3Ob2VxBE397m50nu3C2/HqK6V7HcjhBBC+Em1x4xcc801ZGdnM2vWLDIzM+nXrx+rVq1yDmo9cOCAWybkscceQ9M0HnvsMTIyMmjdujVjxoxh7ty5/nsXdcFmAy/TlyuIjfXbY9PTITvb+/lerZNJbJvI5owtoJUFJY7Mh1KqQlDStWU3lly2hA92fEC+1fPgosVjFktWRAghRJ2o0QDW++67j/vuu8/juQ0bNrg/wGTiiSee4IknnqjJoxoOX3fpbd0ahg71yyOLiiAxEbI8b6gLQEyMxuJ1KYx53z2LoVBM6DOBN355o8I1L4xaiNFo5JHzHuGx9Y9VON+umWRFhBBC1B3Zm8YX1dml94Yb/DZexGKB9u3BYAAi0iE21e1La5tKyzNTiYmIwpBfNoDYsafMksuWEGp2mQqtoFurbozsMhKAmefNdD9f6rUxr0lWRAghRJ2RXXt9MXeu77v0Xn653x578CDcfDNs3r0bJg6CUPc6KGA7kPgaYC6bfeTYU8ZoNPLY+Y/xyNrSNV00eGFU2aBUg8Hgfh7o1rIsWBFCCCHqgmRGqrJiBfjaxdSqld+7aO5/oAhuH1IhEKnAGub80XWn3RlDZpDYNrHCcQfX88GmYF4a/ZJkRYQQQtQpCUYqY7PBlCm+l5882e9dNNgtkHMG2KsIEI52AaCVJZZb289j61aNgwf1GTfzhs+jZ1RP5g2fVyHQcD3/v+v+x4jOI/xSfyGEEMJX0k1TmY0b9b4SX7RqBY8+6rdHHzwI110HmzeXboJ3UyUDSo90A6UHQUf/8xL3PpIEQEwM7N8PSZ2S2D5pu9fLqzovhBBCBJJkRirj67oi4NesiKOLxrki/p5kyEgEu5c/rs8XQkjpnjQFLQF90Gt8fJ1sHCyEEELUigQj3ths8Oabvpf340JnbrNoACjNjhg8LG52pBvsGQkhpWNK8lsBYLdDSgrI8A8hhBANnQQj3mzcCEeO+F7ejwudaZoeSNhdY489yZAxoMIS79F/3g9tUyGkdJO8ZhkY2qXSa3gqvc7xsYtJCCGEqEcyZsSbQ4d8Lxsf77dZNA7JyXpXzeY/0iG0dAnWPcOh3U9lhRRkJdwPCS4X3nQxdvQpvwNfi2H/lP0EmSpuOiiEEEI0FBKMeFOdTMeCBX7fGE/T4PHZRVy2LhHCvSzBWkkXjAED8RHxWIwyaEQIIUTDJt003gwdCnFxlQ+6MBrhgw9g3Di/Pjo9HVJTIba1BeOp9t4HrlbCjp2UYSmyZogQQogGT4IRb4zGqpeAf+cdGD/er491zKRJSIDERA3bai8DVyvhWA6+/AJnQgghREMkwUhlxo2D5cv1NURcxcfDhx/CVVf5/ZEVZtI4p/X63g3kWA5esiJCCCEaAwlGqjJuHDz9tP5znz6wfj3s2+f3rhmHijNpHNN6bT5db9AM9Grdi16tewWkfkIIIYS/STBSFZsNfvxR/zk6Wh9L4ufBquU5ZtJUyI6o0kyHosIUXwe7srM9ezsDXxtIUUlRQOsphBBC+IPMpqnMihX63jSOJeFXr4YOHfSxJDXMjKSnQ3a29/Nt2ujjZlNSYJRzBfhyS8L70PvSrlk7mUkjhBCiUZBgxJsVK/TBqapcCiIjQz++fHm1AxLH4NQsLzN1oWw/meRk6NIFdu/Wj2v7klHFYWDJ07MiVQQkc4bNkTEjQgghGgXppvHEsVtv+UAEyo498IBerhoqLvPuznU/GU2DsWNdHmvXaGGJ1l9UEWN0a9mNkV1GVqtuQgghRH2RYMSTqnbrVUrvb9m4sVq39bjMu4vy+8nEx5edS0yEVi1L/7iyu3sdMwJwf5eFZGRIVkQIIUTjIMGIJ74uBV+dJeNLVRicWspo1I8nuywNkpOjf2/eHObNg1PFp/QDmyZ7z44c6cb9o0eSmKh3CwkhhBANnQQjnvi6FHwNNsfzlh2x2SrususIRu64A5KSIK84D4AWJ0Z43DQPgM8XYjBozu4eIYQQoqGTYMSTqpaC17RabY6XnAzdu5e99pQVgbJgJDISlFLOzMioYeGwbk7F7MiRbrBnZIXuHiGEEKIhk2DEE9el4Mt/ojte12JzPE2DiRPLXnvKigCcOKF/j4yEwpJCVGkqZHBCOOxJxpA5oKywNRhWvoTRqHkMbIQQQoiGSoIRbxxLwbdr5348Lq5G03pdpadDeLj7LaOi9M3xUlPLxs66jhlxjhcBYluHAhpxv8+HE+31r3f+B3tHeA1shBBCiIZK1hmpzLhxcMklEBysv/7kExg9ulYrsHpaa+TgQRjgkuRwrDXi2k2TZ9XHiwQZQjhxTH++fXcS8Xv+JD1dL2c0Qv/+khURQgjRuEhmpCpWa9nPSUm1XgresdZIZcNRWraEX3+FzEz9WFYWfLtZz4wUnQx3dvEcPIgzEAG9u2fWLMmKCCGEaFwkGKlKYWHZz0FBtb6dYzaNp/XUQD++fbueKTlwQD92551w4616ZoTiMK/3Dg3VEzdCCCFEYyLBSFUcwYjF4n3p1GpKToauXSse1zS9R8hjZsNSOmakONzDSd1jj/mtikIIIUSdkY+uqhQU6N8d40b8QNPg2msrHldKj33csiYR6RCbCtG/AKVLxbdN1Y/FpkKEPto1OloPclwHwAohhBCNgQxgrYojM+LHYAT0gaZVMhbBnYkQXjbatbjFr3BnQlmZkzGwYD9ZWUHOQbCOAbB+6FUSQgghAk4yI1VxBCMhIXX/bJsFctqD3csfk90AufF6uVKum+0JIYQQjYEEI1UJUGbE22Z5oHfj6FkNDdalgMFLYYNdP++yFKusviqEEKKxkWCkKgEKRlwn6ZSnlMsmd3uSISMRrfza73YjZCTq50sZDNC3r6wzIoQQonGRYKQqAQpGfJ/1otHtYIpzKfiyG9g8ZkUOHIDiYn/VUgghhAg8GcBalQAFI0eOlDsQkQ5h2RXKmc0wZWIUs3a14mjBUf2g3QiH+rtlRRw6d5bxIkIIIRoXCUaqEoBgpKgIHn3U5YCHWTMOVmDSL2A2mMsOesiKOMyZI+NFhBBCNC7STVOVAKwzYrFAq1YuB6qYNWPAQKgp1Pk69EQihv0VsyIDBsh4ESGEEI2PBCNVCUBmRNPgiivcjlQ6a8aOndbhrQFo16wdjw2eh90mWREhhBCnBwlGqhKgMSM9e5Y7sP8CsHnvNdt9bDcAL178IjOuSiIxsWzPPqNR3wlYsiJCCCEaIwlGqhKgYKTCRnm2IDjeqcrrWgS3cG62Z7OVXmqTtUWEEEI0XhKMVCVAK7Da7UBEOsEdHfvMbIVN91d5XURwBKBnQRIT9WOSFRFCCNGYyWyaqgRq0bMSfQZNoYcZNOUZNSMKhV3ZaWZpBuhZkHnzYPJk/btkRYQQQjRWEoxUJVCLntlLZ9CEZYNWydrwgE3ZnD83C2rm/DkpCbZv92u1hBBCiDon3TSVsdlg3z7954yMskEafqBU6QyaKgIRTRnoH1u2xa8jMyKEEEKcLiQY8WbFCujQAVat0l8vXqy/XrHCL7e32YA9ybQsTMSoGb2WU5qdhwY/BIBBMxBqDvVaVgghhGiMJBjxZMUKGD8eDh50P56RoR/3Q0Ci79qr0ePEZLdumPKaEUOQKQiAEFMIWzO3knooldRDqRzMPej1OiGEEKKxkDEj5dlsMGWKh7m36Mc0DR54AC6/vGyhjxqw2wFjEalRD1Va7iSZXPn+lQDkWfNI+L8E57mY8Bj2T9nvDFaEEEKIxkgyI+Vt3FgxI+JKKUhP18vVgs0G2CyE2dqjedhjpioaGvER8ViMsiueEEKIxk0yI+UdOuSXcunpkF1xE16n48eBiIN0y7uZ74M2+16/UgrFrPNnocmcXiGEEI2cBCPlxcbWulxRkb4QWVYlS4iERerrjHzvwzojnoSaQxnddXSNrhVCCCEaEummKW/oUIiL876KmKZBfLxezguLBdq3B4OX1jUYICKsdJ0RVbM/gkfOewSDtwcIIYQQjYh8mpVnNMLChfrP5QMSx+sFCyodvOrYO8buZQkRux2GXejbOiOehJhCmHnezGpfJ4QQQjREEox4Mm4cLF8O7dq5H4+L04+PG1flLRx7x5SPWRw77HbsCOxJpnXJgGpXz6gZsdqt1b5OCCGEaIgkGPFm3DjYvx+io/XXr7yir8bqQyACVNhZ18Gxw65jnZEhBXOqXbXurbrLLBohhBCnDQlGKmM0lg38OOecaq8r4rqzroNjh11HF05ccTLkt6nWfecOnyuzaIQQQpw2ZDZNVayl3SFmc5VFPU3nvflm2OwyczclRc+aOIKRIItGZO455IR+4lN1BsQOILlzsk9lhRBCiMZAgpGqFBfr3y2Vd4v4Mp0X4IIL9O+O7hujEQb3jmaVI4hRgObyvZw5F82RrIgQQojTigQjVfExM5JVkE6rs7I5bPS8kjx5bTCciiOodOV2R2bEYICYtlbIBgoiISRHP1Eu3jBoBhJiEyQrIoQQ4rQjwUhVHMFIJZmRopIiBr6WSNbQLPC2/MjJGCL/vR9N06MRRzBiNEKRrUh/8dUs6P0utNsMGQMgKAeidunllZ2UYSmSFRFCCHHakQGslVEKSkr0nyvJjFiMFtpHtsfgrTntBsiNJ8hUFtA4umkMBii26V1BZ8QFw9p5kN0T1s6HlYvQbMEAJLZNlKyIEEKI05IEI5WxuqzlUUkwomkaKcNSsONlATODHdalYDSUZTVcu2kcmZGxl1lgbxIs2g57kwjKGMFTff5Hz6iezBs+T7IiQgghTkvSTVMZx+BVqHIAa3LnZBLbJpJ6KBWbcllcxG6EQ/1hTzKGeJfDLt00jsxI/z5BxMaW7cGXnAzTxicxje3+eDdCCCFEgySZkcr4mBmBsuyIWyACYLDpy76juQ1sde2mKSrRMyPBpiDGji0r06pVzasuhBBCNBYSjFTGNRgxVZ1ESu6cTOcWncsO2I2EHEuEPfpYj/x8l1Mu3TSOzIjFaHHbf69FixrXXAghhGg0JBipjKObxmz2vouvC03TGNfTZbl4g407OulZEYC8vLJTnmbTpO8L4sSJsjKFhZCaqn8dPFiL9yGEEEI0YDJmpDLVWH3VoUuLLmUvMhIYPyyZF0tfFgWl82N6NiYTHDYCsfCXghMF+toikx/Ogd/KLn/lFf0LICZG3yrHsU6JEEIIcbqoUWZk0aJFdOjQgeDgYAYNGsSPP/5YafkTJ04wadIkYmNjCQoKolu3bqxcubJGFa5TPq6+6qrQVlj2YsOTpKaWZlSMRXBnIoOWJpDwfwmsjE+AuxJYWJjA3hN79DKXTNLLlWMwQHx8taohhBBCNBrVzoy89957TJ06lVdffZVBgwaxYMECRo4cyc6dO2nTpuKGb8XFxYwYMYI2bdqwfPly2rVrx59//knz5s39Uf/AqkFmpMBaUPYi/Tz+9rfSn20WyGkPodn6VF9PTkXr5cqx28v2tBFCCCFON9UORp5//nkmTpzIrbfeCsCrr77KZ599xtKlS5kxY0aF8kuXLuXYsWN89913mEs/1Dt06FDpM4qKiigqKssQ5ObmAmC1WrG6DiqtJce9vN4zPx8zoCwWSnx87qmiU2UvDK7XaPqsmptGeb02PnMSfxnLZtoAGI2Kfv0Uw4bZ8ONbr1NVtrPwG2nruiHtXDeknetGINvZ13tWKxgpLi5my5YtzJw503nMYDCQlJTE999/7/GaTz75hMGDBzNp0iT++9//0rp1a66//nqmT5+O0Wj0eM38+fOZPXt2heNffvkloaGh1amyT1avXu3xeIs//uB8IN9qZY2P3UrbMraVvTC6/CFEpEN+FBzuBVG/e8yOXNq7Oa+scE9/2Gwal176PZ9/nl2hfGPjrZ2F/0lb1w1p57oh7Vw3AtHO+a7TSCtRrWDkyJEj2Gw2oqOj3Y5HR0fz+++/e7xm7969rFu3jhtuuIGVK1eye/du7r33XqxWK0888YTHa2bOnMnUqVOdr3Nzc4mPjyc5OZmIiIjqVLlSVquV1atXM2LECGfWxpUWGQlAaEQEo0eP9ume/1v5P33TOyjNjCgwFsOdiRBe+Za+d9/Zhx8/tZOWpmGzac6syCOPJDbqLpqq2ln4j7R13ZB2rhvSznUjkO3s6NmoSsBn09jtdtq0acP//d//YTQaSUhIICMjg2eeecZrMBIUFESQh2kjZrM5IH8hvd63dP6tFhTk83NPWV26aYxWQPNtvAjQIqw5c+caGFXak2Ozacydq2GxnB4zsAP15ycqkrauG9LOdUPauW4Eop19vV+1PuWioqIwGo1kZbn/hp+VlUVMTIzHa2JjY+nWrZtbl0zPnj3JzMyk2HW59YaoBgNYc4tcokDnmJHS8SKVBCIAwaZgkpMhMVF/nZioLwkvhBBCnM6qFYxYLBYSEhJYu3at85jdbmft2rUMHjzY4zVDhgxh9+7d2O1lH8R//PEHsbGxWBr6XFVHMFJFPdNz0kk9lErqoVT+OvlX2YnoX2jRKxUiDuqrsGYk6nvVuHJZIt5itKBpMG8e9Oypf2/M3TNCCCGEL6rdTTN16lQmTJjAgAEDGDhwIAsWLCAvL885u+bmm2+mXbt2zJ8/H4B77rmHl156iSlTpnD//feza9cu5s2bx+TJk/37TgLBdQVWL4pKikhcnEhWnofxIFddy3GAkzGwYL/n2TQuwUaQSe+aSkqC7bI3nhBCiCai2sHINddcQ3Z2NrNmzSIzM5N+/fqxatUq56DWAwcOYDCUJVzi4+P54osv+Nvf/kafPn1o164dU6ZMYfr06f57F4HiQzeNxWihfWR7svOyseOhG0YZIDdeHzeyJxn+6g9tU52nY809OGT93XkvIYQQoqmp0QDW++67j/vuu8/juQ0bNlQ4NnjwYH744YeaPKp++bACq2O33lFveVk/RLPDuhTMZk2PbTbOhGuucp4e3OxaVhx7EpPBhEE7PQaqCiGEENUhn36V8XEAa3LnZBLbJmLUyo0HsRswZuq79joHoh4Y6lYk2twJkKyIEEKIpkuCkcr4OIDVkR2xKZv7CYMdwwZ9197kZGjXDjCUuBUpRN8kL8goO+AJIYRomiQYqYwPA1gdkjsn0y+mn/vBo12x/q6nRDIz4cILqRCMZBw9AUhmRAghRNMlwUhlqrHOiKZpTD1nqvvBbdfimC4zfz689RbuS8QDX359AgCLZEaEEEI0URKMVMaHAayuEtsmuh/IPtP5o3O9EEO5TYOCTwAQZJLMiBBCiKZJgpHKVHMF1oKSAvcDLl0ySlU8BpQFI5IZEUII0URJMFKZamZG8q3ldid06ZLp3BmMRip004S0OKE/QsaMCCGEaKIkGKlMNTMjFYIRly6ZG24Am40K3TRhsfry8SX2EueS8qmHUjmYe7DG1RZCCCEak4Dv2tuo1babxiULkpiof23OdO+mOcIOALYd3kbC/yU4j8eEx7B/yn7nEvFCCCHE6UoyI97YbLB3r/7zX3+VpjUqV1lmxGKBlBQqdNN4YsBAfES8dN0IIYRoEiQY8WTFCujQAT7+WH/95pv66xUrKr2ssjEjZjMkJ4PJUnUwYsdOyrAUNNmyVwghRBMgwUh5K1bA+PFwsNyYjYwM/XglAUllmRGTSZ/eG9my3GyacoyakcS2iSR3Tq60nBBCCHG6kGDElc0GU6a4zMN14Tj2wANeu2wKrN7HjDiGnYSGV54ZsSmbZEWEEEI0KTKA1dXGjRUzIq6UgvR02LiR9LM7k52f7XZ697Hd7uUNFYMRFX7I6+0NmoHebXpLVkQIIUSTIsGIq0PeAwVX1oMHSPzpWrLysiovaCrLlJjNUFRSxKEzp3stbld2DuQcoNhWLLNohBBCNBkSjLiKjfWpmKldPO0L2pOdl40du/eCWtm5XbvAarVgLG6JzZzj9ZLOLTrLLBohhBBNiowZcTV0KMTFuWwkU46mQXw82vnnkzIspfJABMBYNlh1/HgYMECjZNsVlV4y56I5Ml5ECCFEkyLBiCujERYu1H8uHxA4Xi9YAEYjyZ2TSWybiFEzVryPvfRYudVWDQYw5XbXX5QbI6uh0SuqF1GhUbL6qhBCiCZFgpHyxo2D5cuhXTv343Fx+vFx4wDQNI2UYSnYlIeZNfmt9O/lFjiz26FNbOk4knKxjkKx/ch2BiweQOLiRIpKivzxboQQQogGT4IRT8aNg/37oW9f/fUTT8C+fc5AxMGRHSnPWBit/+CSGTEa9eXgm0WUHvAwexhk9VUhhBBNjwQj3hiNEBam/9y3b+mWu+40TePuhLsrHA8LKR0XHJYFEXqXi82mLwdvMJWOI/EyLERWXxVCCNHUSDBSmZLSwMHkPukoPSed1EOp/HDwBx788sEKl+WGbdV/6PoFTEwEYxH9++vLwRtMpdmSvFYVsiOy+qoQQoimSKb2VsZDMFJUUkTi4sSq1xgBPdjIjQebhSef1MfAao4ZNn8lQtdVbsVl9VUhhBBNkWRGKuMhGLEYLbSPbI/Bl6bTgHUpgMbFF5cecwxqPd4RMhIxlM7GkayIEEKIpkqCkco4ghHHWu6UzaKpco0RgMII2KMHF454RnMEI3YLrEvBXjobR7IiQgghmioJRirjZcxIpWuMuDrRAdBcYxkwlN7TboI9yfRppc/GkayIEEKIpkqCkcp4CUYqXWMEygamKiA2FXt0KqmHUvXFzByZEZsZ0JiROI+eUT2ZN3yeZEWEEEI0STKAtTIegpH0dMjOhiiVTK/IRLbn/ISH5VR1sb/AXQnYgIT/g5jwGFobxurn7Hq65IL4JK4btD2Q70IIIYRo0CQYqUy5YKSoSF+4LCsLQIPOKXDTKJ9u5VjMrOh46VgTu35PD8uXCCGEEE2KdNNUplwwYrFA+/b6HjOAPji1MMLzteXYsXNz35spMGTqB0IPQ2wqmfmyD40QQoimTYKRypQLRjRNX0XV7pxIo8HxTm6XGDGB8tys939+P7uMn+gvBi2CuxJIXi770AghhGjaJBipjIcxI8nJeleNs3uluJnbJa3Do0DzYdovgN1Au2ayD40QQoimTYKRyngIRhzZEZtjIo3BfWfeqJAomhWcWXbAXkkTG+w8dq6sLSKEEKJpk2CkMt7WGUl2WQfN6B6MhAeF0yXrobIDBjsc6VZxTRK7BhmJjOgoa4sIIYRo2iQYqYzXdUYgMrL0hbHY7Vy4JZyWJ0aWHcgYAJ8vrLgmiUHBuhRMJsmKCCGEaNokGPHGbi8bqWqqOAM6OLj0h3LdNGHmMIwl4WUHNjwJe0aSEJvgfoNjHWFPctnMHCGEEKKJknVGvLGVZTIOZpo4fMD9tCNpUr6bJswSRmFJqEvBYIjdyqguo9hyaEvZ8f0XQEQGBkOcnysuhBBCNC4SjHjjjDbg/ItM7Mv2Uq5cN02YOYz0PCOUWMBUDBOSAJi7sdx1/ZdB11VsTt1PsDkIgDZtIE5iEyGEEE2MBCPeuAQjbdub+POo6/oiLsp105i1YDZtAgaH6cGI0kBTFa9TGuTGM+Scsmm9MTGwfz8EBfnnLQghhBCNgYxY8MYlGJn1d5PnQAQqdNOYTUY9mLCG6Qc8BSKO4+tScGxkYzBAfLy+yqsQQgjRlEgw4o21LMgYMcrovtCZQ0Q6GAvdDh3Jz6ZN31RQpUHI8Q6e1xopHcDqYLfr65fIkiNCCCGaGglGvHFkRoxGNIPmvtAZgLEI7kyEoDy3y97a9hZ7khKgeYZ+oMV+fa2R8sIyod0miE3F0PwgiYn6+iVCCCFEUyNjRrwpt8ZIcjJ07gx79pSet1kgpz2EZTl6WtwpPB93CCqAiYMBsJ+M4fHh+9E0GSwihBCi6ZHMiDceNsm74grXAhqs+7v3gMPX7ha7gVBbPJeMlMEiQgghmiYJRrzxsPpq165lpy0WYP8wz9fajVBQukSrvYqoxGDnkXNSMBhksIgQQoimSYIRbxzBiHMTGih2WVKkZUsqzKRxMtjgUOmKqwYvs2kA7EZCTyQy8yoZLCKEEKLpkmDEGw+ZkaKistPBwbitMWLQ9KY0akZCjifCsc4AtDK31cePeGKw8di5khURQgjRtEkw4k0VwUhJCW6ZEbvSZ8zYlI2Y31LAqu9Pc1HXIW7jRzRHk9uNtCpMZMZ4yYoIIYRo2iQY8aaKYMRmw5kZMWpGEtsmAtAnug9aYRRYcvWCCkJMIQBEhUahKJ3ma7AxpDgFTRYWEUII0cRJMOKNL8FI6b40QaYg5g2fR/dW3UnPSWdv0gBIWALABzs+oKCkAIAj+UcwaqX3y0ikT5hkRYQQQggJRrzxKRjRMyNmg5mkTknsmLSDLi27gPLcrBoa7cM7QXZPWDuP5pGSFRFCCCEkGPGmGt00ZqM+40bTNFKGpYDmeSMbhWL24Bdg0XbYm0RkZEBqLoQQQjQqsgKrN6XBSL7VxO+p+qH09LLTRUVAsN5NY1BmUkvLRKlkzIcTsUZtqbAMfOdmZ9E6p6xr5uhRnNe1aQNxcQF5J0IIIUSDJsGIF9aCEszAbztNDEyoeL6gAGipZ0aOZFlIcJbRoHMK3DSqwjV7lk3n4m1lXTMzZuhfADExsH8/+o6/QgghRBMi3TRemNAzIyWVxWul3TQmzey+2+6eZMjsXbH8nos938YA8fGlq7oKIYQQTYwEI15oNh+CkdIBrMWFZpTrwmYRByH19orlW/4Bsan6eRd2O6SkgMzyFUII0RRJN403pWNGQpqZMOaXDlgtr3RqLzazy7EiuDMRwrMqlr/jXP37yRhYsB9sQRiN0L+/viuwEEII0RRJZsSb0mCkQxeT50AEypaDt7n0r9gskNMe7F6a1m6A3HjnNTabZEWEEEI0bRKMeFMajIRFmOjZ00sZx3LwdpfMCBqsS6kwk8bJYMewIQXQMBohMVGyIkIIIZo2CUa8KQ1GNn5vYscOL2WcmRGz+/E9yZCRiNumNOjLxncLS8S+S48+JCsihBBCSDDinVUPNCyhJu/BQumYkWZh5YIRR3ak3Ha9NmVj4eUpJCbqN5SsiBBCCCHBiHelmZEeZ5ncZ8q4Ku2m6dHVw5zcPcl0jujhdiixbSIjuyQzbx707Anz5klWRAghhJBgxJvSYCQ6zkSvXl7KlHbTxLQpnxkBIg4yttNNbodu7nszWzO30vLMVL784SBJSf6ssBBCCNE4ydReb0qDEc1kYsIEmD7dQxlj2aJn7sf16b3PpblP773/8/udP8eEx7B/yn6CTLLkqhBCiKZNMiPeuGyU16OHlzKlY0bMhnLdNKXTezUvzWvAQHxEPBajLLkqhBBC1CgYWbRoER06dCA4OJhBgwbx448/+nTdu+++i6ZpjB07tiaPrVuOYMRsJi+v3LmIdH0l1ch9AOQU5uqvHV8RGbAuBYXn6b127KQMS0GTASNCCCFE9btp3nvvPaZOncqrr77KoEGDWLBgASNHjmTnzp20adPG63X79+/noYceYujQobWqcJ2w2WDXLv3nrCzycm2AkebN4cTJiiusfrHvM7jrs7LrT8bAgn30bZ3IL9k/oVxm1Rg1I/1j+5PcWabRCCGEEFCDzMjzzz/PxIkTufXWW+nVqxevvvoqoaGhLF261Os1NpuNG264gdmzZ9OpU6daVTjgVqyADh3gjTf01598wjXTO3AFK+jfH4LMvq6wGsTMgSlugQjo03slKyKEEEKUqVZmpLi4mC1btjBz5kznMYPBQFJSEt9//73X6/7+97/Tpk0bbr/9djZu3Fjlc4qKiigqKnK+zs3NBcBqtWItXf/DHxz3cnzXPvoI47XXglJuy5WF52SwnPH8y/A+RQnj+HZdCtw0yvNNDfbSNUY0zm83jITYBNIy07ApG0bNSL+YfgxrP8yv76OhK9/OInCkreuGtHPdkHauG4FsZ1/vWa1g5MiRI9hsNqKjo92OR0dH8/vvv3u85ptvvmHJkiWkpaX5/Jz58+cze/bsCse//PJLQkNDq1Nln6xevRpsNpLvvRdjuUAEQEOh0Bj/7WRe7XRe2QqrbX8CzSXzYTfCof76eWDdujVcGnIpW9QWQM+KXBpyKZ9//rnf30NjsHr16vquQpMhbV03pJ3rhrRz3QhEO+fn5/tULqBTe0+ePMlNN93E4sWLiYqK8vm6mTNnMnXqVOfr3Nxc4uPjSU5OJiIiwm/1s1qtrF69mhEjRmD57jtMR496LWtA0brgEMMt2/mFGD37UT47YrA5syIAI0eO4KqIJD5d9ilbDm0hITaBR655pMl10bi2s9nsYU0W4TfS1nVD2rluSDvXjUC2s6NnoyrVCkaioqIwGo1kZbmvn5GVlUVMTEyF8nv27GH//v2MGTPGecxu12eYmEwmdu7cSefOnStcFxQURFBQxfU3zGZzQP5Cms1mTNnZPpVtdqr0ve9JhvyWEHpMf10uKwIQHGzGYoGnkp5i8ueTeSrpKSyWpjudN1B/fqIiaeu6Ie1cN6Sd60Yg2tnX+1VrAKvFYiEhIYG1a9c6j9ntdtauXcvgwYMrlO/Rowfbtm0jLS3N+XXZZZcxbNgw0tLSiI+Pr87jAys21qdiX+1ylNPgWJeyE+WyIgCG0tZN6pTE9knbSeokS64KIYQQ5VW7m2bq1KlMmDCBAQMGMHDgQBYsWEBeXh633norADfffDPt2rVj/vz5BAcHc9ZZZ7ld37x5c4AKx+vd0KEQFwcZGXjajMaOxkHi2IjL1GTX3XozEt2yIlAWjAghhBDCu2oHI9dccw3Z2dnMmjWLzMxM+vXrx6pVq5yDWg8cOIChMX4KG42wcCFq/HgUGgaXKbn20mzHAyzAjrHsmqCTALQ0tOfY2nlQbuir0YgQQgghqlCjAaz33Xcf9913n8dzGzZsqPTaZcuW1eSRdWPcOPhgOdnXTSHaetB5+CBxPMACPmKce/ngHAAmhL3PP/cOqnC7xhiTCSGEEHVNNsorR7tyHGkfX07bS/rSm994zPIg8+MvwB6aC7zlXjjkMACnCgs83kuCESGEEKJqEox4kHyxkZ2hFsiHn8a8hr33c5WWf6v4ajCmg819BtDWrWU/t2mjD0kRQgghhDsJRjzQNIhrVQD5UFAUAyqn/HAQN2G2ePJtFafsJiSU/RwTA/v3g4cZy0IIIUSTJh0JXoQZ9K6Xgq33VhqIAAw8OZfKChkMEB8PTXiJESGEEMIrCUa80ApKg5GMCyFjAFSc7auzG4nKGVnpvex2SEnRMy5CCCGEcCfBiDeOYIRQWDfHe+KjIJK/7FshNlX/ijjodtpohMRESE72cr0QQgjRxMmYkXLS0yE7G87OL0ADCgjB+GcybQxncsj+W8ULwo6xulMC3FX6+mQMLNjvHMxqs0lWRAghhKiMZEZcFBXpWYyBCSVothJAD0ZsJRqHVt5e9Q3sBsiNB7s+OESyIkIIIUTVJBhxYbFA+/YQppWtG1JAiP7DsYob+lVgsOv70yg9DSJZESGEEKJqEoy40DQ9eAhSZcFIIcH6DyHH3QuXH9BqNzr3p3Hs/ydZESGEEKJqEoyUk5wM5/RxDF4NxjFyVQs76l6wfLbDZdfeyy6Dnj1h3jzJigghhBBVkWCkHE2Dafc7gpEQ53EVXC4YKXFZvcwlKwLQuzds3w5JSQGvrhBCCNHoSTDiwZD+7sGIwQCtzzjmXsjukvJwyYoAmM11UUshhBDi9CBTe104pvWG/VxAd6BAM0NMKnagZefdZJe4FLYUlv38V1lWBOCvv+DgQdmLRgghhPCFBCOlHNN6s7LgIgpYCxS0yoC79A1mdpZ4ufBUa1gzD9dBJI8/DosWyV40QgghhC+km6aUY1qvwQBhnAIgpMjIBXs1DPZKLvz5Jiho6bbyqqbJXjRCCCGEryQYKeWY1nu5fQVL0Rc463KyiA3/VuxfAFds93LhkOf17MnERDAWAaCUrC8ihBBC+EqCERfJp1bwIeNphfvMmXa5sPz9SgISx8qrNj0V0rWrrC8ihBBC+EqCEQebDe2BKYCquIRI6fcFq/DcZeNYebX0yuHDYetWSE3VB7IKIYQQwjsJRhw2boSDB71uzmsA2ufC0D/LnbAb3NYYAXj1VUhI0L8SE/XBsUIIIYTwTIIRh0OHfCoWe6rcgXJZEbdTBhnIKoQQQlRFghGH2FifimU3KxdZZPd0y4q4sttlIKsQQghRFQlGbDa0r76CjAxo3dpr5GAH0iM1VO9r3U9sug9PWRGjUTbKE0IIIXzRpBc9O/raR1w08z5MOdnOY4qKoYVjzOqUkYp1J//tfnLfRR7vbbNJVkQIIYTwRZMNRqzvraDNvdeihx9lPMUOGvD0ufBRr9IDrhFLSaiznMGgd80YjdC/v2RFhBBCCF80zW4amw3TQ/o0Xl8aQAHX/eoyrdc1YrGWbaZntztvL1kRIYQQwkdNMxjZuBHt4EGf37zbtF67EUpcBrGW6MGI3WX9EZMJLrjAX5UVQgghTm9NMxjxcRpvebGnAIMNcly24y3NjLhq3142yBNCCCF81TSDER+n8ZaXFV66wNnJ0mDEZgZlrFDu+HEoLq5NBYUQQoimo2kGI0OHQlRUtS7JCoWvzrATnXkzlJSmPTxkRQA6d5aFzoQQQghfNc3ZNEYjvPwy6uqrAc8zaBwcc20mXaKv/J6VcD9YSyMNuwliU8sK57WB3DjmzJHBq0IIIYSvmmYwAnDVVdinTsXw/PNVFn36XPjwTJcD5tI+mNBjcFdC2fGTMfTfuJ/kZBkwIoQQQviqaXbTlLLPnUt2nz5ez5+wwFXjYYYv64XYDZAbz9zZFsmKCCGEENXQdDMjK1ZgmjyZNhkZzkM5hBMyuD/mYedxye/L+aLXbuymsjm7BgzYsXu6GxjsdD2YwsiREokIIYQQ1dE0MyMrVsD48fp+NC6akYf5h41oCQnsKXjBLRABsGOnW8tuYC8XcNiNkJHIC5OTJSsihBBCVFPTC0ZsNpgyBZSqMHDV4Biu+sADhB8ark/jdZzTDCS2TWThqIVgUOUutNFNsiJCCCFEjTS9YGTjRjh40OtpTSlIT6df7jewLsV53K7spAxLYWSXkZAxQB8jAhgwEnw0kZf+JlkRIYQQoiaaXjDi4+qrLYsOwZ5kLFowAN1bdaenJZmtWzWCvpvj3KjGjo1nRqfQqpVWWYwjhBBCCC+a3gBWH1dfzTLEAhoR5lYcKc7gjn53M3CgRlYWQDKcmwjtNkNGIvdfrE+3iYmB/ftlKXghhBCiOppeZmToUIiL87oqmdI0iI/nB/NQAMwGs35Zh3Np317fnRc0WDsPsnvq39EwGCA+XlZeFUIIIaqr6QUjRiMsXAiUBh4u7I4hrQsWUGzT95wpUfoCZxajmZQUl9159ybBou36d/TjKSmy8qoQQghRXU0vGAEYNw6WL4e2bd0OHySOjAXLYdw4bDb9WImyAmA2mklOhsTE8jfT45vEREj2ZXE0IYQQQrhpmsEIwLhxlOza5Xx5BR/SkX3kDB8HQEmJftwRjFiM+sqqKSkV7oTNJlkRIYQQoqaabjACoMrWC9nAMOwYnRkRZ2bEXpoZKR074siOGPVeHMmKCCGEELXUtIOR4uKyH9FHnjrGhJRlRvQyZqMejDiyI65Bi2RFhBBCiJpr2sGI1Vr2I3qw4Z4ZUVjtZd00Dq5jRyQrIoQQQtRO0w5GXDIj5YORkhLAYHOed3TTgJ4FmTcPevbUv0tWRAghhKi5prfomavSYKTEYHZufufoprHZAGNZsOLopnFISoLt2+uklkIIIcRprWlnRkq7aewugYZ7ZqSsG8c1MyKEEEII/2nawYgzM1I2HsRm0yfZ6JkRl2DEKMGIEEIIEQgSjOAejNjtLquslnbTGDUjBq1pN5UQQggRKE37E7Z0/q7N4N5N4+iqcXTTSFZECCGECJwmHYxopZkRq+beTeNYY8TRTSPjRYQQQojAadLBiLObRnPvpimfGXFdY0QIIYQQ/tW0g5HS2TRWg7fMiPvqq0IIIYTwv6YdjDi6aXAfMyLdNEIIIUTdkUXPcB8z4tZNY5RuGiFE42O32yl2WWG6sbJarZhMJgoLC7HZbFVfIGqkNu1sNpsxOnaOrYWmHYw4umnw3E1jtBRjQ7pphBCNR3FxMfv27cPuXKOg8VJKERMTQ3p6OprsuxEwtW3n5s2bExMTU6s/o6YdjJT+5lCM56m9BpNVD0akm0YI0QgopTh06BBGo5H4+HgMhsbdE2+32zl16hTh4eGN/r00ZDVtZ6UU+fn5HD58GIDY2Nga16FpByOlmRHXYMRud82MWLEimREhRONQUlJCfn4+bdu2JTQ0tL6rU2uO7qbg4GAJRgKoNu0cEhICwOHDh2nTpk2Nu2ya9p+uIxhR7t00ZZkRPXMiY0aEEI2Bo7/fYpH/s0TdcQS+Vqu1ipLeNelgxLHoWflgxJEZMZhlNo0QovGR8RWiLvnj71uTDkYcY0aKlOfZNAaTLAcvhBBCBFqTHTOSng7qTyvtgXxbWTCydy84MpySGRFCCCECr0kGI0VFkJgId2TZmAPk5JcFGykpZeU0GTMihGhC0tMhO9v7+TZtIC6u7uojmo4m2U1jsUD79hBEEQDFuAcbju4vTbpphBBNhOOXtIQE71+JiXo5f7vlllvQNI2nnnrK7fjHH39MixYtKpTv0aMHQUFBZGZmerzf+vXrufTSS2ndujXBwcF07tyZa665hq+//tr/lRd+UaNgZNGiRXTo0IHg4GAGDRrEjz/+6LXs4sWLGTp0KC1atKBFixYkJSVVWr4uaJqeATHjmNrrHowopX83SjeNEKKJcPyS5m1mp8EA8fFl3dj+FhwczD/+8Q+OHz9eablvvvmGgoICxo8fzxtvvFHh/Msvv8zw4cNp1aoV7733Hjt37uSjjz7i3HPP5W9/+1tgKi9qrdrByHvvvcfUqVN54oknSE1NpW/fvowcOdK56El5GzZs4LrrrmP9+vV8//33xMfHk5ycTEZGRq0rXxvJyRDXxrHoWdm/Lk2D7t1LX8hGeUKIRkwpyMvz7Ss/Hx59VB/E74ndrp/Pz/ftfo5f6nyVlJRETEwM8+fPr7TckiVLuP7667nppptYunSp27kDBw7wwAMP8MADD/DGG29w0UUXccYZZ9CnTx+mTJnCTz/9VL1KiTpT7WDk+eefZ+LEidx666306tWLV199ldDQ0Ap/KRzeeust7r33Xvr160ePHj147bXXsNvtrF27ttaVrw1Ng/MG6vlG143ylIJbb9V/dsymsRhkzIgQovHJz4fwcN+/xo6t/H5jx/p+r/z86tXVaDQyb948XnzxRQ4ePOixzMmTJ/nggw+48cYbGTFiBDk5OWzcuNF5/sMPP8RqtTJt2jSP18uU54arWgNYi4uL2bJlCzNnznQeMxgMJCUl8f333/t0j/z8fKxWKy1btvRapqioiCKXjsnc3FxAX1ClNouqlNeudSHgnhmJi1OcdZYNMDkzI0bN6NfnNjWOtpM2DDxp67rRUNvZarWilMJut5d+QX0NDSx7ftWUUiiluPzyy+nXrx+zZs3itddecztvt9t5++236dq1Kz179gTgmmuu4bXXXmPIkCEA7Ny5k4iICNq0aePcm+fDDz/kVsdvmMC3335L7969/fQuTw+qNI3laOfqstvtKKWwWq0VVmD19d9ItYKRI0eOYLPZiI6OdjseHR3N77//7tM9pk+fTtu2bUlKSvJaZv78+cyePbvC8S+//NKvSxz3O/AnZ+AejHTv/ic//HAIGExxySkAMtIzWLlypd+e21StXr26vqvQZEhb142G1s4mk4mYmBhOnTpFcXExSoGXJINXSsGll4bz669GbDYNo1H/Be3TT09RncRCSQmU/h5ZJavVSklJCbm5uTz22GNcfvnl3HXXXRQUFAB6RgT0Lporr7zS+Qvq2LFjufTSS5kzZw7NmjVz7lSc6/LgwYMH8/XXX3Po0CEuvfRScnNz3c6LMo52rq7i4mIKCgr4+uuvKXGsGloq38cUWZ1O7X3qqad499132bBhA8HBwV7LzZw5k6lTpzpf5+bmOseaRERE+K0+2jvvAO7dNBdeGM+ZZ+pz14LC9H953Tp1Y3TSaL89t6mxWq2sXr2aESNGYDbL+JtAkrauGw21nQsLC0lPTyc8PNz5f2xkZPXvM38+jB6t//9ns2nMn2+gbVv//d9bntlsxmQyERERwcUXX0xycjLz5s1jwoQJADRr1owdO3awefNmtmzZwpNPPum81mazsXLlSiZOnMiZZ57J66+/Tn5+PjExMQBERETQtm1bmjdvDkBYWJhfP0dOB0opTp48SbNmzWrUlVVYWEhISAjnn39+hc92XwO/agUjUVFRGI1GsrKy3I5nZWU5/+C9efbZZ3nqqadYs2YNffr0qbRsUFAQQUFBFY6bzWa//sO3l0Zw7gNYy1JMmlE/H2QOalD/4TRW/v7zE95JW9eNhtbONpsNTdMwGAy12lhu1Ch9Gu/mzfr3UaMM1cqKVJemac56A/zjH/+gX79+dC+dTaBpGq+//jrnn38+ixYtcrv29ddf5/XXX+euu+7iqquuYubMmTzzzDP885//dCvnuHdt2+Z05Oiacf0zqA6DwYCmaR7/Pfj676NawYjFYiEhIYG1a9cytnSkk2Mw6n333ef1uqeffpq5c+fyxRdfMGDAgOo80u827Uhn1dZt7D3yBw9v+Z6zgA7dn8Mw6B3soceYd6qI8F/NMDGU7Jb6HPaVf6zEbrfTO7o3wzoOIy5CVv0RQpy+NA3mzYPJk/XvdT3us3fv3txwww28+OKLgJ6J+s9//sPf//53zjrrLLeyd9xxB88//zy//fYbZ555Js899xxTpkzh2LFj3HLLLXTs2JFjx47x5ptvAtR4V1kRWNXuppk6dSoTJkxgwIABDBw4kAULFpCXl+ccIHTzzTfTrl075/Ssf/zjH8yaNYu3336bDh06OBepCQ8PJzw83I9vpWq5eUWcs2wAV+w/zMJVEF+aPXpo536uObSfKaPgoxjItwPtwNHztS17G9uytwHQJqwNBx44QJCpYuZGCCFOF0lJsH17/T3/73//O++99x4An3zyCUePHuWKK66oUK5nz5707NmTJUuW8Pzzz3P//ffTs2dPnn/+ecaPH09ubi6tWrVi8ODBrFq1SgavNlDVDkauueYasrOzmTVrFpmZmfTr149Vq1Y5B7UeOHDALc3zyiuvUFxczPjx493u88QTT7j1+9WF8BAL125vxlufVlwTpV0uLH8fxl8NH/Xyfo/2Ee1leXghhPCjZcuWVTjWoUMHCgoKyM3NJSIiAptjB1MPtpeLmpKSkiqdJCEanhoNYL3vvvu8dsts2LDB7fX+/ftr8oiAMCg7//ouR/+5/DnADixYBf/tAXYv3WZzLpojc9WFEEIIP2pao3g2biTi2BGvb9oAtM+FoX96Pj8gdgDJnZMDVTshhBCiSWpawcihQz4Viz3l+fiUPpIVEUIIIfytaQUjsbE+FTtUflytAjIG8NAVyQHZsVIIIYRoyppWMDJ0KMTFeZ2nZgcORMDGM8qd0EDbMIf28VrAdqwUQgghmqqmFYwYjbBwIQCqXEDiWI3/gVEeBq9mDEDtSiYlpe7n2wshhBCnu6YVjACMGwfLl6O1a+d2OCPCwPjLIvj4jDZwqg0UNAebAU61wbB+PomJGskydlUIIYTwuzrdm6bBGDcOLr+ckvXrSfv8c/pdfDHLvhnGR7ONjB4N5ffEswMpqyQrIoQQQgRC08uMOBiNqAsuIOP881EXXEBunr5EsNkMzZqVFTMYoFcv/UsIIUT90DSNjz/+uL6rwYYNG9A0jRMnTngts2zZMufGfMI3TTcYcVFUBK++qv/83/+C6y7Kdru+JPLAgchMGiHEaS09J53UQ6levw7mHgzYs7Ozs7nnnnto3749QUFBxMTEMGrUKH744QcADh06xMUXXxyw5/vq3HPP5dChQ0RWYzvkZcuWoWkao0aNcjt+4sQJNE2rsFgowF133YXRaOSDDz7weM/du3dz2223OdurXbt2DB8+nLfeeouSkhKP1zRkTbObphyLBZo3h1Ne1hfRNIiPR2bSCCFOW0UlRSQuTiQrL8trmZjwGPZP2R+QvbmuvPJKiouLeeONN+jUqRNZWVmsWbOGY8eO6c+uYmf4umKxWGpUF5PJxJo1a1i/fj3Dhg2rtGx+fj7vvvsu06ZNY+nSpVx11VVu53/88UeSkpI488wzWbRoET169ADgp59+YtGiRZx11ln07du32nWsT5IZQQ82ygWsbpRCZtIIIU5rFqOF9pHtMXj5WDBgID4iPiB7c504cYKNGzfyj3/8g2HDhnHGGWcwcOBAZsyYwejRo4GK3TTfffcd/fr1Izg4mAEDBvDxxx+jaRppaWlAWXfKF198wdlnn01ISAgXXXQRhw8f5vPPP6dnz55ERERw/fXXk5+f77xvUVERkydPpk2bNgQHB3PeeeexefNm53lP3TTLli2jffv2hIaGcsUVV3D06NEK7zEsLIzbbruNGTNmVNkeH3zwAb169WLGjBl8/fXXpKenO88ppbjlllvo1q0b3377LWPGjKFr16507dqV6667jm+++YY+ffr42vQNhgQjpXr29HzcaITERGQmjRCi0VFKkVec59NXvjWfR4c+it250IE7O3YeHfoo+dZ8n+6nlPK5no5d3D/++GOKfOgPz83NZcyYMfTu3ZvU1FRSUlKYPn26x7JPPvkkL730Et999x3p6elcffXVLFiwgLfffpvPPvuML7/8khdffNFZftq0aXz44Ye88cYbpKam0qVLF0aOHOnM0JS3adMmbr/9du677z7S0tIYNmwYc+bM8VqXbdu2sXz58krf35IlS7jxxhuJjIzk4osvdttIMC0tjR07dvDQQw+5bUrrqjGuFC7dNKVMXlrCZpOsiBCiccq35hM+v/yS0jU39r2xPpc9NfMUYZYwn8qaTCaWLVvGxIkTefXVV+nfvz8XXHABV199NR06dKhQ/u2330bTNBYvXkxwcDC9evUiIyODiRMnVig7Z84chgwZAsDtt9/OzJkz2bNnD506dQJg/PjxrF+/nunTp5OXl8crr7zCsmXLnONTFi9ezOrVq1myZAkPP/xwhfsvXLiQUaNGMW3aNAC6devGd999x6pVqyqUbdu2LVOmTOHRRx9l7NixHtti165d/PDDD6xYsQKAG2+8kalTp/LYY4+haRp//PEHAN27d3dec/jwYef7AXj66ae59957Pd6/oZLMSClPAaZkRYQQom5ceeWV/PXXX3zyySeMGjWKDRs2MGDAAN5+++0KZXfu3EmfPn0IDg52Hhs4cKDH+7p2WURHRxMaGur2wR0dHc3hw4cB2LNnD1ar1Rm8AJjNZgYOHMiOHTs83n/Hjh0MGjTI7djgwYO9vs/p06eTnZ3N0qVLPZ5funQpI0eOJCoqCoDRo0eTk5PDunXrvN6zVatWpKWlkZaWRvPmzSkuLvZatqGSzEgpo7HiMcmKCCEas1BzKKdmehmZ74VSigveuICfM3/GpmwYNSN9Y/ry1YSvqpX+DzWHVre6BAcHM2LECEaMGMHjjz/O7bffzvz587n77rurfS8Hs9ns/FnTNLfXjmN2u+euqUBo3rw5M2fOZPbs2Vx66aVu52w2G2+88QaZmZmYXNL1NpuNpUuXMnz4cLp27QroAdnZZ58NgNFopEuXLgBu1zUmkhkp5SkYkayIEKIx0zSNMEtYtb7Cg8KZd9E8bMoGgE3ZmHfRPMKDwqt1H3+MW+jVq5fb4FKH7t27s23bNrfxJa6DTGuqc+fOWCwWvv32W+cxq9XK5s2b6eVlsamePXuyadMmt2OO6cje3H///RgMBhaWbk/isHLlSk6ePMnWrVudmY60tDTeeecdVqxYwYkTJzj77LPp0aMHzz77bJ0GUYEmwUip8t00LVvCvHmSFRFCND3JnZNJbJsIQGLbRJI7B/a3sqNHj3LRRRfx5ptv8ssvv7Bv3z4++OADnnnmGedsGlfXX389drudO++8kx07dvDFF1/w7LPPArUbvBkWFsY999zDww8/zKpVq9i+fTsTJ04kPz+f22+/3eM1kydPZtWqVTz77LPs2rWLl156yeN4EVfBwcHMnj2bF154we34kiVLuOSSS+jbty9nnXWW8+vqq6+mefPmvPXWW2iaxuuvv87OnTsZMmQIn3zyCbt27WL79u28+uqrZGdnY/T023UDJ8FIqfJ/dpMmQVJS/dRFCCHqk6ZpzBs+j55RPZk3fF7AZ2eEh4czaNAg/vnPf3L++edz1lln8fjjj3PHHXfw9NNPVygfERHB//73P9LS0ujXrx+PPvoos2bNAnAbR1ITTz31FFdeeSU33XQT/fv3Z/fu3XzxxRe0aNHCY/lzzjmHxYsXs3DhQvr27cuXX37JY489VuVzJkyY4DZ2JSsri88++4wrr7yyQlmDwcAVV1zBkiVLnM/csmUL3bt3Z9KkSfTq1Ytzzz2Xd955h3/+85/cc889NXz39UdT1Zl/VU9yc3OJjIwkJyeHiIgIv93XarWycuVKRo8ezTvvmJkwoezcvHkwc6bfHtWkubZz+f5a4V/S1nWjobZzYWEh+/bto2PHjrX+UG4I7HY7ubm5REREeJ3G6vDWW29x6623kpOTQ0hISB3V8PRQnXb2pLK/d75+fjfOkS4BUL795e+yEEI0XP/+97/p1KkT7dq14+eff2b69OlcffXVEog0UhKMlCrfTRNa/YHgQggh6khmZiazZs0iMzOT2NhYrrrqKubOnVvf1RI1JMFIqfLBiATXQgjRcE2bNs250Jho/GQAaynpphFCCCHqhwQjpSQzIoQQQtQPCUZKSTAihBBC1A8JRkqV76aRAaxCCCFE3ZBgpJRkRoQQQoj6IcFIKQlGhBBCiPohwUgpmU0jhBANl6ZpfPzxx/VdDTZs2ICmaZw4ccJrmWXLltG8efM6q9PpQIKRUpIZEUKIUjYbbNgA77yjf7fZAv7I7Oxs7rnnHtq3b09QUBAxMTGMGjXKuQPuoUOHuPjiiwNej6qce+65HDp0iMjISJ+vWbZsGZqmMWrUKLfjJ06cQNM0NmzYUOGau+66C6PRyAcffODxnrt37+a2225ztle7du0YPnw4b731FiUlJW5lP/30Uy644AKaNWtGaGgoiYmJLFu2zON9P/zwQy666CJatGhBSEgI3bt357bbbmPr1q0+v9+akGCklKzAKoQQwIoV0KEDDBsG11+vf+/QQT8eQFdeeSVbt27ljTfe4I8//uCTTz7hwgsv5NixYwDExMQQFBQU0Dr4wmKxEBMTU+3NA00mE2vWrGH9+vVVls3Pz+fdd99l2rRpLF26tML5H3/8kf79+7Njxw4WLVrEr7/+yoYNG7jjjjt45ZVX+O2335xlX3zxRS6//HKGDBnCpk2b+OWXX7j22mu5++67eeihh9zuO2PGDK655hr69evHJ598ws6dO3n77bfp1KkTMwO9WZtqBHJychSgcnJy/Hrf4uJi9fHHH6vi4mK1caNSUPZls/n1UU2aazuLwJK2rhsNtZ0LCgrU9u3bVUFBQc1u8OGHSmma+3+GoB/TNP18ABw/flwBasOGDW7HbTabOn78uLLZbApQH330kfPct99+q/r27auCgoJUQkKC+uijjxSgtm7dqpRSav369QpQq1atUv369VPBwcFq2LBhKisrS61cuVL16NFDNWvWTF133XUqLy/Ped/CwkJ1//33q9atW6ugoCA1ZMgQ9eOPPzrPO+57/Phx57HXX39dxcfHq5CQEDV27Fj17LPPqsjISLfzkZGRauLEiWrgwIEV3vf69evd3veyZcvUOeeco06cOKFCQ0PVgQMHnOfsdrvq2bOnSkhIUDYvH1R2u10ppdSBAweU2WxWU6dOrVDmhRdeUID64YcflM1mU19++aUC1MKFCyu9pyeV/b3z9fO7yWdGsrODWbUK1qwpO2Yy6dnJt96Czz+Hgwfrr35CCFFjSkFenm9fubkwebJ+jaf7AEyZopfz5X7V2BA+PDyc8PBwPv74Y4qKiqosn5uby5gxY+jduzepqamkpKQwffp0j2WffPJJXnrpJb777jvS09O5+uqrWbBgAW+//TafffYZX375JS+++KKz/LRp0/jwww954403SE1NpUuXLowcOdKZoSlv06ZN3H777dx3332kpaUxbNgw5syZ47Uu27ZtY/ny5ZW+vyVLlnDjjTcSGRnJxRdf7NalkpaWxo4dO3jooYe87rDryNosX74cq9VaIQMCejdQeHg477zzDqB3z4SHh3PvvfdWes+AqTRUaSAClRk5ebJYRUYWVPgloPxXdLRShYV+fXST0lB/izwdSVvXjYbazhV+Qz11qvL/3AL5depUteq+fPly1aJFCxUcHKzOPfdcNXPmTLV161aPmZFXXnlFtWrVyu038cWLF3vMjKxZs8ZZZv78+QpQe/bscR6766671MiRI0ub65Qym83qrbfecp4vLi5Wbdu2VU8//bTbfR2Zkeuuu06NHj3a7b1cc801HjMjSik1Y8YM1a1bN2W1Wj1mRv744w9lNptVdna2Ukqpjz76SHXs2NGZmXj33XcVoFJTU53XZGVlqbCwMOfXokWLlFJK3X333W71KK9Pnz7q4osvVjabTQ0fPlz16dPH7fxzzz3ndt8TJ054vI9kRmrJYoGoqAKg8gg+Pl4vK4QQIjCuvPJK/vrrLz755BNGjRrFhg0bGDBgAG+//XaFsjt37qRPnz4EBwc7jw0cONDjffv06eP8OTo6mtDQUDp16uR27PDhwwDs2bMHq9XKkCFDnOfNZjMDBw5kx44dHu+/Y8cOBg0a5HZs8ODBXt/n9OnTyc7O9jgWBGDp0qWMHDmSqKgoAEaPHk1OTg7r1q3zes9WrVqRlpZGWloazZs3p7i42GvZ8iyVfLjddtttpKWl8a9//Yu8vDxUNbJd1dWkgxFNgxtv3AFUnn6aM0cvK4QQjUpoKJw65dvXypW+3XPlSt/uV4NZAMHBwYwYMYLHH3+c7777jgkTJjB//vxq38eV2Wx2/qxpmttrxzG73V6rZ1RH8+bNmTlzJrNnzyY/P9/tnM1m44033uCzzz7DZDJhMpkIDQ3l2LFjzuCla9eugB6QORiNRrp06UKXLl0wmUzO4127diUnJ4e//vqrQj2Ki4vZs2cP3bp1A6Bz587s3bsXq9XqVtcuXbrQrl07/zWAF006GAHo1y+b/v29/0UcMACSk+uwQkII4S+aBmFhvn0lJ0NcnPffvDRNTxMnJ/t2Pz/8BterV68KH9gA3bt3Z9u2bW7jSzZv3lzr53Xu3BmLxcK3337rPGa1Wtm8eTO9evXyeE3Pnj3ZtGmT2zHHdGRv7r//fgwGAwsXLnQ7vnLlSk6ePMnWrVudmY60tDTeeecdVqxYwYkTJzj77LPp0aMHzz77bJVB1Pjx4zGZTDz33HMVzr366qvk5+dz8803A3pm6tSpU7z88suV3jNQTFUXOb1pGvz973YuvdRzXCZZESFEk2A0wsKFMH68/p+ea0re8Z/gggUV10Hwg6NHj3LVVVdx22230adPH5o1a8ZPP/3EM888w+jRoyuUv/7663n00Ue58847mTFjBgcOHODZZ58trWrN/8MOCwvjnnvu4eGHH6Zly5a0b9+ep59+mvz8fG6//XaP10yePJkhQ4bw7LPPcvnll/PFF1+watWqSp8THBzM7NmzmTRpktvxJUuWcMkll9C3b1+347169eJvf/sbb731FpMmTeL1119nxIgRDBkyhJkzZ9KzZ0+sVitff/012dnZGEv/jBz1f+ihhwgODuamm27CbDbz3//+l0ceeYQ5c+Zw1llnYbfbGThwIFOnTuXBBx/kzz//ZNy4ccTHx3Po0CGWLFmCpmleB8z6RaUjShqIQE/tLSoqVgMGVBx/NWCAUpXMZhI+aqiD/U5H0tZ1o6G2c62n9iqlT9+Ni3P/zzA+PmDTepXSp9POmDFD9e/fX0VGRqrQ0FDVvXt39eijj6q//vrL69TePn36KIvFohISEtTbb7+tAPX7778rpbxPwS0/oPOJJ55Qffv2db4uKChQ999/v4qKivJ5au+SJUtUXFycCgkJUWPGjPE6tddVSUmJ6tWrl3MAa2ZmpjKZTOr999/32Eb33HOPOvvss52vd+7cqSZMmKDi4uKUyWRSkZGR6vzzz1f/+te/lNVqdbv2448/VkOHDlVhYWEKfZCkeuedd5znXadQv/fee+rCCy9UkZGRymw2q7i4OHX99derH374wWO9HG1W2wGsmlIBHJHiJ7m5uURGRpKTk0NERITf7mu1Wlm5ciWjR49m3Toz5RbHY9UqGDnSb49rslzbuXx/rfAvaeu60VDbubCwkH379tGxY0e3wZ3VZrPBxo1w6BDExsLQoQHJiFTFbreTm5tLRERElb+Vv/XWW9x6663k5OQQIktoe3Xs2DGGDx9OREQEn3/+OaGhodVqZ08q+3vn6+d3k++mcUhO1seH/PST/lrGigghmiyjES68sL5rUal///vfdOrUiXbt2vHzzz8zffp0rr76aglEqtCyZUvWrFnDokWL+P777xk+fHh9VwmQYMRJ02D+fHB0C86fL2NFhBCiocrMzGTWrFlkZmYSGxvLVVddxdy5c+u7Wo1Cq1atmDVrVn1Xw40EIy6SkuDPP+u7FkIIIaoybdo0pk2bVt/VEH7S5Kf2CiGEEKJ+STAihBBCiHolwYgQQpxmGsEkSXEa8ccKtjJmRAghThNmsxlN08jOzqZ169aB32k1wOx2O8XFxRQWFgZ2wa0mrqbtrJSiuLiY7OxsDAZDpfvcVEWCESGEOE0YjUbi4uI4ePAg+/fvr+/q1JpSioKCAkJCQhp9YNWQ1badQ0NDad++fa0CRglGhBDiNBIeHk7Xrl3dNjxrrBxLnJ9//vkNanG5001t2tloNGIymWodLEowIoQQpxmj0ejcn6QxMxqNlJSUEBwcLMFIADWEdpZOOCGEEELUKwlGhBBCCFGvJBgRQgghRL1qFGNGHHPmc3Nz/Xpfq9VKfn4+ubm50h8ZQNLOdUfaum5IO9cNaee6Ech2dnxuV7X2TaMIRk6ePAlAfHx8PddECCGEENV18uRJIiMjvZ7XVCNYqs9ut/PXX3/RrFkzv841z83NJT4+nvT0dCIiIvx2X+FO2rnuSFvXDWnnuiHtXDcC2c5KKU6ePEnbtm0rXYekUWRGDAYDcXFxAbt/RESE/EWvA9LOdUfaum5IO9cNaee6Eah2riwj4iADWIUQQghRryQYEUIIIUS9atLBSFBQEE888QRBQUH1XZXTmrRz3ZG2rhvSznVD2rluNIR2bhQDWIUQQghx+mrSmREhhBBC1D8JRoQQQghRryQYEUIIIUS9kmBECCGEEPVKghEhhBBC1KsmHYwsWrSIDh06EBwczKBBg/jxxx/ru0qNytdff82YMWNo27Ytmqbx8ccfu51XSjFr1ixiY2MJCQkhKSmJXbt2uZU5duwYN9xwAxERETRv3pzbb7+dU6dO1eG7aPjmz59PYmIizZo1o02bNowdO5adO3e6lSksLGTSpEm0atWK8PBwrrzySrKystzKHDhwgEsuuYTQ0FDatGnDww8/TElJSV2+lQbtlVdeoU+fPs5VKAcPHsznn3/uPC9tHBhPPfUUmqbxwAMPOI9JW9fek08+iaZpbl89evRwnm9wbayaqHfffVdZLBa1dOlS9dtvv6mJEyeq5s2bq6ysrPquWqOxcuVK9eijj6oVK1YoQH300Udu55966ikVGRmpPv74Y/Xzzz+ryy67THXs2FEVFBQ4y4waNUr17dtX/fDDD2rjxo2qS5cu6rrrrqvjd9KwjRw5Ur3++uvq119/VWlpaWr06NGqffv26tSpU84yd999t4qPj1dr165VP/30kzrnnHPUueee6zxfUlKizjrrLJWUlKS2bt2qVq5cqaKiotTMmTPr4y01SJ988on67LPP1B9//KF27typHnnkEWU2m9Wvv/6qlJI2DoQff/xRdejQQfXp00dNmTLFeVzauvaeeOIJdeaZZ6pDhw45v7Kzs53nG1obN9lgZODAgWrSpEnO1zabTbVt21bNnz+/HmvVeJUPRux2u4qJiVHPPPOM89iJEydUUFCQeuedd5RSSm3fvl0BavPmzc4yn3/+udI0TWVkZNRZ3Rubw4cPK0B99dVXSim9Xc1ms/rggw+cZXbs2KEA9f333yul9MDRYDCozMxMZ5lXXnlFRUREqKKiorp9A41IixYt1GuvvSZtHAAnT55UXbt2VatXr1YXXHCBMxiRtvaPJ554QvXt29fjuYbYxk2ym6a4uJgtW7aQlJTkPGYwGEhKSuL777+vx5qdPvbt20dmZqZbG0dGRjJo0CBnG3///fc0b96cAQMGOMskJSVhMBjYtGlTnde5scjJyQGgZcuWAGzZsgWr1erW1j169KB9+/Zubd27d2+io6OdZUaOHElubi6//fZbHda+cbDZbLz77rvk5eUxePBgaeMAmDRpEpdccolbm4L8ffanXbt20bZtWzp16sQNN9zAgQMHgIbZxo1i115/O3LkCDabza2RAaKjo/n999/rqVanl8zMTACPbew4l5mZSZs2bdzOm0wmWrZs6Swj3Nntdh544AGGDBnCWWedBejtaLFYaN68uVvZ8m3t6c/CcU7otm3bxuDBgyksLCQ8PJyPPvqIXr16kZaWJm3sR++++y6pqals3ry5wjn5++wfgwYNYtmyZXTv3p1Dhw4xe/Zshg4dyq+//tog27hJBiNCNFaTJk3i119/5ZtvvqnvqpyWunfvTlpaGjk5OSxfvpwJEybw1Vdf1Xe1Tivp6elMmTKF1atXExwcXN/VOW1dfPHFzp/79OnDoEGDOOOMM3j//fcJCQmpx5p51iS7aaKiojAajRVGDmdlZRETE1NPtTq9ONqxsjaOiYnh8OHDbudLSko4duyY/Dl4cN999/Hpp5+yfv164uLinMdjYmIoLi7mxIkTbuXLt7WnPwvHOaGzWCx06dKFhIQE5s+fT9++fVm4cKG0sR9t2bKFw4cP079/f0wmEyaTia+++ooXXngBk8lEdHS0tHUANG/enG7durF79+4G+fe5SQYjFouFhIQE1q5d6zxmt9tZu3YtgwcPrseanT46duxITEyMWxvn5uayadMmZxsPHjyYEydOsGXLFmeZdevWYbfbGTRoUJ3XuaFSSnHffffx0UcfsW7dOjp27Oh2PiEhAbPZ7NbWO3fu5MCBA25tvW3bNrfgb/Xq1URERNCrV6+6eSONkN1up6ioSNrYj4YPH862bdtIS0tzfg0YMIAbbrjB+bO0tf+dOnWKPXv2EBsb2zD/Pvt9SGwj8e6776qgoCC1bNkytX37dnXnnXeq5s2bu40cFpU7efKk2rp1q9q6dasC1PPPP6+2bt2q/vzzT6WUPrW3efPm6r///a/65Zdf1OWXX+5xau/ZZ5+tNm3apL755hvVtWtXmdpbzj333KMiIyPVhg0b3Kbp5efnO8vcfffdqn379mrdunXqp59+UoMHD1aDBw92nndM00tOTlZpaWlq1apVqnXr1jIV0sWMGTPUV199pfbt26d++eUXNWPGDKVpmvryyy+VUtLGgeQ6m0YpaWt/ePDBB9WGDRvUvn371LfffquSkpJUVFSUOnz4sFKq4bVxkw1GlFLqxRdfVO3bt1cWi0UNHDhQ/fDDD/VdpUZl/fr1CqjwNWHCBKWUPr338ccfV9HR0SooKEgNHz5c7dy50+0eR48eVdddd50KDw9XERER6tZbb1UnT56sh3fTcHlqY0C9/vrrzjIFBQXq3nvvVS1atFChoaHqiiuuUIcOHXK7z/79+9XFF1+sQkJCVFRUlHrwwQeV1Wqt43fTcN12223qjDPOUBaLRbVu3VoNHz7cGYgoJW0cSOWDEWnr2rvmmmtUbGysslgsql27duqaa65Ru3fvdp5vaG2sKaWU//MtQgghhBC+aZJjRoQQQgjRcEgwIoQQQoh6JcGIEEIIIeqVBCNCCCGEqFcSjAghhBCiXkkwIoQQQoh6JcGIEEIIIeqVBCNCCCGEqFcSjAghhBCiXkkwIoQQQoh6JcGIEEIIIerV/wPtSW4W1MpEEgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import csv\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, datasets\n",
        "import torchvision.transforms as trnsfrms\n",
        "from torchvision.transforms import ToTensor, Resize, Lambda\n",
        "\n",
        "trnsfrms = trnsfrms.Compose([Resize(224), ToTensor(),  Lambda(lambda x: x.repeat(3, 1, 1) ) ])  # Grayscale Images like MNIST and USPS\n",
        "#trnsfrms = trnsfrms.Compose([Resize(224), ToTensor(), ])                                       # Color Images like CIFAR10\n",
        "#trnsfrms = trnsfrms.Compose([ ToTensor(), ]) \n",
        "\n",
        "# Download training data from open datasets.FashionMNIST.MNIST.USPS  / CIFAR10\n",
        "training_data = datasets.USPS(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform= trnsfrms\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.FashionMNIST.MNIST\n",
        "testing_data = datasets.USPS(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform= trnsfrms\n",
        ")\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=batch_size)\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#model = models.regnet_x_400mf(pretrained=True)  #Linear(in_features=400,\n",
        "#model = models.regnet_y_400mf(pretrained=True)  #(fc): Linear(in_features=440,\n",
        "#model = models.regnet_x_800mf(pretrained=True)  #Linear(in_features=672,\n",
        "#model = models.regnet_y_800mf(pretrained=True)  #(fc): Linear(in_features=784,\n",
        "#model = models.regnet_y_1_6gf(pretrained=True)  #Linear(in_features=888,\n",
        "#model = models.regnet_x_1_6gf(pretrained=True)  #Linear(in_features=912,\n",
        "#model = models.regnet_x_3_2gf(pretrained=True)  #Linear(in_features=1008,\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "model = models.regnet_x_400mf(pretrained=True)  \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "model.fc = nn.Sequential(*list(model.fc.children())[:-1])\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "print(model.fc)\n",
        "print(type(model.fc))\n",
        "\n",
        "\n",
        "# Save the raw dataset: USPS MNIST CIFAR10\n",
        "train_dataset = []\n",
        "size = len(train_dataloader.dataset)\n",
        "num_batches = len(train_dataloader)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in train_dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        print(f\"Shape of model(X) [N, C, H, W]: {pred.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "        pred = torch.reshape(pred, (pred.shape[0], -1) )\n",
        "        y = torch.reshape(y, (y.shape[0], -1) )\n",
        "        print(f\"Shape of model(X): {pred.shape} {pred.dtype}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "\n",
        "        train_dataset += torch.cat( (y, pred ), 1)\n",
        "        print(f\"Shape of train_dataset: {len(train_dataset)}, {len(train_dataset[0])}\")\n",
        "\n",
        "print(\"train_dataset :\" + str(len(train_dataset)) + \",\\t\" + str(len(train_dataset[0])) )\n",
        "print(type(train_dataset))\n",
        "with open('REGNET_X_400MF_USPS_TRAINING.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for i in range( len(train_dataset)):                                   #len(train_dataset)):\n",
        "      writer.writerow(train_dataset[i].detach().cpu().numpy())\n",
        "csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "# Save the raw dataset: USPS MNIST CIFAR10\n",
        "test_dataset = []\n",
        "size = len(test_dataloader.dataset)\n",
        "num_batches = len(test_dataloader)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        print(f\"Shape of model(X) [N, C, H, W]: {pred.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "        pred = torch.reshape(pred, (pred.shape[0], -1) )\n",
        "        y = torch.reshape(y, (y.shape[0], -1) )\n",
        "        print(f\"Shape of model(X): {pred.shape} {pred.dtype}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "\n",
        "        test_dataset += torch.cat( (y, pred ), 1)\n",
        "        print(f\"Shape of test_dataset: {len(test_dataset)}, {len(test_dataset[0])}\")\n",
        "\n",
        "print(\"test_dataset :\" + str(len(test_dataset)) + \",\\t\" + str(len(test_dataset[0])) )\n",
        "print(type(test_dataset))\n",
        "with open('REGNET_X_400MF_USPS_TESTING.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for i in range(len(test_dataset)):\n",
        "      writer.writerow(test_dataset[i].detach().cpu().numpy())\n",
        "csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# coding=utf8\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "\n",
        "from copy import deepcopy\n",
        "from math import log, exp, pow, sqrt\n",
        "\n",
        "import matplotlib\n",
        "#matplotlib.use('pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "\n",
        "\n",
        "#hlambda = lambda x:1.0/(1+exp(-x))\n",
        "#Sigmoid(x) ~ poly3 = 0.5 + 0.10679534503216294.*x + -0.00038503259805075.*x.^3; (lambda = 128)\n",
        "def hlambda(x):\n",
        "    x[x>+8] = +8\n",
        "    x[x<-8] = -8\n",
        "    res = 1 / (1 + np.exp(-x) )\n",
        "    #res = 5.0000e-01  + 0.10679534503216294 * x  - 0.00038503259805075 * np.multiply(np.multiply(x,  x), x)\n",
        "    return res \n",
        "\n",
        "\n",
        "\n",
        "import csv\n",
        "epsilon = 1e-10\n",
        "num_iter = 500\n",
        "\n",
        "\n",
        "with open(\"REGNET_X_400MF_USPS_TRAINING.csv\",'r') as csvfile:\n",
        "#with open(\"REGNET_X_400MF_USPS_TESTING.csv\",'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    traindata = []\n",
        "    for row in reader:\n",
        "        row = [float(x) for x in row]\n",
        "        traindata.append(row)\n",
        "csvfile.close()\n",
        "with open(\"REGNET_X_400MF_USPS_TESTING.csv\", 'r') as csvfile:\n",
        "#with open(\"REGNET_X_400MF_USPS_TRAININGfirst8192.csv\",'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    testdata = []\n",
        "    for row in reader:\n",
        "        row = [float(x) for x in row]\n",
        "        testdata.append(row)\n",
        "csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#traindata = traindata[:6144]\n",
        "TrainX = [row[1:] for row in traindata[:]]\n",
        "TestX = [row[1:] for row in testdata[:]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = []\n",
        "Xtest  = []\n",
        "\n",
        "\n",
        "for (rowidx, row) in enumerate(TrainX):\n",
        "    #TrainData.append( [ trainy[rowidx] ] + row )\n",
        "    X.append( [ 1.0 ] + row )\n",
        "for (rowidx, row) in enumerate(TestX):\n",
        "    #TestData.append( [ testy[rowidx] ] + row )\n",
        "    Xtest.append( [ 1.0 ] + row )\n",
        "   \n",
        "#X = X[:]\n",
        "X = np.matrix(X)\n",
        "Xtest = np.matrix(Xtest)\n",
        "\n",
        "\n",
        "ytrain = [int(row[0]) for row in traindata[:]]\n",
        "ytest = [int(row[0]) for row in testdata[:]]\n",
        "\n",
        "#y = self.one_hot(y)\n",
        "Y = []\n",
        "for rowidx in range( len(traindata) ):\n",
        "    row = []\n",
        "    for colidx in range( len( set(ytrain + ytest) ) ):\n",
        "        if colidx == ytrain[rowidx]:\n",
        "            row.append( 1 )\n",
        "        else:\n",
        "            row.append( 0 )\n",
        "    Y.append( row )\n",
        "\n",
        "#Y = Y[:]\n",
        "Y = np.matrix(Y)\n",
        "\n",
        "Ytest = []\n",
        "for rowidx in range( len(testdata) ):\n",
        "    row = []\n",
        "    for colidx in range( len( set(ytrain + ytest) ) ):\n",
        "        if colidx == ytest[rowidx]:\n",
        "            row.append( 1 )\n",
        "        else:\n",
        "            row.append( 0 )\n",
        "    Ytest.append( row )\n",
        "Ytest = np.matrix(Ytest)\n",
        "\n",
        "\n",
        "#     Step 2. Extract X and Y from data\n",
        "\n",
        "\n",
        "\n",
        "def precision(vec0, vec1):\n",
        "    if len(vec0) != len(vec1):\n",
        "        return -1\n",
        "    totalnum = len(vec0)\n",
        "    rightnum = 0.0\n",
        "    for idx in range(totalnum):\n",
        "        if vec0[idx] == vec1[idx]:\n",
        "            rightnum += 1\n",
        "    return rightnum / totalnum\n",
        "\n",
        "\n",
        "\n",
        "# ======================================= Raw NAG without QG ======================================= \n",
        "# Build the initial weight matrix\n",
        "velocity = []\n",
        "for rowidx in range( len(set(ytrain)) ):\n",
        "    vrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        vrow.append( 0.0 )\n",
        "    velocity.append(vrow)\n",
        "velocity = np.matrix( velocity )\n",
        "weights = []\n",
        "for rowidx in range( len(set(ytest+ytrain)) ):\n",
        "    wrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        wrow.append( 0.0 )\n",
        "    weights.append(wrow)\n",
        "weights = np.matrix( weights )\n",
        "\n",
        "\n",
        "NAG_result_prec_train = []\n",
        "NAG_result_loss_train = []\n",
        "z = np.dot(X, weights.T).reshape(-1,len(set(ytrain+ytest)))\n",
        "probs = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "loss =   -1 * np.mean(np.multiply(Y,  np.log(probs)) )\n",
        "NAG_result_loss_train.append( loss )\n",
        "NAG_result_prec_train.append( precision(np.argmax(probs, axis=1) ,ytrain) )\n",
        "\n",
        "NAG_result_prec_test = []\n",
        "NAG_result_loss_test = []\n",
        "z = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)))\n",
        "probs = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "loss =   -1 * np.mean(np.multiply(Ytest,  np.log(probs)) )\n",
        "NAG_result_loss_test.append( loss )\n",
        "NAG_result_prec_test.append( precision(np.argmax(probs, axis=1) ,ytest) )\n",
        "\n",
        "\n",
        "alpha0 = 0.01\n",
        "alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "start_time = time.time()\n",
        "for it in range(num_iter):\n",
        "    # np.dot(X, np.matrix(weights).T)  #.reshape(-1,len(self.classes))\n",
        "    z = np.dot(X, velocity.T).reshape(-1,len(set(ytrain+ytest)) )\n",
        "    \n",
        "    zi = z - np.max(z,-1)\n",
        "    h = np.exp(zi) / np.sum(np.exp(zi), axis=1)\n",
        "\n",
        "    gradient = -(h - Y).T.dot(X)\n",
        "\n",
        "\n",
        "    eta = (1 - alpha0) / alpha1\n",
        "    gamma = 1.0/(it+1)/ X.shape[0]\n",
        "    \n",
        "    MG = gradient          \n",
        "    # should be 'plus', 'cause to compute the MLE  \n",
        "    MtmpW = weights + (gamma + 0.0) * MG            \n",
        "    weights = (1.0-eta)*MtmpW + np.multiply(eta, velocity)\n",
        "    velocity = MtmpW\n",
        "\n",
        "    alpha0 = alpha1\n",
        "    alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "\n",
        "    zz = np.dot(X, weights.T).reshape(-1,len(set(ytrain)) )\n",
        "    zzi = zz - np.max(zz,-1)\n",
        "    pp = np.exp(zzi) / np.sum(np.exp(zzi), axis=1)\n",
        "    loss =  -1 * np.mean(np.multiply(Y,  np.log(pp)) )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytrain)\n",
        "    NAG_result_loss_train.append( loss )\n",
        "    NAG_result_prec_train.append( prec )\n",
        "    #print(' Training Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "    zz = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)) )\n",
        "    zzi = zz - np.max(zz,-1)\n",
        "    pp = np.exp(zzi) / np.sum(np.exp(zzi), axis=1)\n",
        "    loss =  -1 * np.mean(np.multiply(Ytest,  np.log(pp)) )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytest)\n",
        "    NAG_result_loss_test.append( loss )\n",
        "    NAG_result_prec_test.append( prec )\n",
        "    print(' Testing Accuray at {:2d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "\n",
        "#############################################################################################################3\n",
        "# ======================================= SigmoidNAG without QG ======================================= \n",
        "# Build the initial weight matrix\n",
        "velocity = []\n",
        "for rowidx in range( len(set(ytrain)) ):\n",
        "    vrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        vrow.append( 0.0 )\n",
        "    velocity.append(vrow)\n",
        "velocity = np.matrix( velocity )\n",
        "weights = []\n",
        "for rowidx in range( len(set(ytest+ytrain)) ):\n",
        "    wrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        wrow.append( 0.0 )\n",
        "    weights.append(wrow)\n",
        "weights = np.matrix( weights )\n",
        "\n",
        "\n",
        "\n",
        "SigmoidNAG_result_prec_train = []\n",
        "SigmoidNAG_result_loss_train = []\n",
        "z = np.dot(X, weights.T).reshape(-1,len(set(ytrain+ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =   np.sum( np.log( np.absolute(probs -1 + Y) )  )\n",
        "SigmoidNAG_result_loss_train.append( loss )\n",
        "SigmoidNAG_result_prec_train.append( precision(np.argmax(probs, axis=1) ,ytrain) )\n",
        "\n",
        "SigmoidNAG_result_prec_test = []\n",
        "SigmoidNAG_result_loss_test = []\n",
        "z = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =   np.sum( np.log( np.absolute(probs -1 + Ytest) )  )\n",
        "SigmoidNAG_result_loss_test.append( loss )\n",
        "SigmoidNAG_result_prec_test.append( precision(np.argmax(probs, axis=1) ,ytest) )\n",
        "\n",
        "\n",
        "alpha0 = 0.01\n",
        "alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "start_time = time.time()\n",
        "for it in range(num_iter):\n",
        "\n",
        "    # np.dot(X, np.matrix(weights).T)  #.reshape(-1,len(self.classes))\n",
        "    z = np.dot(X, velocity.T).reshape(-1,len(set(ytest+ytrain)) ) \n",
        "    \n",
        "    #P = 1.0 / ( 1.0 + np.exp(-z) ) \n",
        "    P = hlambda(z)\n",
        "\n",
        "    \n",
        "    gradient = (Y - P).T.dot(X)\n",
        "   \n",
        "\n",
        "    eta = (1 - alpha0) / alpha1\n",
        "    gamma = 1.0/(it+1)/ X.shape[0]\n",
        "            \n",
        "    # should be 'plus', 'cause to compute the MLE\n",
        "    MtmpW = weights + (gamma + 0.0) * gradient               \n",
        "    weights = (1.0-eta)*MtmpW + np.multiply(eta, velocity)\n",
        "    velocity = MtmpW\n",
        "\n",
        "    alpha0 = alpha1\n",
        "    alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "\n",
        "\n",
        "\n",
        "    zz = np.dot(X, weights.T).reshape(-1,len(set(ytest+ytrain)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Y) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytrain)\n",
        "    SigmoidNAG_result_loss_train.append( loss )\n",
        "    SigmoidNAG_result_prec_train.append( prec )\n",
        "    #print('SigmoidNAG without QG Training Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "    zz = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Ytest) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytest)\n",
        "    SigmoidNAG_result_loss_test.append( loss )\n",
        "    SigmoidNAG_result_prec_test.append( prec )\n",
        "    print('SigmoidNAG without QG Testing Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "\n",
        "\n",
        "#############################################################################################################3\n",
        "\n",
        "# ======================================= SigmoidNAG with QG ======================================= \n",
        "# Build the initial weight matrix\n",
        "velocity = []\n",
        "for rowidx in range( len(set(ytrain)) ):\n",
        "    vrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        vrow.append( 0.0 )\n",
        "    velocity.append(vrow)\n",
        "velocity = np.matrix( velocity )\n",
        "weights = []\n",
        "for rowidx in range( len(set(ytest+ytrain)) ):\n",
        "    wrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        wrow.append( 0.0 )\n",
        "    weights.append(wrow)\n",
        "weights = np.matrix( weights )\n",
        "\n",
        "\n",
        "SigmoidNAGQG_result_prec_train = []\n",
        "SigmoidNAGQG_result_loss_train = []\n",
        "z = np.dot(X, weights.T).reshape(-1,len(set(ytrain+ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =   np.sum( np.log( np.absolute(probs -1 + Y) )  ) \n",
        "SigmoidNAGQG_result_loss_train.append( loss )\n",
        "SigmoidNAGQG_result_prec_train.append( precision(np.argmax(probs, axis=1) ,ytrain) )\n",
        "\n",
        "SigmoidNAGQG_result_prec_test = []\n",
        "SigmoidNAGQG_result_loss_test = []\n",
        "z = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =    np.sum( np.log( np.absolute(probs -1 + Ytest) )  )  \n",
        "SigmoidNAGQG_result_loss_test.append( loss )\n",
        "SigmoidNAGQG_result_prec_test.append( precision(np.argmax(probs, axis=1) ,ytest) )\n",
        "\n",
        "print('X := ')\n",
        "print(X)\n",
        "start_time = time.time()\n",
        "XTX = X.T.dot(X)\n",
        "print('XTX := ')\n",
        "print(XTX)\n",
        "#B = np.sum((XTX * .5), axis=0) + epsilon\n",
        "invBrow = 1.0 / ( epsilon +  .25 * np.sum(XTX, axis=0) )\n",
        "print('invBrow := ')\n",
        "print(invBrow)\n",
        "\n",
        "alpha0 = 0.01\n",
        "alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "start_time = time.time()\n",
        "for it in range(num_iter):\n",
        "\n",
        "    # np.dot(X, np.matrix(weights).T)  #.reshape(-1,len(self.classes))\n",
        "    z = np.dot(X, velocity.T).reshape(-1,len(set(ytest+ytrain)) ) \n",
        "    \n",
        "    #P = 1.0 / ( 1.0 + np.exp(-z) ) \n",
        "    P = hlambda(z)\n",
        "\n",
        "    \n",
        "    gradient = (Y - P).T.dot(X)\n",
        "  \n",
        "    MG = np.multiply(invBrow, gradient)  \n",
        "\n",
        "    eta = (1 - alpha0) / alpha1\n",
        "    gamma = 1.0/(it+1)/ X.shape[0]\n",
        "            \n",
        "    # should be 'plus', 'cause to compute the MLE\n",
        "    MtmpW = weights + (gamma + 1.0) * MG               \n",
        "    weights = (1.0-eta)*MtmpW + np.multiply(eta, velocity)\n",
        "    velocity = MtmpW\n",
        "\n",
        "    alpha0 = alpha1\n",
        "    alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "\n",
        "\n",
        "\n",
        "    zz = np.dot(X, weights.T).reshape(-1,len(set(ytest+ytrain)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Y) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytrain)\n",
        "    SigmoidNAGQG_result_loss_train.append( loss )\n",
        "    SigmoidNAGQG_result_prec_train.append( prec )\n",
        "    #print('SigmoidNAG with QG Training Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "    zz = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Ytest) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytest)\n",
        "    SigmoidNAGQG_result_loss_test.append( loss )\n",
        "    SigmoidNAGQG_result_prec_test.append( prec )\n",
        "    print('SigmoidNAG with QG Testing Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "\n",
        "\n",
        "EnAdagradTimeDiff = time.time() - start_time\n",
        "print(\"TotalEnAdagradTimeDiff = \"), print(EnAdagradTimeDiff)\n",
        "print(\"AveraEnAdagradTimeDiff = \"), print(EnAdagradTimeDiff/num_iter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label = [  'NAG', 'SigmoidNAG', 'SigmoidNAGQG' ]\n",
        "plt.plot(range(len(NAG_result_prec_train)), NAG_result_prec_train, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_prec_train)), SigmoidNAG_result_prec_train, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_prec_train)), SigmoidNAGQG_result_prec_train, 'o-r')\n",
        "plt.title('train precision')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "#plt.savefig(\"prec_train_.pdf\")\n",
        "plt.close()\n",
        "plt.plot(range(len(NAG_result_prec_test)), NAG_result_prec_test, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_prec_test)), SigmoidNAG_result_prec_test, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_prec_test)), SigmoidNAGQG_result_prec_test, 'o-r')\n",
        "plt.title('test precision')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "#plt.savefig(\"prec_test_.pdf\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "plt.plot(range(len(NAG_result_loss_train)), NAG_result_loss_train, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_loss_train)), SigmoidNAG_result_loss_train, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_loss_train)), SigmoidNAGQG_result_loss_train, 'o-r')\n",
        "plt.title('train loss')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.close()\n",
        "plt.plot(range(len(NAG_result_loss_test)), NAG_result_loss_test, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_loss_test)), SigmoidNAG_result_loss_test, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_loss_test)), SigmoidNAGQG_result_loss_test, 'o-r')\n",
        "plt.title('test loss')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "#plt.savefig(\"loss_test_.pdf\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "\n",
        "# -------------- FILE: LOSS training -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_LOSS_training_USPS.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_loss_train):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_loss_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_loss_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_loss_train[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "# -------------- FILE: LOSS testing -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_LOSS_testing_USPS.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_loss_test):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_loss_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_loss_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_loss_test[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "\n",
        "# -------------- FILE: PREC training -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_PREC_training_USPS.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_prec_train):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_prec_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_prec_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_prec_train[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "# -------------- FILE: PREC testing -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_PREC_testing_USPS.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_prec_test):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_prec_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_prec_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_prec_test[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}