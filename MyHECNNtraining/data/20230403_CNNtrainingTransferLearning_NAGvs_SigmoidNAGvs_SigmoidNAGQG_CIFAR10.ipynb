{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "goNemCsROZdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f6fd1e66-db27-4242-bc5d-97dd6eb42cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:14<00:00, 11751690.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Using cuda device\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RegNet_X_400MF_Weights.IMAGENET1K_V1`. You can also use `weights=RegNet_X_400MF_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/regnet_x_400mf-adf1edd5.pth\" to /root/.cache/torch/hub/checkpoints/regnet_x_400mf-adf1edd5.pth\n",
            "100%|██████████| 21.3M/21.3M [00:00<00:00, 25.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RegNet(\n",
            "  (stem): SimpleStemIN(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (trunk_output): Sequential(\n",
            "    (block1): AnyStage(\n",
            "      (block1-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=2, bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block2): AnyStage(\n",
            "      (block2-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=4, bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block2-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block3): AnyStage(\n",
            "      (block3-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-3): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-4): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-5): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block3-6): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=10, bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (block4): AnyStage(\n",
            "      (block4-0): ResBottleneckBlock(\n",
            "        (proj): Conv2dNormActivation(\n",
            "          (0): Conv2d(160, 400, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(160, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-1): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-2): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-3): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-4): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-5): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-6): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-7): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-8): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-9): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-10): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "      (block4-11): ResBottleneckBlock(\n",
            "        (f): BottleneckTransform(\n",
            "          (a): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (b): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=25, bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "          )\n",
            "          (c): Conv2dNormActivation(\n",
            "            (0): Conv2d(400, 400, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (activation): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Sequential()\n",
            ")\n",
            "Sequential()\n",
            "<class 'torch.nn.modules.container.Sequential'>\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 512, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 1024, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 1536, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 2048, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 2560, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 3072, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 3584, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 4096, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 4608, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 5120, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 5632, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 6144, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 6656, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 7168, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 7680, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 8192, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 8704, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 9216, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 9728, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 10240, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 10752, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 11264, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 11776, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 12288, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 12800, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 13312, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 13824, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 14336, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 14848, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 15360, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 15872, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 16384, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 16896, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 17408, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 17920, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 18432, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 18944, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 19456, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 19968, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 20480, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 20992, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 21504, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 22016, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 22528, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 23040, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 23552, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 24064, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 24576, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 25088, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 25600, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 26112, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 26624, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 27136, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 27648, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 28160, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 28672, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 29184, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 29696, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 30208, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 30720, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 31232, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 31744, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 32256, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 32768, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 33280, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 33792, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 34304, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 34816, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 35328, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 35840, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 36352, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 36864, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 37376, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 37888, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 38400, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 38912, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 39424, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 39936, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 40448, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 40960, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 41472, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 41984, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 42496, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 43008, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 43520, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 44032, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 44544, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 45056, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 45568, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 46080, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 46592, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 47104, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 47616, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 48128, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 48640, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 49152, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of train_dataset: 49664, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([336, 400])\n",
            "Shape of y: torch.Size([336]) torch.int64\n",
            "Shape of model(X): torch.Size([336, 400]) torch.float32\n",
            "Shape of y: torch.Size([336, 1]) torch.int64\n",
            "Shape of train_dataset: 50000, 401\n",
            "train_dataset :50000,\t401\n",
            "<class 'list'>\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 512, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 1024, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 1536, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 2048, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 2560, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 3072, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 3584, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 4096, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 4608, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 5120, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 5632, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 6144, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 6656, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 7168, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 7680, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 8192, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 8704, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 9216, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([512, 400])\n",
            "Shape of y: torch.Size([512]) torch.int64\n",
            "Shape of model(X): torch.Size([512, 400]) torch.float32\n",
            "Shape of y: torch.Size([512, 1]) torch.int64\n",
            "Shape of test_dataset: 9728, 401\n",
            "Shape of model(X) [N, C, H, W]: torch.Size([272, 400])\n",
            "Shape of y: torch.Size([272]) torch.int64\n",
            "Shape of model(X): torch.Size([272, 400]) torch.float32\n",
            "Shape of y: torch.Size([272, 1]) torch.int64\n",
            "Shape of test_dataset: 10000, 401\n",
            "test_dataset :10000,\t401\n",
            "<class 'list'>\n",
            " Testing Accuray at  1 iterations is 0.248300000000 with loss: 0.228657988282\n",
            " Testing Accuray at  2 iterations is 0.214300000000 with loss: 1.871108455856\n",
            " Testing Accuray at  3 iterations is 0.100000000000 with loss: 2.731148121229\n",
            " Testing Accuray at  4 iterations is 0.100000000000 with loss: 3.543899811776\n",
            " Testing Accuray at  5 iterations is 0.106800000000 with loss: 3.994802395559\n",
            " Testing Accuray at  6 iterations is 0.109400000000 with loss: 4.947500120393\n",
            " Testing Accuray at  7 iterations is 0.100100000000 with loss: 5.537502584829\n",
            " Testing Accuray at  8 iterations is 0.100000000000 with loss: 5.689180144870\n",
            " Testing Accuray at  9 iterations is 0.150800000000 with loss: 5.624711451447\n",
            " Testing Accuray at 10 iterations is 0.143200000000 with loss: 5.161014610806\n",
            " Testing Accuray at 11 iterations is 0.100000000000 with loss: 5.941469328415\n",
            " Testing Accuray at 12 iterations is 0.100700000000 with loss: 4.422952407543\n",
            " Testing Accuray at 13 iterations is 0.143700000000 with loss: 3.105516287728\n",
            " Testing Accuray at 14 iterations is 0.183400000000 with loss: 2.727525530478\n",
            " Testing Accuray at 15 iterations is 0.208800000000 with loss: 1.511075418874\n",
            " Testing Accuray at 16 iterations is 0.338100000000 with loss: 1.045091594820\n",
            " Testing Accuray at 17 iterations is 0.304500000000 with loss: 2.010651155054\n",
            " Testing Accuray at 18 iterations is 0.237300000000 with loss: 2.287907080180\n",
            " Testing Accuray at 19 iterations is 0.248400000000 with loss: 2.128542024034\n",
            " Testing Accuray at 20 iterations is 0.304100000000 with loss: 1.705712256548\n",
            " Testing Accuray at 21 iterations is 0.320700000000 with loss: 1.341588429103\n",
            " Testing Accuray at 22 iterations is 0.349600000000 with loss: 1.071274959601\n",
            " Testing Accuray at 23 iterations is 0.295300000000 with loss: 1.004142770741\n",
            " Testing Accuray at 24 iterations is 0.232000000000 with loss: 0.946264516629\n",
            " Testing Accuray at 25 iterations is 0.303500000000 with loss: 0.669894592794\n",
            " Testing Accuray at 26 iterations is 0.259200000000 with loss: 0.941456084823\n",
            " Testing Accuray at 27 iterations is 0.258500000000 with loss: 1.149643406715\n",
            " Testing Accuray at 28 iterations is 0.308300000000 with loss: 1.021630583372\n",
            " Testing Accuray at 29 iterations is 0.375500000000 with loss: 0.860654408733\n",
            " Testing Accuray at 30 iterations is 0.410700000000 with loss: 0.709878808468\n",
            " Testing Accuray at 31 iterations is 0.433600000000 with loss: 0.560654736250\n",
            " Testing Accuray at 32 iterations is 0.433700000000 with loss: 0.480078642834\n",
            " Testing Accuray at 33 iterations is 0.402600000000 with loss: 0.512235530043\n",
            " Testing Accuray at 34 iterations is 0.435400000000 with loss: 0.516321567389\n",
            " Testing Accuray at 35 iterations is 0.429100000000 with loss: 0.609602647494\n",
            " Testing Accuray at 36 iterations is 0.356600000000 with loss: 0.740462721647\n",
            " Testing Accuray at 37 iterations is 0.358300000000 with loss: 0.696260645260\n",
            " Testing Accuray at 38 iterations is 0.420800000000 with loss: 0.514117028852\n",
            " Testing Accuray at 39 iterations is 0.493700000000 with loss: 0.332633361820\n",
            " Testing Accuray at 40 iterations is 0.533900000000 with loss: 0.273447562519\n",
            " Testing Accuray at 41 iterations is 0.495900000000 with loss: 0.359428421700\n",
            " Testing Accuray at 42 iterations is 0.461600000000 with loss: 0.471897611151\n",
            " Testing Accuray at 43 iterations is 0.452100000000 with loss: 0.506326482662\n",
            " Testing Accuray at 44 iterations is 0.472400000000 with loss: 0.463184543967\n",
            " Testing Accuray at 45 iterations is 0.494300000000 with loss: 0.392149351562\n",
            " Testing Accuray at 46 iterations is 0.506400000000 with loss: 0.338315062864\n",
            " Testing Accuray at 47 iterations is 0.526000000000 with loss: 0.298978677237\n",
            " Testing Accuray at 48 iterations is 0.545700000000 with loss: 0.271200748730\n",
            " Testing Accuray at 49 iterations is 0.529200000000 with loss: 0.295608553525\n",
            " Testing Accuray at 50 iterations is 0.483200000000 with loss: 0.367016866791\n",
            " Testing Accuray at 51 iterations is 0.457700000000 with loss: 0.405635554051\n",
            " Testing Accuray at 52 iterations is 0.474800000000 with loss: 0.380389215608\n",
            " Testing Accuray at 53 iterations is 0.520500000000 with loss: 0.317020068870\n",
            " Testing Accuray at 54 iterations is 0.549500000000 with loss: 0.273028903337\n",
            " Testing Accuray at 55 iterations is 0.531100000000 with loss: 0.275270449960\n",
            " Testing Accuray at 56 iterations is 0.528300000000 with loss: 0.270742532454\n",
            " Testing Accuray at 57 iterations is 0.559100000000 with loss: 0.241801049086\n",
            " Testing Accuray at 58 iterations is 0.584900000000 with loss: 0.227844173534\n",
            " Testing Accuray at 59 iterations is 0.563600000000 with loss: 0.247743474769\n",
            " Testing Accuray at 60 iterations is 0.538200000000 with loss: 0.276142165229\n",
            " Testing Accuray at 61 iterations is 0.531500000000 with loss: 0.288126582382\n",
            " Testing Accuray at 62 iterations is 0.539100000000 with loss: 0.275301511107\n",
            " Testing Accuray at 63 iterations is 0.556300000000 with loss: 0.245329667492\n",
            " Testing Accuray at 64 iterations is 0.577000000000 with loss: 0.218868173341\n",
            " Testing Accuray at 65 iterations is 0.581900000000 with loss: 0.212180610972\n",
            " Testing Accuray at 66 iterations is 0.574400000000 with loss: 0.222666593804\n",
            " Testing Accuray at 67 iterations is 0.561100000000 with loss: 0.234929636398\n",
            " Testing Accuray at 68 iterations is 0.559900000000 with loss: 0.236091006428\n",
            " Testing Accuray at 69 iterations is 0.571700000000 with loss: 0.225158741348\n",
            " Testing Accuray at 70 iterations is 0.576800000000 with loss: 0.213815421348\n",
            " Testing Accuray at 71 iterations is 0.577500000000 with loss: 0.210587678330\n",
            " Testing Accuray at 72 iterations is 0.579300000000 with loss: 0.207024614376\n",
            " Testing Accuray at 73 iterations is 0.591400000000 with loss: 0.194074123999\n",
            " Testing Accuray at 74 iterations is 0.606700000000 with loss: 0.180602638283\n",
            " Testing Accuray at 75 iterations is 0.612000000000 with loss: 0.179747192196\n",
            " Testing Accuray at 76 iterations is 0.601900000000 with loss: 0.186693137303\n",
            " Testing Accuray at 77 iterations is 0.600500000000 with loss: 0.191185004779\n",
            " Testing Accuray at 78 iterations is 0.602300000000 with loss: 0.193375455812\n",
            " Testing Accuray at 79 iterations is 0.598800000000 with loss: 0.196639102012\n",
            " Testing Accuray at 80 iterations is 0.587200000000 with loss: 0.199607852320\n",
            " Testing Accuray at 81 iterations is 0.581300000000 with loss: 0.197866982131\n",
            " Testing Accuray at 82 iterations is 0.587200000000 with loss: 0.188539050940\n",
            " Testing Accuray at 83 iterations is 0.601200000000 with loss: 0.172905296678\n",
            " Testing Accuray at 84 iterations is 0.619900000000 with loss: 0.156629455923\n",
            " Testing Accuray at 85 iterations is 0.635500000000 with loss: 0.147340555177\n",
            " Testing Accuray at 86 iterations is 0.636500000000 with loss: 0.149896876334\n",
            " Testing Accuray at 87 iterations is 0.618300000000 with loss: 0.162733619001\n",
            " Testing Accuray at 88 iterations is 0.597600000000 with loss: 0.177969100322\n",
            " Testing Accuray at 89 iterations is 0.587700000000 with loss: 0.186105320165\n",
            " Testing Accuray at 90 iterations is 0.590300000000 with loss: 0.182194580897\n",
            " Testing Accuray at 91 iterations is 0.606000000000 with loss: 0.168423747431\n",
            " Testing Accuray at 92 iterations is 0.628500000000 with loss: 0.151717008574\n",
            " Testing Accuray at 93 iterations is 0.647800000000 with loss: 0.139048793218\n",
            " Testing Accuray at 94 iterations is 0.658700000000 with loss: 0.134229573656\n",
            " Testing Accuray at 95 iterations is 0.654100000000 with loss: 0.137474534684\n",
            " Testing Accuray at 96 iterations is 0.640700000000 with loss: 0.146266785755\n",
            " Testing Accuray at 97 iterations is 0.622300000000 with loss: 0.156311740678\n",
            " Testing Accuray at 98 iterations is 0.608600000000 with loss: 0.162992639972\n",
            " Testing Accuray at 99 iterations is 0.608400000000 with loss: 0.163657118014\n",
            " Testing Accuray at 100 iterations is 0.616900000000 with loss: 0.158865712560\n",
            " Testing Accuray at 101 iterations is 0.625800000000 with loss: 0.151018340048\n",
            " Testing Accuray at 102 iterations is 0.639800000000 with loss: 0.142567299484\n",
            " Testing Accuray at 103 iterations is 0.649000000000 with loss: 0.135834246126\n",
            " Testing Accuray at 104 iterations is 0.652000000000 with loss: 0.132773455340\n",
            " Testing Accuray at 105 iterations is 0.648900000000 with loss: 0.133696610964\n",
            " Testing Accuray at 106 iterations is 0.640600000000 with loss: 0.136937421678\n",
            " Testing Accuray at 107 iterations is 0.635800000000 with loss: 0.140097952988\n",
            " Testing Accuray at 108 iterations is 0.635700000000 with loss: 0.141331970137\n",
            " Testing Accuray at 109 iterations is 0.640100000000 with loss: 0.140029358554\n",
            " Testing Accuray at 110 iterations is 0.647600000000 with loss: 0.136982388847\n",
            " Testing Accuray at 111 iterations is 0.652000000000 with loss: 0.133764993179\n",
            " Testing Accuray at 112 iterations is 0.650000000000 with loss: 0.131381675318\n",
            " Testing Accuray at 113 iterations is 0.648900000000 with loss: 0.129546825947\n",
            " Testing Accuray at 114 iterations is 0.651000000000 with loss: 0.127466751183\n",
            " Testing Accuray at 115 iterations is 0.655200000000 with loss: 0.124985259389\n",
            " Testing Accuray at 116 iterations is 0.657100000000 with loss: 0.122947674868\n",
            " Testing Accuray at 117 iterations is 0.658500000000 with loss: 0.122743490716\n",
            " Testing Accuray at 118 iterations is 0.656400000000 with loss: 0.125041615518\n",
            " Testing Accuray at 119 iterations is 0.649200000000 with loss: 0.128554527907\n",
            " Testing Accuray at 120 iterations is 0.643700000000 with loss: 0.130776079910\n",
            " Testing Accuray at 121 iterations is 0.646200000000 with loss: 0.130370658731\n",
            " Testing Accuray at 122 iterations is 0.651300000000 with loss: 0.128048834025\n",
            " Testing Accuray at 123 iterations is 0.655700000000 with loss: 0.125144872653\n",
            " Testing Accuray at 124 iterations is 0.657500000000 with loss: 0.122280530450\n",
            " Testing Accuray at 125 iterations is 0.662800000000 with loss: 0.119460368215\n",
            " Testing Accuray at 126 iterations is 0.668500000000 with loss: 0.116791405306\n",
            " Testing Accuray at 127 iterations is 0.671800000000 with loss: 0.114843094379\n",
            " Testing Accuray at 128 iterations is 0.672800000000 with loss: 0.114349592474\n",
            " Testing Accuray at 129 iterations is 0.671900000000 with loss: 0.115503247705\n",
            " Testing Accuray at 130 iterations is 0.670300000000 with loss: 0.117518573230\n",
            " Testing Accuray at 131 iterations is 0.664200000000 with loss: 0.118998858547\n",
            " Testing Accuray at 132 iterations is 0.663600000000 with loss: 0.118850777064\n",
            " Testing Accuray at 133 iterations is 0.665100000000 with loss: 0.116964340367\n",
            " Testing Accuray at 134 iterations is 0.671600000000 with loss: 0.114218301707\n",
            " Testing Accuray at 135 iterations is 0.678200000000 with loss: 0.111907712174\n",
            " Testing Accuray at 136 iterations is 0.678300000000 with loss: 0.110933296419\n",
            " Testing Accuray at 137 iterations is 0.679400000000 with loss: 0.111233788831\n",
            " Testing Accuray at 138 iterations is 0.676000000000 with loss: 0.111928272140\n",
            " Testing Accuray at 139 iterations is 0.677800000000 with loss: 0.112117559686\n",
            " Testing Accuray at 140 iterations is 0.678200000000 with loss: 0.111561641408\n",
            " Testing Accuray at 141 iterations is 0.683800000000 with loss: 0.110639179755\n",
            " Testing Accuray at 142 iterations is 0.682800000000 with loss: 0.109848947982\n",
            " Testing Accuray at 143 iterations is 0.681000000000 with loss: 0.109418838336\n",
            " Testing Accuray at 144 iterations is 0.679900000000 with loss: 0.109272520047\n",
            " Testing Accuray at 145 iterations is 0.680300000000 with loss: 0.109203877182\n",
            " Testing Accuray at 146 iterations is 0.679600000000 with loss: 0.109033409918\n",
            " Testing Accuray at 147 iterations is 0.680000000000 with loss: 0.108657484149\n",
            " Testing Accuray at 148 iterations is 0.684000000000 with loss: 0.108002088803\n",
            " Testing Accuray at 149 iterations is 0.684000000000 with loss: 0.106973561249\n",
            " Testing Accuray at 150 iterations is 0.685000000000 with loss: 0.105519954539\n",
            " Testing Accuray at 151 iterations is 0.686500000000 with loss: 0.103772797611\n",
            " Testing Accuray at 152 iterations is 0.692700000000 with loss: 0.102112320782\n",
            " Testing Accuray at 153 iterations is 0.695000000000 with loss: 0.101064054401\n",
            " Testing Accuray at 154 iterations is 0.695700000000 with loss: 0.101063140640\n",
            " Testing Accuray at 155 iterations is 0.691300000000 with loss: 0.102202304703\n",
            " Testing Accuray at 156 iterations is 0.688200000000 with loss: 0.104091860333\n",
            " Testing Accuray at 157 iterations is 0.684500000000 with loss: 0.105920382020\n",
            " Testing Accuray at 158 iterations is 0.681000000000 with loss: 0.106759115270\n",
            " Testing Accuray at 159 iterations is 0.681100000000 with loss: 0.106026731556\n",
            " Testing Accuray at 160 iterations is 0.685300000000 with loss: 0.103825511364\n",
            " Testing Accuray at 161 iterations is 0.693000000000 with loss: 0.100886076017\n",
            " Testing Accuray at 162 iterations is 0.698400000000 with loss: 0.098189282817\n",
            " Testing Accuray at 163 iterations is 0.704000000000 with loss: 0.096559698759\n",
            " Testing Accuray at 164 iterations is 0.703500000000 with loss: 0.096405611192\n",
            " Testing Accuray at 165 iterations is 0.698000000000 with loss: 0.097605977953\n",
            " Testing Accuray at 166 iterations is 0.691900000000 with loss: 0.099558949439\n",
            " Testing Accuray at 167 iterations is 0.688100000000 with loss: 0.101421102233\n",
            " Testing Accuray at 168 iterations is 0.686600000000 with loss: 0.102452746355\n",
            " Testing Accuray at 169 iterations is 0.686300000000 with loss: 0.102295937656\n",
            " Testing Accuray at 170 iterations is 0.688700000000 with loss: 0.101055325760\n",
            " Testing Accuray at 171 iterations is 0.692000000000 with loss: 0.099171879060\n",
            " Testing Accuray at 172 iterations is 0.695400000000 with loss: 0.097191134999\n",
            " Testing Accuray at 173 iterations is 0.699200000000 with loss: 0.095571398561\n",
            " Testing Accuray at 174 iterations is 0.699800000000 with loss: 0.094611954277\n",
            " Testing Accuray at 175 iterations is 0.699300000000 with loss: 0.094452973415\n",
            " Testing Accuray at 176 iterations is 0.700100000000 with loss: 0.095047142430\n",
            " Testing Accuray at 177 iterations is 0.693600000000 with loss: 0.096102332774\n",
            " Testing Accuray at 178 iterations is 0.692800000000 with loss: 0.097120507523\n",
            " Testing Accuray at 179 iterations is 0.693700000000 with loss: 0.097610994677\n",
            " Testing Accuray at 180 iterations is 0.694400000000 with loss: 0.097359569362\n",
            " Testing Accuray at 181 iterations is 0.696600000000 with loss: 0.096535994179\n",
            " Testing Accuray at 182 iterations is 0.700400000000 with loss: 0.095551247260\n",
            " Testing Accuray at 183 iterations is 0.703200000000 with loss: 0.094787650906\n",
            " Testing Accuray at 184 iterations is 0.704800000000 with loss: 0.094404567989\n",
            " Testing Accuray at 185 iterations is 0.705600000000 with loss: 0.094320649921\n",
            " Testing Accuray at 186 iterations is 0.704900000000 with loss: 0.094327856571\n",
            " Testing Accuray at 187 iterations is 0.702400000000 with loss: 0.094237683093\n",
            " Testing Accuray at 188 iterations is 0.706300000000 with loss: 0.093985095577\n",
            " Testing Accuray at 189 iterations is 0.708400000000 with loss: 0.093651332232\n",
            " Testing Accuray at 190 iterations is 0.707400000000 with loss: 0.093399501951\n",
            " Testing Accuray at 191 iterations is 0.707300000000 with loss: 0.093357363066\n",
            " Testing Accuray at 192 iterations is 0.705800000000 with loss: 0.093518380870\n",
            " Testing Accuray at 193 iterations is 0.702400000000 with loss: 0.093732376351\n",
            " Testing Accuray at 194 iterations is 0.703300000000 with loss: 0.093799318749\n",
            " Testing Accuray at 195 iterations is 0.702400000000 with loss: 0.093598700454\n",
            " Testing Accuray at 196 iterations is 0.703000000000 with loss: 0.093155684964\n",
            " Testing Accuray at 197 iterations is 0.703600000000 with loss: 0.092597864672\n",
            " Testing Accuray at 198 iterations is 0.705100000000 with loss: 0.092047517750\n",
            " Testing Accuray at 199 iterations is 0.705700000000 with loss: 0.091543910758\n",
            " Testing Accuray at 200 iterations is 0.705500000000 with loss: 0.091057233542\n",
            " Testing Accuray at 201 iterations is 0.707700000000 with loss: 0.090571841528\n",
            " Testing Accuray at 202 iterations is 0.710100000000 with loss: 0.090156303198\n",
            " Testing Accuray at 203 iterations is 0.709500000000 with loss: 0.089951126707\n",
            " Testing Accuray at 204 iterations is 0.708100000000 with loss: 0.090077129367\n",
            " Testing Accuray at 205 iterations is 0.706800000000 with loss: 0.090533024844\n",
            " Testing Accuray at 206 iterations is 0.706100000000 with loss: 0.091155793567\n",
            " Testing Accuray at 207 iterations is 0.703700000000 with loss: 0.091670663418\n",
            " Testing Accuray at 208 iterations is 0.703600000000 with loss: 0.091807085634\n",
            " Testing Accuray at 209 iterations is 0.705000000000 with loss: 0.091427714266\n",
            " Testing Accuray at 210 iterations is 0.705500000000 with loss: 0.090606423080\n",
            " Testing Accuray at 211 iterations is 0.708800000000 with loss: 0.089605131821\n",
            " Testing Accuray at 212 iterations is 0.711400000000 with loss: 0.088749904722\n",
            " Testing Accuray at 213 iterations is 0.714900000000 with loss: 0.088273845014\n",
            " Testing Accuray at 214 iterations is 0.715700000000 with loss: 0.088222623686\n",
            " Testing Accuray at 215 iterations is 0.713800000000 with loss: 0.088473953106\n",
            " Testing Accuray at 216 iterations is 0.712000000000 with loss: 0.088838252311\n",
            " Testing Accuray at 217 iterations is 0.712500000000 with loss: 0.089158351871\n",
            " Testing Accuray at 218 iterations is 0.710800000000 with loss: 0.089348234778\n",
            " Testing Accuray at 219 iterations is 0.708800000000 with loss: 0.089371561327\n",
            " Testing Accuray at 220 iterations is 0.711100000000 with loss: 0.089203805439\n",
            " Testing Accuray at 221 iterations is 0.713500000000 with loss: 0.088820890493\n",
            " Testing Accuray at 222 iterations is 0.714900000000 with loss: 0.088224606103\n",
            " Testing Accuray at 223 iterations is 0.713500000000 with loss: 0.087480926256\n",
            " Testing Accuray at 224 iterations is 0.716600000000 with loss: 0.086734797749\n",
            " Testing Accuray at 225 iterations is 0.717100000000 with loss: 0.086178333839\n",
            " Testing Accuray at 226 iterations is 0.714800000000 with loss: 0.085978194139\n",
            " Testing Accuray at 227 iterations is 0.713700000000 with loss: 0.086196054577\n",
            " Testing Accuray at 228 iterations is 0.712100000000 with loss: 0.086747186032\n",
            " Testing Accuray at 229 iterations is 0.709200000000 with loss: 0.087425952603\n",
            " Testing Accuray at 230 iterations is 0.706000000000 with loss: 0.087989247740\n",
            " Testing Accuray at 231 iterations is 0.706900000000 with loss: 0.088254091446\n",
            " Testing Accuray at 232 iterations is 0.709000000000 with loss: 0.088159412177\n",
            " Testing Accuray at 233 iterations is 0.709800000000 with loss: 0.087767506680\n",
            " Testing Accuray at 234 iterations is 0.712400000000 with loss: 0.087216795000\n",
            " Testing Accuray at 235 iterations is 0.715600000000 with loss: 0.086659025122\n",
            " Testing Accuray at 236 iterations is 0.719100000000 with loss: 0.086211120446\n",
            " Testing Accuray at 237 iterations is 0.718800000000 with loss: 0.085933800677\n",
            " Testing Accuray at 238 iterations is 0.718900000000 with loss: 0.085832586148\n",
            " Testing Accuray at 239 iterations is 0.719400000000 with loss: 0.085870670963\n",
            " Testing Accuray at 240 iterations is 0.718600000000 with loss: 0.085985209871\n",
            " Testing Accuray at 241 iterations is 0.719200000000 with loss: 0.086103089439\n",
            " Testing Accuray at 242 iterations is 0.717800000000 with loss: 0.086155501077\n",
            " Testing Accuray at 243 iterations is 0.718900000000 with loss: 0.086091575479\n",
            " Testing Accuray at 244 iterations is 0.720600000000 with loss: 0.085890667817\n",
            " Testing Accuray at 245 iterations is 0.720200000000 with loss: 0.085571146237\n",
            " Testing Accuray at 246 iterations is 0.722300000000 with loss: 0.085191316410\n",
            " Testing Accuray at 247 iterations is 0.719900000000 with loss: 0.084837440565\n",
            " Testing Accuray at 248 iterations is 0.719300000000 with loss: 0.084597215270\n",
            " Testing Accuray at 249 iterations is 0.718500000000 with loss: 0.084524798979\n",
            " Testing Accuray at 250 iterations is 0.716100000000 with loss: 0.084612008567\n",
            " Testing Accuray at 251 iterations is 0.716500000000 with loss: 0.084783392550\n",
            " Testing Accuray at 252 iterations is 0.714700000000 with loss: 0.084924662746\n",
            " Testing Accuray at 253 iterations is 0.713300000000 with loss: 0.084935162116\n",
            " Testing Accuray at 254 iterations is 0.713000000000 with loss: 0.084777371182\n",
            " Testing Accuray at 255 iterations is 0.714000000000 with loss: 0.084495029292\n",
            " Testing Accuray at 256 iterations is 0.716200000000 with loss: 0.084189846486\n",
            " Testing Accuray at 257 iterations is 0.717500000000 with loss: 0.083971976015\n",
            " Testing Accuray at 258 iterations is 0.719700000000 with loss: 0.083912958390\n",
            " Testing Accuray at 259 iterations is 0.718600000000 with loss: 0.084023454498\n",
            " Testing Accuray at 260 iterations is 0.718800000000 with loss: 0.084259424304\n",
            " Testing Accuray at 261 iterations is 0.719000000000 with loss: 0.084544844240\n",
            " Testing Accuray at 262 iterations is 0.718500000000 with loss: 0.084795861325\n",
            " Testing Accuray at 263 iterations is 0.717800000000 with loss: 0.084938043605\n",
            " Testing Accuray at 264 iterations is 0.718800000000 with loss: 0.084916805650\n",
            " Testing Accuray at 265 iterations is 0.718100000000 with loss: 0.084705037991\n",
            " Testing Accuray at 266 iterations is 0.719900000000 with loss: 0.084310473208\n",
            " Testing Accuray at 267 iterations is 0.722500000000 with loss: 0.083781098146\n",
            " Testing Accuray at 268 iterations is 0.726500000000 with loss: 0.083203659686\n",
            " Testing Accuray at 269 iterations is 0.727200000000 with loss: 0.082690509247\n",
            " Testing Accuray at 270 iterations is 0.727600000000 with loss: 0.082354031045\n",
            " Testing Accuray at 271 iterations is 0.727500000000 with loss: 0.082273936734\n",
            " Testing Accuray at 272 iterations is 0.726600000000 with loss: 0.082467752542\n",
            " Testing Accuray at 273 iterations is 0.723800000000 with loss: 0.082876132485\n",
            " Testing Accuray at 274 iterations is 0.721900000000 with loss: 0.083371245456\n",
            " Testing Accuray at 275 iterations is 0.719100000000 with loss: 0.083789331393\n",
            " Testing Accuray at 276 iterations is 0.716900000000 with loss: 0.083979512033\n",
            " Testing Accuray at 277 iterations is 0.717400000000 with loss: 0.083852967693\n",
            " Testing Accuray at 278 iterations is 0.719400000000 with loss: 0.083413794979\n",
            " Testing Accuray at 279 iterations is 0.721000000000 with loss: 0.082758489454\n",
            " Testing Accuray at 280 iterations is 0.725600000000 with loss: 0.082043818669\n",
            " Testing Accuray at 281 iterations is 0.727400000000 with loss: 0.081436456322\n",
            " Testing Accuray at 282 iterations is 0.729100000000 with loss: 0.081064444588\n",
            " Testing Accuray at 283 iterations is 0.729300000000 with loss: 0.080986954491\n",
            " Testing Accuray at 284 iterations is 0.728800000000 with loss: 0.081188373488\n",
            " Testing Accuray at 285 iterations is 0.724100000000 with loss: 0.081592592816\n",
            " Testing Accuray at 286 iterations is 0.723800000000 with loss: 0.082088423403\n",
            " Testing Accuray at 287 iterations is 0.722300000000 with loss: 0.082557378235\n",
            " Testing Accuray at 288 iterations is 0.720700000000 with loss: 0.082897830032\n",
            " Testing Accuray at 289 iterations is 0.719600000000 with loss: 0.083042313203\n",
            " Testing Accuray at 290 iterations is 0.721000000000 with loss: 0.082966565245\n",
            " Testing Accuray at 291 iterations is 0.721300000000 with loss: 0.082689989939\n",
            " Testing Accuray at 292 iterations is 0.722900000000 with loss: 0.082268119004\n",
            " Testing Accuray at 293 iterations is 0.725300000000 with loss: 0.081778736798\n",
            " Testing Accuray at 294 iterations is 0.726800000000 with loss: 0.081304575577\n",
            " Testing Accuray at 295 iterations is 0.727000000000 with loss: 0.080916386602\n",
            " Testing Accuray at 296 iterations is 0.729800000000 with loss: 0.080660084688\n",
            " Testing Accuray at 297 iterations is 0.729200000000 with loss: 0.080550331651\n",
            " Testing Accuray at 298 iterations is 0.729800000000 with loss: 0.080570999685\n",
            " Testing Accuray at 299 iterations is 0.728600000000 with loss: 0.080681509429\n",
            " Testing Accuray at 300 iterations is 0.728200000000 with loss: 0.080827519641\n",
            " Testing Accuray at 301 iterations is 0.726300000000 with loss: 0.080954203234\n",
            " Testing Accuray at 302 iterations is 0.725000000000 with loss: 0.081019529370\n",
            " Testing Accuray at 303 iterations is 0.724700000000 with loss: 0.081003875406\n",
            " Testing Accuray at 304 iterations is 0.726500000000 with loss: 0.080912378140\n",
            " Testing Accuray at 305 iterations is 0.727400000000 with loss: 0.080768782026\n",
            " Testing Accuray at 306 iterations is 0.728100000000 with loss: 0.080603372310\n",
            " Testing Accuray at 307 iterations is 0.728900000000 with loss: 0.080440523399\n",
            " Testing Accuray at 308 iterations is 0.730500000000 with loss: 0.080291392302\n",
            " Testing Accuray at 309 iterations is 0.732500000000 with loss: 0.080154324065\n",
            " Testing Accuray at 310 iterations is 0.734000000000 with loss: 0.080021550593\n",
            " Testing Accuray at 311 iterations is 0.734300000000 with loss: 0.079888040118\n",
            " Testing Accuray at 312 iterations is 0.733700000000 with loss: 0.079758006760\n",
            " Testing Accuray at 313 iterations is 0.734200000000 with loss: 0.079646261508\n",
            " Testing Accuray at 314 iterations is 0.731400000000 with loss: 0.079574108718\n",
            " Testing Accuray at 315 iterations is 0.730800000000 with loss: 0.079561685675\n",
            " Testing Accuray at 316 iterations is 0.731900000000 with loss: 0.079619771761\n",
            " Testing Accuray at 317 iterations is 0.731800000000 with loss: 0.079743981591\n",
            " Testing Accuray at 318 iterations is 0.730100000000 with loss: 0.079913197356\n",
            " Testing Accuray at 319 iterations is 0.728600000000 with loss: 0.080092636818\n",
            " Testing Accuray at 320 iterations is 0.729300000000 with loss: 0.080240616466\n",
            " Testing Accuray at 321 iterations is 0.729800000000 with loss: 0.080317161920\n",
            " Testing Accuray at 322 iterations is 0.727800000000 with loss: 0.080292256674\n",
            " Testing Accuray at 323 iterations is 0.727100000000 with loss: 0.080151754629\n",
            " Testing Accuray at 324 iterations is 0.728300000000 with loss: 0.079899788930\n",
            " Testing Accuray at 325 iterations is 0.728900000000 with loss: 0.079557650313\n",
            " Testing Accuray at 326 iterations is 0.731800000000 with loss: 0.079160091481\n",
            " Testing Accuray at 327 iterations is 0.732300000000 with loss: 0.078750351989\n",
            " Testing Accuray at 328 iterations is 0.733500000000 with loss: 0.078374795848\n",
            " Testing Accuray at 329 iterations is 0.735200000000 with loss: 0.078077347060\n",
            " Testing Accuray at 330 iterations is 0.736400000000 with loss: 0.077893546151\n",
            " Testing Accuray at 331 iterations is 0.736900000000 with loss: 0.077844377311\n",
            " Testing Accuray at 332 iterations is 0.737000000000 with loss: 0.077930814941\n",
            " Testing Accuray at 333 iterations is 0.736100000000 with loss: 0.078130740749\n",
            " Testing Accuray at 334 iterations is 0.735400000000 with loss: 0.078399979630\n",
            " Testing Accuray at 335 iterations is 0.735600000000 with loss: 0.078678497075\n",
            " Testing Accuray at 336 iterations is 0.735100000000 with loss: 0.078901412881\n",
            " Testing Accuray at 337 iterations is 0.734500000000 with loss: 0.079012800525\n",
            " Testing Accuray at 338 iterations is 0.734900000000 with loss: 0.078978865609\n",
            " Testing Accuray at 339 iterations is 0.735600000000 with loss: 0.078796687524\n",
            " Testing Accuray at 340 iterations is 0.738100000000 with loss: 0.078495645353\n",
            " Testing Accuray at 341 iterations is 0.738900000000 with loss: 0.078130758072\n",
            " Testing Accuray at 342 iterations is 0.738900000000 with loss: 0.077769713085\n",
            " Testing Accuray at 343 iterations is 0.738400000000 with loss: 0.077477330404\n",
            " Testing Accuray at 344 iterations is 0.739300000000 with loss: 0.077301807585\n",
            " Testing Accuray at 345 iterations is 0.739500000000 with loss: 0.077266122024\n",
            " Testing Accuray at 346 iterations is 0.737500000000 with loss: 0.077365960254\n",
            " Testing Accuray at 347 iterations is 0.738000000000 with loss: 0.077573442872\n",
            " Testing Accuray at 348 iterations is 0.736400000000 with loss: 0.077844552927\n",
            " Testing Accuray at 349 iterations is 0.734500000000 with loss: 0.078127880172\n",
            " Testing Accuray at 350 iterations is 0.734000000000 with loss: 0.078372836332\n",
            " Testing Accuray at 351 iterations is 0.733800000000 with loss: 0.078536360351\n",
            " Testing Accuray at 352 iterations is 0.732100000000 with loss: 0.078587846371\n",
            " Testing Accuray at 353 iterations is 0.731600000000 with loss: 0.078512366537\n",
            " Testing Accuray at 354 iterations is 0.733300000000 with loss: 0.078312256895\n",
            " Testing Accuray at 355 iterations is 0.735300000000 with loss: 0.078006966577\n",
            " Testing Accuray at 356 iterations is 0.736700000000 with loss: 0.077630944266\n",
            " Testing Accuray at 357 iterations is 0.739200000000 with loss: 0.077229402519\n",
            " Testing Accuray at 358 iterations is 0.740100000000 with loss: 0.076852114203\n",
            " Testing Accuray at 359 iterations is 0.740600000000 with loss: 0.076545896198\n",
            " Testing Accuray at 360 iterations is 0.743200000000 with loss: 0.076346956190\n",
            " Testing Accuray at 361 iterations is 0.744700000000 with loss: 0.076274592990\n",
            " Testing Accuray at 362 iterations is 0.741700000000 with loss: 0.076327661733\n",
            " Testing Accuray at 363 iterations is 0.741900000000 with loss: 0.076484700162\n",
            " Testing Accuray at 364 iterations is 0.741200000000 with loss: 0.076707806617\n",
            " Testing Accuray at 365 iterations is 0.740100000000 with loss: 0.076949528318\n",
            " Testing Accuray at 366 iterations is 0.738600000000 with loss: 0.077161401212\n",
            " Testing Accuray at 367 iterations is 0.737600000000 with loss: 0.077302496234\n",
            " Testing Accuray at 368 iterations is 0.737500000000 with loss: 0.077346368290\n",
            " Testing Accuray at 369 iterations is 0.737600000000 with loss: 0.077285127062\n",
            " Testing Accuray at 370 iterations is 0.738700000000 with loss: 0.077129909989\n",
            " Testing Accuray at 371 iterations is 0.738500000000 with loss: 0.076907770967\n",
            " Testing Accuray at 372 iterations is 0.738900000000 with loss: 0.076655759838\n",
            " Testing Accuray at 373 iterations is 0.740300000000 with loss: 0.076413545805\n",
            " Testing Accuray at 374 iterations is 0.739800000000 with loss: 0.076216149688\n",
            " Testing Accuray at 375 iterations is 0.740500000000 with loss: 0.076088154253\n",
            " Testing Accuray at 376 iterations is 0.740200000000 with loss: 0.076040284765\n",
            " Testing Accuray at 377 iterations is 0.739900000000 with loss: 0.076068697772\n",
            " Testing Accuray at 378 iterations is 0.741000000000 with loss: 0.076156839219\n",
            " Testing Accuray at 379 iterations is 0.740700000000 with loss: 0.076279374809\n",
            " Testing Accuray at 380 iterations is 0.741000000000 with loss: 0.076407422273\n",
            " Testing Accuray at 381 iterations is 0.741700000000 with loss: 0.076514107038\n",
            " Testing Accuray at 382 iterations is 0.740900000000 with loss: 0.076579367132\n",
            " Testing Accuray at 383 iterations is 0.740900000000 with loss: 0.076593040854\n",
            " Testing Accuray at 384 iterations is 0.742100000000 with loss: 0.076555635638\n",
            " Testing Accuray at 385 iterations is 0.741600000000 with loss: 0.076476746187\n",
            " Testing Accuray at 386 iterations is 0.741300000000 with loss: 0.076371699419\n",
            " Testing Accuray at 387 iterations is 0.741700000000 with loss: 0.076257442095\n",
            " Testing Accuray at 388 iterations is 0.740700000000 with loss: 0.076148797012\n",
            " Testing Accuray at 389 iterations is 0.742500000000 with loss: 0.076055967422\n",
            " Testing Accuray at 390 iterations is 0.742700000000 with loss: 0.075983679460\n",
            " Testing Accuray at 391 iterations is 0.742100000000 with loss: 0.075931815045\n",
            " Testing Accuray at 392 iterations is 0.741300000000 with loss: 0.075896993186\n",
            " Testing Accuray at 393 iterations is 0.741500000000 with loss: 0.075874413874\n",
            " Testing Accuray at 394 iterations is 0.741500000000 with loss: 0.075859383664\n",
            " Testing Accuray at 395 iterations is 0.742600000000 with loss: 0.075848205258\n",
            " Testing Accuray at 396 iterations is 0.743400000000 with loss: 0.075838407819\n",
            " Testing Accuray at 397 iterations is 0.742600000000 with loss: 0.075828510216\n",
            " Testing Accuray at 398 iterations is 0.741500000000 with loss: 0.075817590621\n",
            " Testing Accuray at 399 iterations is 0.741200000000 with loss: 0.075804892489\n",
            " Testing Accuray at 400 iterations is 0.741100000000 with loss: 0.075789585982\n",
            " Testing Accuray at 401 iterations is 0.740500000000 with loss: 0.075770694609\n",
            " Testing Accuray at 402 iterations is 0.739400000000 with loss: 0.075747136781\n",
            " Testing Accuray at 403 iterations is 0.739500000000 with loss: 0.075717830287\n",
            " Testing Accuray at 404 iterations is 0.741300000000 with loss: 0.075681840688\n",
            " Testing Accuray at 405 iterations is 0.740900000000 with loss: 0.075638585521\n",
            " Testing Accuray at 406 iterations is 0.741600000000 with loss: 0.075588106390\n",
            " Testing Accuray at 407 iterations is 0.741700000000 with loss: 0.075531383113\n",
            " Testing Accuray at 408 iterations is 0.742000000000 with loss: 0.075470603604\n",
            " Testing Accuray at 409 iterations is 0.743100000000 with loss: 0.075409252644\n",
            " Testing Accuray at 410 iterations is 0.744400000000 with loss: 0.075351878478\n",
            " Testing Accuray at 411 iterations is 0.745900000000 with loss: 0.075303461714\n",
            " Testing Accuray at 412 iterations is 0.745600000000 with loss: 0.075268439855\n",
            " Testing Accuray at 413 iterations is 0.745400000000 with loss: 0.075249591443\n",
            " Testing Accuray at 414 iterations is 0.745000000000 with loss: 0.075247091589\n",
            " Testing Accuray at 415 iterations is 0.745800000000 with loss: 0.075258057720\n",
            " Testing Accuray at 416 iterations is 0.745600000000 with loss: 0.075276791080\n",
            " Testing Accuray at 417 iterations is 0.745600000000 with loss: 0.075295720460\n",
            " Testing Accuray at 418 iterations is 0.746100000000 with loss: 0.075306845155\n",
            " Testing Accuray at 419 iterations is 0.745700000000 with loss: 0.075303333631\n",
            " Testing Accuray at 420 iterations is 0.745800000000 with loss: 0.075280907345\n",
            " Testing Accuray at 421 iterations is 0.745000000000 with loss: 0.075238718216\n",
            " Testing Accuray at 422 iterations is 0.745600000000 with loss: 0.075179567403\n",
            " Testing Accuray at 423 iterations is 0.745200000000 with loss: 0.075109457402\n",
            " Testing Accuray at 424 iterations is 0.743700000000 with loss: 0.075036582647\n",
            " Testing Accuray at 425 iterations is 0.742400000000 with loss: 0.074969936111\n",
            " Testing Accuray at 426 iterations is 0.743500000000 with loss: 0.074917749043\n",
            " Testing Accuray at 427 iterations is 0.743200000000 with loss: 0.074885998803\n",
            " Testing Accuray at 428 iterations is 0.745200000000 with loss: 0.074877218250\n",
            " Testing Accuray at 429 iterations is 0.743100000000 with loss: 0.074889813877\n",
            " Testing Accuray at 430 iterations is 0.743600000000 with loss: 0.074918042464\n",
            " Testing Accuray at 431 iterations is 0.743300000000 with loss: 0.074952707302\n",
            " Testing Accuray at 432 iterations is 0.742800000000 with loss: 0.074982523582\n",
            " Testing Accuray at 433 iterations is 0.742200000000 with loss: 0.074995983701\n",
            " Testing Accuray at 434 iterations is 0.742800000000 with loss: 0.074983445747\n",
            " Testing Accuray at 435 iterations is 0.743100000000 with loss: 0.074939092809\n",
            " Testing Accuray at 436 iterations is 0.744100000000 with loss: 0.074862386861\n",
            " Testing Accuray at 437 iterations is 0.743600000000 with loss: 0.074758684675\n",
            " Testing Accuray at 438 iterations is 0.744700000000 with loss: 0.074638801061\n",
            " Testing Accuray at 439 iterations is 0.744400000000 with loss: 0.074517487634\n",
            " Testing Accuray at 440 iterations is 0.744900000000 with loss: 0.074411015632\n",
            " Testing Accuray at 441 iterations is 0.744700000000 with loss: 0.074334263841\n",
            " Testing Accuray at 442 iterations is 0.745600000000 with loss: 0.074297863020\n",
            " Testing Accuray at 443 iterations is 0.746400000000 with loss: 0.074305986463\n",
            " Testing Accuray at 444 iterations is 0.747300000000 with loss: 0.074355275548\n",
            " Testing Accuray at 445 iterations is 0.745900000000 with loss: 0.074435160136\n",
            " Testing Accuray at 446 iterations is 0.746100000000 with loss: 0.074529530107\n",
            " Testing Accuray at 447 iterations is 0.746100000000 with loss: 0.074619419137\n",
            " Testing Accuray at 448 iterations is 0.746600000000 with loss: 0.074686158322\n",
            " Testing Accuray at 449 iterations is 0.746400000000 with loss: 0.074714397000\n",
            " Testing Accuray at 450 iterations is 0.747600000000 with loss: 0.074694471577\n",
            " Testing Accuray at 451 iterations is 0.748300000000 with loss: 0.074623785193\n",
            " Testing Accuray at 452 iterations is 0.748700000000 with loss: 0.074507075173\n",
            " Testing Accuray at 453 iterations is 0.747600000000 with loss: 0.074355633369\n",
            " Testing Accuray at 454 iterations is 0.746400000000 with loss: 0.074185676013\n",
            " Testing Accuray at 455 iterations is 0.747600000000 with loss: 0.074016132516\n",
            " Testing Accuray at 456 iterations is 0.748800000000 with loss: 0.073866151896\n",
            " Testing Accuray at 457 iterations is 0.749100000000 with loss: 0.073752627580\n",
            " Testing Accuray at 458 iterations is 0.749100000000 with loss: 0.073688024847\n",
            " Testing Accuray at 459 iterations is 0.747500000000 with loss: 0.073678760437\n",
            " Testing Accuray at 460 iterations is 0.746600000000 with loss: 0.073724327829\n",
            " Testing Accuray at 461 iterations is 0.745600000000 with loss: 0.073817283895\n",
            " Testing Accuray at 462 iterations is 0.747200000000 with loss: 0.073944117290\n",
            " Testing Accuray at 463 iterations is 0.746300000000 with loss: 0.074086913756\n",
            " Testing Accuray at 464 iterations is 0.745500000000 with loss: 0.074225629228\n",
            " Testing Accuray at 465 iterations is 0.745100000000 with loss: 0.074340690680\n",
            " Testing Accuray at 466 iterations is 0.744900000000 with loss: 0.074415581916\n",
            " Testing Accuray at 467 iterations is 0.745100000000 with loss: 0.074439051661\n",
            " Testing Accuray at 468 iterations is 0.744700000000 with loss: 0.074406615737\n",
            " Testing Accuray at 469 iterations is 0.745400000000 with loss: 0.074321116635\n",
            " Testing Accuray at 470 iterations is 0.746600000000 with loss: 0.074192243204\n",
            " Testing Accuray at 471 iterations is 0.747700000000 with loss: 0.074035078549\n",
            " Testing Accuray at 472 iterations is 0.748700000000 with loss: 0.073867904417\n",
            " Testing Accuray at 473 iterations is 0.748900000000 with loss: 0.073709611824\n",
            " Testing Accuray at 474 iterations is 0.748500000000 with loss: 0.073577123929\n",
            " Testing Accuray at 475 iterations is 0.749400000000 with loss: 0.073483216557\n",
            " Testing Accuray at 476 iterations is 0.750400000000 with loss: 0.073435031736\n",
            " Testing Accuray at 477 iterations is 0.750400000000 with loss: 0.073433444448\n",
            " Testing Accuray at 478 iterations is 0.750300000000 with loss: 0.073473295574\n",
            " Testing Accuray at 479 iterations is 0.750500000000 with loss: 0.073544376154\n",
            " Testing Accuray at 480 iterations is 0.750700000000 with loss: 0.073632960495\n",
            " Testing Accuray at 481 iterations is 0.750700000000 with loss: 0.073723645231\n",
            " Testing Accuray at 482 iterations is 0.750500000000 with loss: 0.073801252868\n",
            " Testing Accuray at 483 iterations is 0.749600000000 with loss: 0.073852589279\n",
            " Testing Accuray at 484 iterations is 0.749200000000 with loss: 0.073867890802\n",
            " Testing Accuray at 485 iterations is 0.749300000000 with loss: 0.073841846416\n",
            " Testing Accuray at 486 iterations is 0.749500000000 with loss: 0.073774126389\n",
            " Testing Accuray at 487 iterations is 0.750000000000 with loss: 0.073669388242\n",
            " Testing Accuray at 488 iterations is 0.750100000000 with loss: 0.073536765426\n",
            " Testing Accuray at 489 iterations is 0.750900000000 with loss: 0.073388877967\n",
            " Testing Accuray at 490 iterations is 0.750600000000 with loss: 0.073240442038\n",
            " Testing Accuray at 491 iterations is 0.751200000000 with loss: 0.073106599134\n",
            " Testing Accuray at 492 iterations is 0.751600000000 with loss: 0.073001131787\n",
            " Testing Accuray at 493 iterations is 0.751300000000 with loss: 0.072934772178\n",
            " Testing Accuray at 494 iterations is 0.751300000000 with loss: 0.072913828114\n",
            " Testing Accuray at 495 iterations is 0.750600000000 with loss: 0.072939333689\n",
            " Testing Accuray at 496 iterations is 0.749300000000 with loss: 0.073006872215\n",
            " Testing Accuray at 497 iterations is 0.750000000000 with loss: 0.073107121527\n",
            " Testing Accuray at 498 iterations is 0.748500000000 with loss: 0.073227054631\n",
            " Testing Accuray at 499 iterations is 0.748000000000 with loss: 0.073351618653\n",
            " Testing Accuray at 500 iterations is 0.747900000000 with loss: 0.073465638579\n",
            "SigmoidNAG without QG Testing Accuray at   1 iterations is 0.248300000000 with loss: -35013.940700221028\n",
            "SigmoidNAG without QG Testing Accuray at   2 iterations is 0.248300000000 with loss: -1558877.755134288687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-ee2599eeb39b>:389: RuntimeWarning: divide by zero encountered in log\n",
            "  loss =  np.sum( np.log( np.absolute(pp -1 + Y) )  )\n",
            "<ipython-input-1-ee2599eeb39b>:396: RuntimeWarning: divide by zero encountered in log\n",
            "  loss =  np.sum( np.log( np.absolute(pp -1 + Ytest) )  )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SigmoidNAG without QG Testing Accuray at   3 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   4 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   5 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   6 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   7 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   8 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at   9 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  10 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  11 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  12 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  13 iterations is 0.248300000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  14 iterations is 0.248400000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  15 iterations is 0.278500000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  16 iterations is 0.399000000000 with loss: -555451.064402857446\n",
            "SigmoidNAG without QG Testing Accuray at  17 iterations is 0.359700000000 with loss: -384909.658962793939\n",
            "SigmoidNAG without QG Testing Accuray at  18 iterations is 0.182600000000 with loss: -155931.426665203267\n",
            "SigmoidNAG without QG Testing Accuray at  19 iterations is 0.256500000000 with loss: -137543.788156887545\n",
            "SigmoidNAG without QG Testing Accuray at  20 iterations is 0.463200000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  21 iterations is 0.518600000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  22 iterations is 0.467200000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  23 iterations is 0.405100000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  24 iterations is 0.371000000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  25 iterations is 0.381500000000 with loss: -inf\n",
            "SigmoidNAG without QG Testing Accuray at  26 iterations is 0.436400000000 with loss: -67949.845617839877\n",
            "SigmoidNAG without QG Testing Accuray at  27 iterations is 0.501500000000 with loss: -94380.210988323044\n",
            "SigmoidNAG without QG Testing Accuray at  28 iterations is 0.522900000000 with loss: -137712.226025827898\n",
            "SigmoidNAG without QG Testing Accuray at  29 iterations is 0.533900000000 with loss: -110341.188813944187\n",
            "SigmoidNAG without QG Testing Accuray at  30 iterations is 0.506400000000 with loss: -61772.956630135464\n",
            "SigmoidNAG without QG Testing Accuray at  31 iterations is 0.441300000000 with loss: -64696.160464015134\n",
            "SigmoidNAG without QG Testing Accuray at  32 iterations is 0.413000000000 with loss: -72504.283384712733\n",
            "SigmoidNAG without QG Testing Accuray at  33 iterations is 0.428800000000 with loss: -75639.113089376304\n",
            "SigmoidNAG without QG Testing Accuray at  34 iterations is 0.485100000000 with loss: -75908.638071856185\n",
            "SigmoidNAG without QG Testing Accuray at  35 iterations is 0.546100000000 with loss: -73053.274895243580\n",
            "SigmoidNAG without QG Testing Accuray at  36 iterations is 0.561300000000 with loss: -66066.184200892807\n",
            "SigmoidNAG without QG Testing Accuray at  37 iterations is 0.548700000000 with loss: -55949.732640202164\n",
            "SigmoidNAG without QG Testing Accuray at  38 iterations is 0.525400000000 with loss: -47141.939474517334\n",
            "SigmoidNAG without QG Testing Accuray at  39 iterations is 0.504300000000 with loss: -47061.170637116957\n",
            "SigmoidNAG without QG Testing Accuray at  40 iterations is 0.505300000000 with loss: -57947.652564855940\n",
            "SigmoidNAG without QG Testing Accuray at  41 iterations is 0.527600000000 with loss: -64526.110243062147\n",
            "SigmoidNAG without QG Testing Accuray at  42 iterations is 0.567100000000 with loss: -55040.351056916537\n",
            "SigmoidNAG without QG Testing Accuray at  43 iterations is 0.564000000000 with loss: -45589.156547308521\n",
            "SigmoidNAG without QG Testing Accuray at  44 iterations is 0.531700000000 with loss: -44220.735807813107\n",
            "SigmoidNAG without QG Testing Accuray at  45 iterations is 0.509500000000 with loss: -45292.363219962965\n",
            "SigmoidNAG without QG Testing Accuray at  46 iterations is 0.507100000000 with loss: -45400.201127668493\n",
            "SigmoidNAG without QG Testing Accuray at  47 iterations is 0.510500000000 with loss: -45080.701950596376\n",
            "SigmoidNAG without QG Testing Accuray at  48 iterations is 0.513100000000 with loss: -45120.853404174959\n",
            "SigmoidNAG without QG Testing Accuray at  49 iterations is 0.526800000000 with loss: -44361.619206908152\n",
            "SigmoidNAG without QG Testing Accuray at  50 iterations is 0.554600000000 with loss: -41826.506497556278\n",
            "SigmoidNAG without QG Testing Accuray at  51 iterations is 0.572400000000 with loss: -38501.607614687578\n",
            "SigmoidNAG without QG Testing Accuray at  52 iterations is 0.558200000000 with loss: -36521.347767100604\n",
            "SigmoidNAG without QG Testing Accuray at  53 iterations is 0.535400000000 with loss: -37300.098180131419\n",
            "SigmoidNAG without QG Testing Accuray at  54 iterations is 0.521300000000 with loss: -39195.309285847921\n",
            "SigmoidNAG without QG Testing Accuray at  55 iterations is 0.535100000000 with loss: -38308.905685545076\n",
            "SigmoidNAG without QG Testing Accuray at  56 iterations is 0.568000000000 with loss: -34642.007982530879\n",
            "SigmoidNAG without QG Testing Accuray at  57 iterations is 0.586400000000 with loss: -32200.043731909427\n",
            "SigmoidNAG without QG Testing Accuray at  58 iterations is 0.580800000000 with loss: -32302.540571231984\n",
            "SigmoidNAG without QG Testing Accuray at  59 iterations is 0.567500000000 with loss: -33555.313443972722\n",
            "SigmoidNAG without QG Testing Accuray at  60 iterations is 0.552100000000 with loss: -34200.710297138270\n",
            "SigmoidNAG without QG Testing Accuray at  61 iterations is 0.550300000000 with loss: -33146.807411756854\n",
            "SigmoidNAG without QG Testing Accuray at  62 iterations is 0.566000000000 with loss: -31098.374891901916\n",
            "SigmoidNAG without QG Testing Accuray at  63 iterations is 0.581600000000 with loss: -29578.121371839832\n",
            "SigmoidNAG without QG Testing Accuray at  64 iterations is 0.583700000000 with loss: -29039.996523767328\n",
            "SigmoidNAG without QG Testing Accuray at  65 iterations is 0.579900000000 with loss: -29055.738477525374\n",
            "SigmoidNAG without QG Testing Accuray at  66 iterations is 0.578600000000 with loss: -29305.674736803321\n",
            "SigmoidNAG without QG Testing Accuray at  67 iterations is 0.580200000000 with loss: -29716.425991191350\n",
            "SigmoidNAG without QG Testing Accuray at  68 iterations is 0.575300000000 with loss: -29907.130339328622\n",
            "SigmoidNAG without QG Testing Accuray at  69 iterations is 0.579700000000 with loss: -29026.890903889700\n",
            "SigmoidNAG without QG Testing Accuray at  70 iterations is 0.589900000000 with loss: -26912.522665735880\n",
            "SigmoidNAG without QG Testing Accuray at  71 iterations is 0.607300000000 with loss: -24911.982773292257\n",
            "SigmoidNAG without QG Testing Accuray at  72 iterations is 0.610800000000 with loss: -24425.058742991911\n",
            "SigmoidNAG without QG Testing Accuray at  73 iterations is 0.600500000000 with loss: -25467.903605605847\n",
            "SigmoidNAG without QG Testing Accuray at  74 iterations is 0.587300000000 with loss: -26950.427616845180\n",
            "SigmoidNAG without QG Testing Accuray at  75 iterations is 0.577400000000 with loss: -27471.666656221980\n",
            "SigmoidNAG without QG Testing Accuray at  76 iterations is 0.583100000000 with loss: -26628.711615704909\n",
            "SigmoidNAG without QG Testing Accuray at  77 iterations is 0.597200000000 with loss: -25335.029154056167\n",
            "SigmoidNAG without QG Testing Accuray at  78 iterations is 0.613900000000 with loss: -24271.097880889211\n",
            "SigmoidNAG without QG Testing Accuray at  79 iterations is 0.629500000000 with loss: -23424.750179089562\n",
            "SigmoidNAG without QG Testing Accuray at  80 iterations is 0.629300000000 with loss: -22895.989012200000\n",
            "SigmoidNAG without QG Testing Accuray at  81 iterations is 0.617100000000 with loss: -22999.813225025195\n",
            "SigmoidNAG without QG Testing Accuray at  82 iterations is 0.604800000000 with loss: -23758.971538566704\n",
            "SigmoidNAG without QG Testing Accuray at  83 iterations is 0.596700000000 with loss: -24605.606351018560\n",
            "SigmoidNAG without QG Testing Accuray at  84 iterations is 0.601000000000 with loss: -24763.929744981433\n",
            "SigmoidNAG without QG Testing Accuray at  85 iterations is 0.612200000000 with loss: -24004.315197430482\n",
            "SigmoidNAG without QG Testing Accuray at  86 iterations is 0.626400000000 with loss: -22906.073957032884\n",
            "SigmoidNAG without QG Testing Accuray at  87 iterations is 0.634600000000 with loss: -22275.530230477172\n",
            "SigmoidNAG without QG Testing Accuray at  88 iterations is 0.629200000000 with loss: -22237.095473891237\n",
            "SigmoidNAG without QG Testing Accuray at  89 iterations is 0.621700000000 with loss: -22197.784121413708\n",
            "SigmoidNAG without QG Testing Accuray at  90 iterations is 0.625000000000 with loss: -21888.099959366526\n",
            "SigmoidNAG without QG Testing Accuray at  91 iterations is 0.624600000000 with loss: -21654.916424090483\n",
            "SigmoidNAG without QG Testing Accuray at  92 iterations is 0.626800000000 with loss: -21691.992268049744\n",
            "SigmoidNAG without QG Testing Accuray at  93 iterations is 0.624400000000 with loss: -21863.482993833968\n",
            "SigmoidNAG without QG Testing Accuray at  94 iterations is 0.626500000000 with loss: -22007.862766545564\n",
            "SigmoidNAG without QG Testing Accuray at  95 iterations is 0.625900000000 with loss: -21976.404695358313\n",
            "SigmoidNAG without QG Testing Accuray at  96 iterations is 0.622300000000 with loss: -21695.311026214189\n",
            "SigmoidNAG without QG Testing Accuray at  97 iterations is 0.621500000000 with loss: -21226.106046552464\n",
            "SigmoidNAG without QG Testing Accuray at  98 iterations is 0.628900000000 with loss: -20663.371181219965\n",
            "SigmoidNAG without QG Testing Accuray at  99 iterations is 0.640700000000 with loss: -20132.707090994852\n",
            "SigmoidNAG without QG Testing Accuray at 100 iterations is 0.650600000000 with loss: -19879.508446419295\n",
            "SigmoidNAG without QG Testing Accuray at 101 iterations is 0.651700000000 with loss: -20091.351470345082\n",
            "SigmoidNAG without QG Testing Accuray at 102 iterations is 0.643500000000 with loss: -20603.741580836959\n",
            "SigmoidNAG without QG Testing Accuray at 103 iterations is 0.636500000000 with loss: -20968.239027683619\n",
            "SigmoidNAG without QG Testing Accuray at 104 iterations is 0.637200000000 with loss: -20880.913116326090\n",
            "SigmoidNAG without QG Testing Accuray at 105 iterations is 0.641100000000 with loss: -20465.413757193375\n",
            "SigmoidNAG without QG Testing Accuray at 106 iterations is 0.644100000000 with loss: -20036.355981955152\n",
            "SigmoidNAG without QG Testing Accuray at 107 iterations is 0.648600000000 with loss: -19697.849840133164\n",
            "SigmoidNAG without QG Testing Accuray at 108 iterations is 0.648700000000 with loss: -19360.666347701528\n",
            "SigmoidNAG without QG Testing Accuray at 109 iterations is 0.653900000000 with loss: -19036.748524356615\n",
            "SigmoidNAG without QG Testing Accuray at 110 iterations is 0.660100000000 with loss: -18889.970355102821\n",
            "SigmoidNAG without QG Testing Accuray at 111 iterations is 0.660200000000 with loss: -19012.596175536084\n",
            "SigmoidNAG without QG Testing Accuray at 112 iterations is 0.656400000000 with loss: -19277.069123205438\n",
            "SigmoidNAG without QG Testing Accuray at 113 iterations is 0.650700000000 with loss: -19411.995801288031\n",
            "SigmoidNAG without QG Testing Accuray at 114 iterations is 0.651900000000 with loss: -19230.083520325745\n",
            "SigmoidNAG without QG Testing Accuray at 115 iterations is 0.660100000000 with loss: -18831.850486636889\n",
            "SigmoidNAG without QG Testing Accuray at 116 iterations is 0.664700000000 with loss: -18532.587226273743\n",
            "SigmoidNAG without QG Testing Accuray at 117 iterations is 0.663000000000 with loss: -18524.122210663350\n",
            "SigmoidNAG without QG Testing Accuray at 118 iterations is 0.658700000000 with loss: -18671.072952686853\n",
            "SigmoidNAG without QG Testing Accuray at 119 iterations is 0.658700000000 with loss: -18702.415667916888\n",
            "SigmoidNAG without QG Testing Accuray at 120 iterations is 0.666900000000 with loss: -18533.482459448358\n",
            "SigmoidNAG without QG Testing Accuray at 121 iterations is 0.672300000000 with loss: -18315.005321640907\n",
            "SigmoidNAG without QG Testing Accuray at 122 iterations is 0.673100000000 with loss: -18209.910005489543\n",
            "SigmoidNAG without QG Testing Accuray at 123 iterations is 0.669000000000 with loss: -18214.924028465593\n",
            "SigmoidNAG without QG Testing Accuray at 124 iterations is 0.665200000000 with loss: -18208.124352839870\n",
            "SigmoidNAG without QG Testing Accuray at 125 iterations is 0.664200000000 with loss: -18116.983605328769\n",
            "SigmoidNAG without QG Testing Accuray at 126 iterations is 0.665100000000 with loss: -17995.206908838969\n",
            "SigmoidNAG without QG Testing Accuray at 127 iterations is 0.666300000000 with loss: -17937.531313214906\n",
            "SigmoidNAG without QG Testing Accuray at 128 iterations is 0.667800000000 with loss: -17960.473813857698\n",
            "SigmoidNAG without QG Testing Accuray at 129 iterations is 0.670700000000 with loss: -17978.487376465477\n",
            "SigmoidNAG without QG Testing Accuray at 130 iterations is 0.673300000000 with loss: -17884.743286566387\n",
            "SigmoidNAG without QG Testing Accuray at 131 iterations is 0.679000000000 with loss: -17662.960652208749\n",
            "SigmoidNAG without QG Testing Accuray at 132 iterations is 0.685500000000 with loss: -17419.645185525849\n",
            "SigmoidNAG without QG Testing Accuray at 133 iterations is 0.691500000000 with loss: -17293.149240645995\n",
            "SigmoidNAG without QG Testing Accuray at 134 iterations is 0.686200000000 with loss: -17331.717404548210\n",
            "SigmoidNAG without QG Testing Accuray at 135 iterations is 0.680200000000 with loss: -17459.359038199989\n",
            "SigmoidNAG without QG Testing Accuray at 136 iterations is 0.680000000000 with loss: -17551.479819375760\n",
            "SigmoidNAG without QG Testing Accuray at 137 iterations is 0.679000000000 with loss: -17544.567194519288\n",
            "SigmoidNAG without QG Testing Accuray at 138 iterations is 0.683000000000 with loss: -17473.360438309504\n",
            "SigmoidNAG without QG Testing Accuray at 139 iterations is 0.686600000000 with loss: -17402.771566267489\n",
            "SigmoidNAG without QG Testing Accuray at 140 iterations is 0.686400000000 with loss: -17344.948051837997\n",
            "SigmoidNAG without QG Testing Accuray at 141 iterations is 0.686900000000 with loss: -17263.491114946912\n",
            "SigmoidNAG without QG Testing Accuray at 142 iterations is 0.691600000000 with loss: -17145.033090061163\n",
            "SigmoidNAG without QG Testing Accuray at 143 iterations is 0.693000000000 with loss: -17035.048286517416\n",
            "SigmoidNAG without QG Testing Accuray at 144 iterations is 0.690900000000 with loss: -16993.639426447120\n",
            "SigmoidNAG without QG Testing Accuray at 145 iterations is 0.685800000000 with loss: -17028.931580055916\n",
            "SigmoidNAG without QG Testing Accuray at 146 iterations is 0.683200000000 with loss: -17081.968120853559\n",
            "SigmoidNAG without QG Testing Accuray at 147 iterations is 0.679700000000 with loss: -17076.336949037912\n",
            "SigmoidNAG without QG Testing Accuray at 148 iterations is 0.680700000000 with loss: -16984.400265879154\n",
            "SigmoidNAG without QG Testing Accuray at 149 iterations is 0.684100000000 with loss: -16848.743856472709\n",
            "SigmoidNAG without QG Testing Accuray at 150 iterations is 0.686400000000 with loss: -16744.371964023401\n",
            "SigmoidNAG without QG Testing Accuray at 151 iterations is 0.692400000000 with loss: -16723.377342036154\n",
            "SigmoidNAG without QG Testing Accuray at 152 iterations is 0.692200000000 with loss: -16784.638379390526\n",
            "SigmoidNAG without QG Testing Accuray at 153 iterations is 0.693600000000 with loss: -16876.486368174275\n",
            "SigmoidNAG without QG Testing Accuray at 154 iterations is 0.694800000000 with loss: -16924.915722870715\n",
            "SigmoidNAG without QG Testing Accuray at 155 iterations is 0.698000000000 with loss: -16877.262623336668\n",
            "SigmoidNAG without QG Testing Accuray at 156 iterations is 0.699300000000 with loss: -16736.102841615579\n",
            "SigmoidNAG without QG Testing Accuray at 157 iterations is 0.701600000000 with loss: -16553.900961134761\n",
            "SigmoidNAG without QG Testing Accuray at 158 iterations is 0.701700000000 with loss: -16393.065265188881\n",
            "SigmoidNAG without QG Testing Accuray at 159 iterations is 0.701300000000 with loss: -16292.231614622728\n",
            "SigmoidNAG without QG Testing Accuray at 160 iterations is 0.703300000000 with loss: -16264.816932017960\n",
            "SigmoidNAG without QG Testing Accuray at 161 iterations is 0.701300000000 with loss: -16311.332062673286\n",
            "SigmoidNAG without QG Testing Accuray at 162 iterations is 0.699300000000 with loss: -16417.366259606577\n",
            "SigmoidNAG without QG Testing Accuray at 163 iterations is 0.696500000000 with loss: -16541.652502064742\n",
            "SigmoidNAG without QG Testing Accuray at 164 iterations is 0.694800000000 with loss: -16621.101637297052\n",
            "SigmoidNAG without QG Testing Accuray at 165 iterations is 0.694900000000 with loss: -16601.995966267015\n",
            "SigmoidNAG without QG Testing Accuray at 166 iterations is 0.696000000000 with loss: -16473.964359840957\n",
            "SigmoidNAG without QG Testing Accuray at 167 iterations is 0.703700000000 with loss: -16277.142393482467\n",
            "SigmoidNAG without QG Testing Accuray at 168 iterations is 0.705500000000 with loss: -16079.163700591951\n",
            "SigmoidNAG without QG Testing Accuray at 169 iterations is 0.706900000000 with loss: -15943.496681075971\n",
            "SigmoidNAG without QG Testing Accuray at 170 iterations is 0.704000000000 with loss: -15907.839849247439\n",
            "SigmoidNAG without QG Testing Accuray at 171 iterations is 0.700600000000 with loss: -15974.542670038378\n",
            "SigmoidNAG without QG Testing Accuray at 172 iterations is 0.697900000000 with loss: -16109.310570897191\n",
            "SigmoidNAG without QG Testing Accuray at 173 iterations is 0.698500000000 with loss: -16250.421361528854\n",
            "SigmoidNAG without QG Testing Accuray at 174 iterations is 0.699800000000 with loss: -16332.107881582027\n",
            "SigmoidNAG without QG Testing Accuray at 175 iterations is 0.701300000000 with loss: -16314.875864680283\n",
            "SigmoidNAG without QG Testing Accuray at 176 iterations is 0.705200000000 with loss: -16203.779637154317\n",
            "SigmoidNAG without QG Testing Accuray at 177 iterations is 0.710500000000 with loss: -16040.967301499686\n",
            "SigmoidNAG without QG Testing Accuray at 178 iterations is 0.714900000000 with loss: -15879.767778471363\n",
            "SigmoidNAG without QG Testing Accuray at 179 iterations is 0.714600000000 with loss: -15760.795878605401\n",
            "SigmoidNAG without QG Testing Accuray at 180 iterations is 0.712200000000 with loss: -15702.063226392382\n",
            "SigmoidNAG without QG Testing Accuray at 181 iterations is 0.712200000000 with loss: -15699.743836394069\n",
            "SigmoidNAG without QG Testing Accuray at 182 iterations is 0.711600000000 with loss: -15733.329384257346\n",
            "SigmoidNAG without QG Testing Accuray at 183 iterations is 0.710600000000 with loss: -15774.737347569282\n",
            "SigmoidNAG without QG Testing Accuray at 184 iterations is 0.709700000000 with loss: -15800.701474510333\n",
            "SigmoidNAG without QG Testing Accuray at 185 iterations is 0.710400000000 with loss: -15801.731599033912\n",
            "SigmoidNAG without QG Testing Accuray at 186 iterations is 0.714900000000 with loss: -15781.494061718613\n",
            "SigmoidNAG without QG Testing Accuray at 187 iterations is 0.718600000000 with loss: -15749.347195570881\n",
            "SigmoidNAG without QG Testing Accuray at 188 iterations is 0.719600000000 with loss: -15714.123261813496\n",
            "SigmoidNAG without QG Testing Accuray at 189 iterations is 0.715900000000 with loss: -15682.861723662305\n",
            "SigmoidNAG without QG Testing Accuray at 190 iterations is 0.712000000000 with loss: -15661.322556365725\n",
            "SigmoidNAG without QG Testing Accuray at 191 iterations is 0.706300000000 with loss: -15652.095691271454\n",
            "SigmoidNAG without QG Testing Accuray at 192 iterations is 0.701700000000 with loss: -15650.729156378366\n",
            "SigmoidNAG without QG Testing Accuray at 193 iterations is 0.701100000000 with loss: -15644.809060907333\n",
            "SigmoidNAG without QG Testing Accuray at 194 iterations is 0.702600000000 with loss: -15620.238237295614\n",
            "SigmoidNAG without QG Testing Accuray at 195 iterations is 0.706800000000 with loss: -15572.432699845598\n",
            "SigmoidNAG without QG Testing Accuray at 196 iterations is 0.710100000000 with loss: -15513.455993653448\n",
            "SigmoidNAG without QG Testing Accuray at 197 iterations is 0.714500000000 with loss: -15467.179451832990\n",
            "SigmoidNAG without QG Testing Accuray at 198 iterations is 0.716800000000 with loss: -15454.221852392295\n",
            "SigmoidNAG without QG Testing Accuray at 199 iterations is 0.715900000000 with loss: -15477.539188979084\n",
            "SigmoidNAG without QG Testing Accuray at 200 iterations is 0.715000000000 with loss: -15519.056153401063\n",
            "SigmoidNAG without QG Testing Accuray at 201 iterations is 0.714500000000 with loss: -15549.070178135165\n",
            "SigmoidNAG without QG Testing Accuray at 202 iterations is 0.715200000000 with loss: -15541.868321806825\n",
            "SigmoidNAG without QG Testing Accuray at 203 iterations is 0.715100000000 with loss: -15488.454473449139\n",
            "SigmoidNAG without QG Testing Accuray at 204 iterations is 0.714900000000 with loss: -15400.004336158299\n",
            "SigmoidNAG without QG Testing Accuray at 205 iterations is 0.715700000000 with loss: -15301.258101381218\n",
            "SigmoidNAG without QG Testing Accuray at 206 iterations is 0.717700000000 with loss: -15218.709478805111\n",
            "SigmoidNAG without QG Testing Accuray at 207 iterations is 0.721600000000 with loss: -15170.647817753041\n",
            "SigmoidNAG without QG Testing Accuray at 208 iterations is 0.723500000000 with loss: -15163.349166097380\n",
            "SigmoidNAG without QG Testing Accuray at 209 iterations is 0.722400000000 with loss: -15192.753237399613\n",
            "SigmoidNAG without QG Testing Accuray at 210 iterations is 0.717200000000 with loss: -15248.060975114124\n",
            "SigmoidNAG without QG Testing Accuray at 211 iterations is 0.715800000000 with loss: -15314.348524969973\n",
            "SigmoidNAG without QG Testing Accuray at 212 iterations is 0.709900000000 with loss: -15373.913299031881\n",
            "SigmoidNAG without QG Testing Accuray at 213 iterations is 0.709300000000 with loss: -15408.221419894764\n",
            "SigmoidNAG without QG Testing Accuray at 214 iterations is 0.708500000000 with loss: -15402.337946350613\n",
            "SigmoidNAG without QG Testing Accuray at 215 iterations is 0.708900000000 with loss: -15351.365123600122\n",
            "SigmoidNAG without QG Testing Accuray at 216 iterations is 0.711000000000 with loss: -15265.392189806611\n",
            "SigmoidNAG without QG Testing Accuray at 217 iterations is 0.713600000000 with loss: -15168.585476157377\n",
            "SigmoidNAG without QG Testing Accuray at 218 iterations is 0.716000000000 with loss: -15090.801296299362\n",
            "SigmoidNAG without QG Testing Accuray at 219 iterations is 0.719400000000 with loss: -15054.923121516074\n",
            "SigmoidNAG without QG Testing Accuray at 220 iterations is 0.720400000000 with loss: -15066.501109857676\n",
            "SigmoidNAG without QG Testing Accuray at 221 iterations is 0.718500000000 with loss: -15111.585166318777\n",
            "SigmoidNAG without QG Testing Accuray at 222 iterations is 0.717200000000 with loss: -15164.077573814211\n",
            "SigmoidNAG without QG Testing Accuray at 223 iterations is 0.717800000000 with loss: -15198.330227166049\n",
            "SigmoidNAG without QG Testing Accuray at 224 iterations is 0.717300000000 with loss: -15199.827171894061\n",
            "SigmoidNAG without QG Testing Accuray at 225 iterations is 0.716800000000 with loss: -15168.677704142545\n",
            "SigmoidNAG without QG Testing Accuray at 226 iterations is 0.716700000000 with loss: -15115.751288301461\n",
            "SigmoidNAG without QG Testing Accuray at 227 iterations is 0.717100000000 with loss: -15055.551773763607\n",
            "SigmoidNAG without QG Testing Accuray at 228 iterations is 0.719300000000 with loss: -15000.448525465361\n",
            "SigmoidNAG without QG Testing Accuray at 229 iterations is 0.720400000000 with loss: -14958.308825200147\n",
            "SigmoidNAG without QG Testing Accuray at 230 iterations is 0.723100000000 with loss: -14932.742025763209\n",
            "SigmoidNAG without QG Testing Accuray at 231 iterations is 0.720400000000 with loss: -14924.083627613340\n",
            "SigmoidNAG without QG Testing Accuray at 232 iterations is 0.721100000000 with loss: -14929.899582942491\n",
            "SigmoidNAG without QG Testing Accuray at 233 iterations is 0.719300000000 with loss: -14945.058151418538\n",
            "SigmoidNAG without QG Testing Accuray at 234 iterations is 0.717300000000 with loss: -14962.250831213083\n",
            "SigmoidNAG without QG Testing Accuray at 235 iterations is 0.715100000000 with loss: -14973.720498656114\n",
            "SigmoidNAG without QG Testing Accuray at 236 iterations is 0.716200000000 with loss: -14973.981998527797\n",
            "SigmoidNAG without QG Testing Accuray at 237 iterations is 0.717100000000 with loss: -14962.235515713706\n",
            "SigmoidNAG without QG Testing Accuray at 238 iterations is 0.719500000000 with loss: -14942.902410139181\n",
            "SigmoidNAG without QG Testing Accuray at 239 iterations is 0.718700000000 with loss: -14923.594843903973\n",
            "SigmoidNAG without QG Testing Accuray at 240 iterations is 0.720200000000 with loss: -14911.300858382365\n",
            "SigmoidNAG without QG Testing Accuray at 241 iterations is 0.723600000000 with loss: -14908.683066555697\n",
            "SigmoidNAG without QG Testing Accuray at 242 iterations is 0.723900000000 with loss: -14912.513360456260\n",
            "SigmoidNAG without QG Testing Accuray at 243 iterations is 0.722700000000 with loss: -14915.270065431383\n",
            "SigmoidNAG without QG Testing Accuray at 244 iterations is 0.721800000000 with loss: -14909.179163420935\n",
            "SigmoidNAG without QG Testing Accuray at 245 iterations is 0.721700000000 with loss: -14890.435155882036\n",
            "SigmoidNAG without QG Testing Accuray at 246 iterations is 0.721200000000 with loss: -14861.148300341791\n",
            "SigmoidNAG without QG Testing Accuray at 247 iterations is 0.720900000000 with loss: -14828.053391518599\n",
            "SigmoidNAG without QG Testing Accuray at 248 iterations is 0.720400000000 with loss: -14799.083043610528\n",
            "SigmoidNAG without QG Testing Accuray at 249 iterations is 0.721500000000 with loss: -14779.963701713417\n",
            "SigmoidNAG without QG Testing Accuray at 250 iterations is 0.721200000000 with loss: -14772.461828445250\n",
            "SigmoidNAG without QG Testing Accuray at 251 iterations is 0.721300000000 with loss: -14774.569639332040\n",
            "SigmoidNAG without QG Testing Accuray at 252 iterations is 0.721400000000 with loss: -14781.893748217297\n",
            "SigmoidNAG without QG Testing Accuray at 253 iterations is 0.721400000000 with loss: -14789.277314041659\n",
            "SigmoidNAG without QG Testing Accuray at 254 iterations is 0.723400000000 with loss: -14792.037883757019\n",
            "SigmoidNAG without QG Testing Accuray at 255 iterations is 0.722200000000 with loss: -14786.712011182635\n",
            "SigmoidNAG without QG Testing Accuray at 256 iterations is 0.722600000000 with loss: -14771.536663685214\n",
            "SigmoidNAG without QG Testing Accuray at 257 iterations is 0.722100000000 with loss: -14746.906641027797\n",
            "SigmoidNAG without QG Testing Accuray at 258 iterations is 0.721400000000 with loss: -14715.755293255019\n",
            "SigmoidNAG without QG Testing Accuray at 259 iterations is 0.722600000000 with loss: -14683.455655617679\n",
            "SigmoidNAG without QG Testing Accuray at 260 iterations is 0.723500000000 with loss: -14656.780843090844\n",
            "SigmoidNAG without QG Testing Accuray at 261 iterations is 0.723200000000 with loss: -14641.879884116621\n",
            "SigmoidNAG without QG Testing Accuray at 262 iterations is 0.724200000000 with loss: -14641.917005994213\n",
            "SigmoidNAG without QG Testing Accuray at 263 iterations is 0.724500000000 with loss: -14655.492455243853\n",
            "SigmoidNAG without QG Testing Accuray at 264 iterations is 0.727600000000 with loss: -14676.793119358739\n",
            "SigmoidNAG without QG Testing Accuray at 265 iterations is 0.728600000000 with loss: -14697.615909407368\n",
            "SigmoidNAG without QG Testing Accuray at 266 iterations is 0.728900000000 with loss: -14710.421636299105\n",
            "SigmoidNAG without QG Testing Accuray at 267 iterations is 0.728800000000 with loss: -14711.016011242276\n",
            "SigmoidNAG without QG Testing Accuray at 268 iterations is 0.729300000000 with loss: -14699.665221927255\n",
            "SigmoidNAG without QG Testing Accuray at 269 iterations is 0.728300000000 with loss: -14680.298326522499\n",
            "SigmoidNAG without QG Testing Accuray at 270 iterations is 0.728000000000 with loss: -14658.403998594731\n",
            "SigmoidNAG without QG Testing Accuray at 271 iterations is 0.727900000000 with loss: -14638.747037845367\n",
            "SigmoidNAG without QG Testing Accuray at 272 iterations is 0.728100000000 with loss: -14623.893743655150\n",
            "SigmoidNAG without QG Testing Accuray at 273 iterations is 0.727400000000 with loss: -14613.948039821376\n",
            "SigmoidNAG without QG Testing Accuray at 274 iterations is 0.727200000000 with loss: -14607.273060446634\n",
            "SigmoidNAG without QG Testing Accuray at 275 iterations is 0.726800000000 with loss: -14601.625606104584\n",
            "SigmoidNAG without QG Testing Accuray at 276 iterations is 0.725200000000 with loss: -14595.139265584776\n",
            "SigmoidNAG without QG Testing Accuray at 277 iterations is 0.726700000000 with loss: -14586.836943764416\n",
            "SigmoidNAG without QG Testing Accuray at 278 iterations is 0.727900000000 with loss: -14576.653240644011\n",
            "SigmoidNAG without QG Testing Accuray at 279 iterations is 0.728000000000 with loss: -14565.160976387460\n",
            "SigmoidNAG without QG Testing Accuray at 280 iterations is 0.727400000000 with loss: -14553.256392555089\n",
            "SigmoidNAG without QG Testing Accuray at 281 iterations is 0.727600000000 with loss: -14541.967051276362\n",
            "SigmoidNAG without QG Testing Accuray at 282 iterations is 0.727800000000 with loss: -14532.371941959933\n",
            "SigmoidNAG without QG Testing Accuray at 283 iterations is 0.728400000000 with loss: -14525.480842103469\n",
            "SigmoidNAG without QG Testing Accuray at 284 iterations is 0.727300000000 with loss: -14521.923575103880\n",
            "SigmoidNAG without QG Testing Accuray at 285 iterations is 0.726500000000 with loss: -14521.477504523016\n",
            "SigmoidNAG without QG Testing Accuray at 286 iterations is 0.727300000000 with loss: -14522.699742110062\n",
            "SigmoidNAG without QG Testing Accuray at 287 iterations is 0.727800000000 with loss: -14523.025148013394\n",
            "SigmoidNAG without QG Testing Accuray at 288 iterations is 0.728700000000 with loss: -14519.506417610624\n",
            "SigmoidNAG without QG Testing Accuray at 289 iterations is 0.730000000000 with loss: -14509.985593890025\n",
            "SigmoidNAG without QG Testing Accuray at 290 iterations is 0.731700000000 with loss: -14494.162996405303\n",
            "SigmoidNAG without QG Testing Accuray at 291 iterations is 0.733700000000 with loss: -14474.014648612800\n",
            "SigmoidNAG without QG Testing Accuray at 292 iterations is 0.733500000000 with loss: -14453.321043595155\n",
            "SigmoidNAG without QG Testing Accuray at 293 iterations is 0.734200000000 with loss: -14436.494907025462\n",
            "SigmoidNAG without QG Testing Accuray at 294 iterations is 0.734900000000 with loss: -14427.179215040527\n",
            "SigmoidNAG without QG Testing Accuray at 295 iterations is 0.735800000000 with loss: -14427.117846231895\n",
            "SigmoidNAG without QG Testing Accuray at 296 iterations is 0.735700000000 with loss: -14435.634749234825\n",
            "SigmoidNAG without QG Testing Accuray at 297 iterations is 0.734600000000 with loss: -14449.816168257719\n",
            "SigmoidNAG without QG Testing Accuray at 298 iterations is 0.733000000000 with loss: -14465.274200409251\n",
            "SigmoidNAG without QG Testing Accuray at 299 iterations is 0.732900000000 with loss: -14477.232583523954\n",
            "SigmoidNAG without QG Testing Accuray at 300 iterations is 0.731100000000 with loss: -14481.633872494087\n",
            "SigmoidNAG without QG Testing Accuray at 301 iterations is 0.732500000000 with loss: -14476.009875408750\n",
            "SigmoidNAG without QG Testing Accuray at 302 iterations is 0.733400000000 with loss: -14459.952163445994\n",
            "SigmoidNAG without QG Testing Accuray at 303 iterations is 0.733800000000 with loss: -14435.129309726575\n",
            "SigmoidNAG without QG Testing Accuray at 304 iterations is 0.732300000000 with loss: -14404.893869049569\n",
            "SigmoidNAG without QG Testing Accuray at 305 iterations is 0.733600000000 with loss: -14373.590584581174\n",
            "SigmoidNAG without QG Testing Accuray at 306 iterations is 0.734400000000 with loss: -14345.713789214169\n",
            "SigmoidNAG without QG Testing Accuray at 307 iterations is 0.734400000000 with loss: -14325.069125554646\n",
            "SigmoidNAG without QG Testing Accuray at 308 iterations is 0.733900000000 with loss: -14314.080558463989\n",
            "SigmoidNAG without QG Testing Accuray at 309 iterations is 0.733600000000 with loss: -14313.357836171463\n",
            "SigmoidNAG without QG Testing Accuray at 310 iterations is 0.735100000000 with loss: -14321.604242529391\n",
            "SigmoidNAG without QG Testing Accuray at 311 iterations is 0.734300000000 with loss: -14335.892095463321\n",
            "SigmoidNAG without QG Testing Accuray at 312 iterations is 0.733400000000 with loss: -14352.259563611229\n",
            "SigmoidNAG without QG Testing Accuray at 313 iterations is 0.731100000000 with loss: -14366.503238354166\n",
            "SigmoidNAG without QG Testing Accuray at 314 iterations is 0.731200000000 with loss: -14374.991310045076\n",
            "SigmoidNAG without QG Testing Accuray at 315 iterations is 0.731700000000 with loss: -14375.327744243894\n",
            "SigmoidNAG without QG Testing Accuray at 316 iterations is 0.730600000000 with loss: -14366.749225261594\n",
            "SigmoidNAG without QG Testing Accuray at 317 iterations is 0.730900000000 with loss: -14350.200595278367\n",
            "SigmoidNAG without QG Testing Accuray at 318 iterations is 0.732500000000 with loss: -14328.087443808225\n",
            "SigmoidNAG without QG Testing Accuray at 319 iterations is 0.733000000000 with loss: -14303.751288951487\n",
            "SigmoidNAG without QG Testing Accuray at 320 iterations is 0.734900000000 with loss: -14280.766989414686\n",
            "SigmoidNAG without QG Testing Accuray at 321 iterations is 0.735100000000 with loss: -14262.215380245994\n",
            "SigmoidNAG without QG Testing Accuray at 322 iterations is 0.735900000000 with loss: -14250.105104035438\n",
            "SigmoidNAG without QG Testing Accuray at 323 iterations is 0.737600000000 with loss: -14245.080664850026\n",
            "SigmoidNAG without QG Testing Accuray at 324 iterations is 0.739000000000 with loss: -14246.466035501317\n",
            "SigmoidNAG without QG Testing Accuray at 325 iterations is 0.738800000000 with loss: -14252.591738310834\n",
            "SigmoidNAG without QG Testing Accuray at 326 iterations is 0.737800000000 with loss: -14261.279220897055\n",
            "SigmoidNAG without QG Testing Accuray at 327 iterations is 0.739100000000 with loss: -14270.331993314305\n",
            "SigmoidNAG without QG Testing Accuray at 328 iterations is 0.737900000000 with loss: -14277.907117520190\n",
            "SigmoidNAG without QG Testing Accuray at 329 iterations is 0.737600000000 with loss: -14282.697625725561\n",
            "SigmoidNAG without QG Testing Accuray at 330 iterations is 0.737500000000 with loss: -14283.926080762392\n",
            "SigmoidNAG without QG Testing Accuray at 331 iterations is 0.736900000000 with loss: -14281.212871624197\n",
            "SigmoidNAG without QG Testing Accuray at 332 iterations is 0.736000000000 with loss: -14274.422702256486\n",
            "SigmoidNAG without QG Testing Accuray at 333 iterations is 0.736200000000 with loss: -14263.594297361107\n",
            "SigmoidNAG without QG Testing Accuray at 334 iterations is 0.735700000000 with loss: -14249.014213252429\n",
            "SigmoidNAG without QG Testing Accuray at 335 iterations is 0.735700000000 with loss: -14231.413666708686\n",
            "SigmoidNAG without QG Testing Accuray at 336 iterations is 0.736800000000 with loss: -14212.177115361086\n",
            "SigmoidNAG without QG Testing Accuray at 337 iterations is 0.737900000000 with loss: -14193.399713355877\n",
            "SigmoidNAG without QG Testing Accuray at 338 iterations is 0.739600000000 with loss: -14177.659445181560\n",
            "SigmoidNAG without QG Testing Accuray at 339 iterations is 0.738700000000 with loss: -14167.485036712242\n",
            "SigmoidNAG without QG Testing Accuray at 340 iterations is 0.739200000000 with loss: -14164.656192418790\n",
            "SigmoidNAG without QG Testing Accuray at 341 iterations is 0.738300000000 with loss: -14169.586266359647\n",
            "SigmoidNAG without QG Testing Accuray at 342 iterations is 0.738300000000 with loss: -14181.039604636288\n",
            "SigmoidNAG without QG Testing Accuray at 343 iterations is 0.736000000000 with loss: -14196.316150319808\n",
            "SigmoidNAG without QG Testing Accuray at 344 iterations is 0.735300000000 with loss: -14211.853671530425\n",
            "SigmoidNAG without QG Testing Accuray at 345 iterations is 0.735100000000 with loss: -14224.045092077937\n",
            "SigmoidNAG without QG Testing Accuray at 346 iterations is 0.734600000000 with loss: -14230.013542038350\n",
            "SigmoidNAG without QG Testing Accuray at 347 iterations is 0.733400000000 with loss: -14228.140806767045\n",
            "SigmoidNAG without QG Testing Accuray at 348 iterations is 0.733100000000 with loss: -14218.261210814138\n",
            "SigmoidNAG without QG Testing Accuray at 349 iterations is 0.734200000000 with loss: -14201.549213107743\n",
            "SigmoidNAG without QG Testing Accuray at 350 iterations is 0.734600000000 with loss: -14180.199236113989\n",
            "SigmoidNAG without QG Testing Accuray at 351 iterations is 0.734700000000 with loss: -14157.009508986992\n",
            "SigmoidNAG without QG Testing Accuray at 352 iterations is 0.735700000000 with loss: -14134.954919918739\n",
            "SigmoidNAG without QG Testing Accuray at 353 iterations is 0.737800000000 with loss: -14116.794348083660\n",
            "SigmoidNAG without QG Testing Accuray at 354 iterations is 0.740100000000 with loss: -14104.727613641087\n",
            "SigmoidNAG without QG Testing Accuray at 355 iterations is 0.740700000000 with loss: -14100.106646867827\n",
            "SigmoidNAG without QG Testing Accuray at 356 iterations is 0.741000000000 with loss: -14103.214609746214\n",
            "SigmoidNAG without QG Testing Accuray at 357 iterations is 0.740800000000 with loss: -14113.147403305175\n",
            "SigmoidNAG without QG Testing Accuray at 358 iterations is 0.741400000000 with loss: -14127.850307174318\n",
            "SigmoidNAG without QG Testing Accuray at 359 iterations is 0.741300000000 with loss: -14144.361501739158\n",
            "SigmoidNAG without QG Testing Accuray at 360 iterations is 0.739800000000 with loss: -14159.280482097307\n",
            "SigmoidNAG without QG Testing Accuray at 361 iterations is 0.739100000000 with loss: -14169.412323215040\n",
            "SigmoidNAG without QG Testing Accuray at 362 iterations is 0.739100000000 with loss: -14172.458288963162\n",
            "SigmoidNAG without QG Testing Accuray at 363 iterations is 0.739200000000 with loss: -14167.566546372103\n",
            "SigmoidNAG without QG Testing Accuray at 364 iterations is 0.739300000000 with loss: -14155.561553491290\n",
            "SigmoidNAG without QG Testing Accuray at 365 iterations is 0.739900000000 with loss: -14138.751673329989\n",
            "SigmoidNAG without QG Testing Accuray at 366 iterations is 0.739300000000 with loss: -14120.348420162847\n",
            "SigmoidNAG without QG Testing Accuray at 367 iterations is 0.740500000000 with loss: -14103.663345233477\n",
            "SigmoidNAG without QG Testing Accuray at 368 iterations is 0.740300000000 with loss: -14091.322226152792\n",
            "SigmoidNAG without QG Testing Accuray at 369 iterations is 0.739900000000 with loss: -14084.720255694614\n",
            "SigmoidNAG without QG Testing Accuray at 370 iterations is 0.740400000000 with loss: -14083.847382873892\n",
            "SigmoidNAG without QG Testing Accuray at 371 iterations is 0.740400000000 with loss: -14087.483618777682\n",
            "SigmoidNAG without QG Testing Accuray at 372 iterations is 0.740300000000 with loss: -14093.652752730397\n",
            "SigmoidNAG without QG Testing Accuray at 373 iterations is 0.739100000000 with loss: -14100.167128277018\n",
            "SigmoidNAG without QG Testing Accuray at 374 iterations is 0.739900000000 with loss: -14105.105687149657\n",
            "SigmoidNAG without QG Testing Accuray at 375 iterations is 0.738200000000 with loss: -14107.125889508317\n",
            "SigmoidNAG without QG Testing Accuray at 376 iterations is 0.739000000000 with loss: -14105.585450507288\n",
            "SigmoidNAG without QG Testing Accuray at 377 iterations is 0.736300000000 with loss: -14100.510468967872\n",
            "SigmoidNAG without QG Testing Accuray at 378 iterations is 0.736200000000 with loss: -14092.473542293323\n",
            "SigmoidNAG without QG Testing Accuray at 379 iterations is 0.735500000000 with loss: -14082.438249000781\n",
            "SigmoidNAG without QG Testing Accuray at 380 iterations is 0.737600000000 with loss: -14071.599249776793\n",
            "SigmoidNAG without QG Testing Accuray at 381 iterations is 0.737400000000 with loss: -14061.220213538325\n",
            "SigmoidNAG without QG Testing Accuray at 382 iterations is 0.738600000000 with loss: -14052.460290991390\n",
            "SigmoidNAG without QG Testing Accuray at 383 iterations is 0.738900000000 with loss: -14046.188858191766\n",
            "SigmoidNAG without QG Testing Accuray at 384 iterations is 0.740300000000 with loss: -14042.811232604377\n",
            "SigmoidNAG without QG Testing Accuray at 385 iterations is 0.739900000000 with loss: -14042.151087348411\n",
            "SigmoidNAG without QG Testing Accuray at 386 iterations is 0.740200000000 with loss: -14043.443145058478\n",
            "SigmoidNAG without QG Testing Accuray at 387 iterations is 0.740100000000 with loss: -14045.472646062744\n",
            "SigmoidNAG without QG Testing Accuray at 388 iterations is 0.740000000000 with loss: -14046.856892878066\n",
            "SigmoidNAG without QG Testing Accuray at 389 iterations is 0.740900000000 with loss: -14046.411778162099\n",
            "SigmoidNAG without QG Testing Accuray at 390 iterations is 0.741600000000 with loss: -14043.503801153789\n",
            "SigmoidNAG without QG Testing Accuray at 391 iterations is 0.742200000000 with loss: -14038.276176632260\n",
            "SigmoidNAG without QG Testing Accuray at 392 iterations is 0.743100000000 with loss: -14031.665772627906\n",
            "SigmoidNAG without QG Testing Accuray at 393 iterations is 0.745000000000 with loss: -14025.188403495706\n",
            "SigmoidNAG without QG Testing Accuray at 394 iterations is 0.745300000000 with loss: -14020.541875144156\n",
            "SigmoidNAG without QG Testing Accuray at 395 iterations is 0.743300000000 with loss: -14019.133130093935\n",
            "SigmoidNAG without QG Testing Accuray at 396 iterations is 0.743600000000 with loss: -14021.658975020111\n",
            "SigmoidNAG without QG Testing Accuray at 397 iterations is 0.742300000000 with loss: -14027.854090090030\n",
            "SigmoidNAG without QG Testing Accuray at 398 iterations is 0.742800000000 with loss: -14036.473544417649\n",
            "SigmoidNAG without QG Testing Accuray at 399 iterations is 0.743200000000 with loss: -14045.515654068240\n",
            "SigmoidNAG without QG Testing Accuray at 400 iterations is 0.741400000000 with loss: -14052.631734201223\n",
            "SigmoidNAG without QG Testing Accuray at 401 iterations is 0.741000000000 with loss: -14055.626053878963\n",
            "SigmoidNAG without QG Testing Accuray at 402 iterations is 0.741800000000 with loss: -14052.931009813854\n",
            "SigmoidNAG without QG Testing Accuray at 403 iterations is 0.742300000000 with loss: -14043.952243915615\n",
            "SigmoidNAG without QG Testing Accuray at 404 iterations is 0.742600000000 with loss: -14029.212476955150\n",
            "SigmoidNAG without QG Testing Accuray at 405 iterations is 0.742200000000 with loss: -14010.271456208378\n",
            "SigmoidNAG without QG Testing Accuray at 406 iterations is 0.743600000000 with loss: -13989.449113716435\n",
            "SigmoidNAG without QG Testing Accuray at 407 iterations is 0.743200000000 with loss: -13969.416976275834\n",
            "SigmoidNAG without QG Testing Accuray at 408 iterations is 0.742900000000 with loss: -13952.741279769141\n",
            "SigmoidNAG without QG Testing Accuray at 409 iterations is 0.744600000000 with loss: -13941.459624769859\n",
            "SigmoidNAG without QG Testing Accuray at 410 iterations is 0.743100000000 with loss: -13936.756926985208\n",
            "SigmoidNAG without QG Testing Accuray at 411 iterations is 0.743700000000 with loss: -13938.783784154477\n",
            "SigmoidNAG without QG Testing Accuray at 412 iterations is 0.742700000000 with loss: -13946.637493518168\n",
            "SigmoidNAG without QG Testing Accuray at 413 iterations is 0.741300000000 with loss: -13958.505235044198\n",
            "SigmoidNAG without QG Testing Accuray at 414 iterations is 0.740900000000 with loss: -13971.949724292092\n",
            "SigmoidNAG without QG Testing Accuray at 415 iterations is 0.741400000000 with loss: -13984.298613409548\n",
            "SigmoidNAG without QG Testing Accuray at 416 iterations is 0.740100000000 with loss: -13993.080853316766\n",
            "SigmoidNAG without QG Testing Accuray at 417 iterations is 0.739400000000 with loss: -13996.440141849269\n",
            "SigmoidNAG without QG Testing Accuray at 418 iterations is 0.738700000000 with loss: -13993.453132362434\n",
            "SigmoidNAG without QG Testing Accuray at 419 iterations is 0.740700000000 with loss: -13984.292491383518\n",
            "SigmoidNAG without QG Testing Accuray at 420 iterations is 0.740700000000 with loss: -13970.201837138186\n",
            "SigmoidNAG without QG Testing Accuray at 421 iterations is 0.742200000000 with loss: -13953.285372781542\n",
            "SigmoidNAG without QG Testing Accuray at 422 iterations is 0.743700000000 with loss: -13936.150575241711\n",
            "SigmoidNAG without QG Testing Accuray at 423 iterations is 0.745200000000 with loss: -13921.468795922676\n",
            "SigmoidNAG without QG Testing Accuray at 424 iterations is 0.746100000000 with loss: -13911.530702996342\n",
            "SigmoidNAG without QG Testing Accuray at 425 iterations is 0.747600000000 with loss: -13907.870427943133\n",
            "SigmoidNAG without QG Testing Accuray at 426 iterations is 0.747100000000 with loss: -13911.017041453259\n",
            "SigmoidNAG without QG Testing Accuray at 427 iterations is 0.746900000000 with loss: -13920.409172660000\n",
            "SigmoidNAG without QG Testing Accuray at 428 iterations is 0.746100000000 with loss: -13934.482590818066\n",
            "SigmoidNAG without QG Testing Accuray at 429 iterations is 0.745800000000 with loss: -13950.914756206348\n",
            "SigmoidNAG without QG Testing Accuray at 430 iterations is 0.745200000000 with loss: -13966.987253312067\n",
            "SigmoidNAG without QG Testing Accuray at 431 iterations is 0.744700000000 with loss: -13980.009017052571\n",
            "SigmoidNAG without QG Testing Accuray at 432 iterations is 0.743600000000 with loss: -13987.732970799689\n",
            "SigmoidNAG without QG Testing Accuray at 433 iterations is 0.743500000000 with loss: -13988.698640504921\n",
            "SigmoidNAG without QG Testing Accuray at 434 iterations is 0.743700000000 with loss: -13982.444923300332\n",
            "SigmoidNAG without QG Testing Accuray at 435 iterations is 0.745000000000 with loss: -13969.559447001562\n",
            "SigmoidNAG without QG Testing Accuray at 436 iterations is 0.745800000000 with loss: -13951.560026263345\n",
            "SigmoidNAG without QG Testing Accuray at 437 iterations is 0.746000000000 with loss: -13930.633523900922\n",
            "SigmoidNAG without QG Testing Accuray at 438 iterations is 0.746700000000 with loss: -13909.281539478085\n",
            "SigmoidNAG without QG Testing Accuray at 439 iterations is 0.747100000000 with loss: -13889.935967236575\n",
            "SigmoidNAG without QG Testing Accuray at 440 iterations is 0.747600000000 with loss: -13874.608620141640\n",
            "SigmoidNAG without QG Testing Accuray at 441 iterations is 0.746900000000 with loss: -13864.628754869358\n",
            "SigmoidNAG without QG Testing Accuray at 442 iterations is 0.746200000000 with loss: -13860.503470328535\n",
            "SigmoidNAG without QG Testing Accuray at 443 iterations is 0.746200000000 with loss: -13861.912676919732\n",
            "SigmoidNAG without QG Testing Accuray at 444 iterations is 0.745500000000 with loss: -13867.827061769905\n",
            "SigmoidNAG without QG Testing Accuray at 445 iterations is 0.744500000000 with loss: -13876.718412867658\n",
            "SigmoidNAG without QG Testing Accuray at 446 iterations is 0.743200000000 with loss: -13886.820141402726\n",
            "SigmoidNAG without QG Testing Accuray at 447 iterations is 0.742800000000 with loss: -13896.393519397718\n",
            "SigmoidNAG without QG Testing Accuray at 448 iterations is 0.742400000000 with loss: -13903.961290998228\n",
            "SigmoidNAG without QG Testing Accuray at 449 iterations is 0.742300000000 with loss: -13908.481929752183\n",
            "SigmoidNAG without QG Testing Accuray at 450 iterations is 0.742500000000 with loss: -13909.450807723808\n",
            "SigmoidNAG without QG Testing Accuray at 451 iterations is 0.742100000000 with loss: -13906.925498976885\n",
            "SigmoidNAG without QG Testing Accuray at 452 iterations is 0.741100000000 with loss: -13901.479916516335\n",
            "SigmoidNAG without QG Testing Accuray at 453 iterations is 0.742300000000 with loss: -13894.096730479261\n",
            "SigmoidNAG without QG Testing Accuray at 454 iterations is 0.743000000000 with loss: -13886.011347897485\n",
            "SigmoidNAG without QG Testing Accuray at 455 iterations is 0.743600000000 with loss: -13878.525095569286\n",
            "SigmoidNAG without QG Testing Accuray at 456 iterations is 0.745100000000 with loss: -13872.810082145101\n",
            "SigmoidNAG without QG Testing Accuray at 457 iterations is 0.745400000000 with loss: -13869.732031878906\n",
            "SigmoidNAG without QG Testing Accuray at 458 iterations is 0.747600000000 with loss: -13869.717988495526\n",
            "SigmoidNAG without QG Testing Accuray at 459 iterations is 0.747700000000 with loss: -13872.691518772028\n",
            "SigmoidNAG without QG Testing Accuray at 460 iterations is 0.747600000000 with loss: -13878.088496774684\n",
            "SigmoidNAG without QG Testing Accuray at 461 iterations is 0.748000000000 with loss: -13884.952933860308\n",
            "SigmoidNAG without QG Testing Accuray at 462 iterations is 0.748100000000 with loss: -13892.097292653656\n",
            "SigmoidNAG without QG Testing Accuray at 463 iterations is 0.747400000000 with loss: -13898.298690093690\n",
            "SigmoidNAG without QG Testing Accuray at 464 iterations is 0.746300000000 with loss: -13902.494716284544\n",
            "SigmoidNAG without QG Testing Accuray at 465 iterations is 0.746300000000 with loss: -13903.942598635809\n",
            "SigmoidNAG without QG Testing Accuray at 466 iterations is 0.746500000000 with loss: -13902.313597524042\n",
            "SigmoidNAG without QG Testing Accuray at 467 iterations is 0.746100000000 with loss: -13897.709092061634\n",
            "SigmoidNAG without QG Testing Accuray at 468 iterations is 0.746400000000 with loss: -13890.602145543702\n",
            "SigmoidNAG without QG Testing Accuray at 469 iterations is 0.747500000000 with loss: -13881.723943689662\n",
            "SigmoidNAG without QG Testing Accuray at 470 iterations is 0.748500000000 with loss: -13871.924329163579\n",
            "SigmoidNAG without QG Testing Accuray at 471 iterations is 0.747900000000 with loss: -13862.037450408179\n",
            "SigmoidNAG without QG Testing Accuray at 472 iterations is 0.747700000000 with loss: -13852.777407655463\n",
            "SigmoidNAG without QG Testing Accuray at 473 iterations is 0.748200000000 with loss: -13844.677138984482\n",
            "SigmoidNAG without QG Testing Accuray at 474 iterations is 0.748300000000 with loss: -13838.070558747824\n",
            "SigmoidNAG without QG Testing Accuray at 475 iterations is 0.747300000000 with loss: -13833.107265436383\n",
            "SigmoidNAG without QG Testing Accuray at 476 iterations is 0.747200000000 with loss: -13829.783963522972\n",
            "SigmoidNAG without QG Testing Accuray at 477 iterations is 0.748100000000 with loss: -13827.977967364137\n",
            "SigmoidNAG without QG Testing Accuray at 478 iterations is 0.747100000000 with loss: -13827.474324142469\n",
            "SigmoidNAG without QG Testing Accuray at 479 iterations is 0.745100000000 with loss: -13827.986016278661\n",
            "SigmoidNAG without QG Testing Accuray at 480 iterations is 0.744800000000 with loss: -13829.172830506222\n",
            "SigmoidNAG without QG Testing Accuray at 481 iterations is 0.745200000000 with loss: -13830.666300590239\n",
            "SigmoidNAG without QG Testing Accuray at 482 iterations is 0.744800000000 with loss: -13832.105226738113\n",
            "SigmoidNAG without QG Testing Accuray at 483 iterations is 0.743900000000 with loss: -13833.180241382248\n",
            "SigmoidNAG without QG Testing Accuray at 484 iterations is 0.743500000000 with loss: -13833.679588182007\n",
            "SigmoidNAG without QG Testing Accuray at 485 iterations is 0.743500000000 with loss: -13833.524518157064\n",
            "SigmoidNAG without QG Testing Accuray at 486 iterations is 0.744700000000 with loss: -13832.783105690758\n",
            "SigmoidNAG without QG Testing Accuray at 487 iterations is 0.745200000000 with loss: -13831.655812048119\n",
            "SigmoidNAG without QG Testing Accuray at 488 iterations is 0.745700000000 with loss: -13830.433251533294\n",
            "SigmoidNAG without QG Testing Accuray at 489 iterations is 0.746200000000 with loss: -13829.434016151783\n",
            "SigmoidNAG without QG Testing Accuray at 490 iterations is 0.745300000000 with loss: -13828.935838329186\n",
            "SigmoidNAG without QG Testing Accuray at 491 iterations is 0.746200000000 with loss: -13829.115269915785\n",
            "SigmoidNAG without QG Testing Accuray at 492 iterations is 0.746100000000 with loss: -13830.008986401832\n",
            "SigmoidNAG without QG Testing Accuray at 493 iterations is 0.746200000000 with loss: -13831.504441289182\n",
            "SigmoidNAG without QG Testing Accuray at 494 iterations is 0.747200000000 with loss: -13833.360417444228\n",
            "SigmoidNAG without QG Testing Accuray at 495 iterations is 0.746600000000 with loss: -13835.251001868281\n",
            "SigmoidNAG without QG Testing Accuray at 496 iterations is 0.747400000000 with loss: -13836.821507894119\n",
            "SigmoidNAG without QG Testing Accuray at 497 iterations is 0.747500000000 with loss: -13837.743204487970\n",
            "SigmoidNAG without QG Testing Accuray at 498 iterations is 0.746200000000 with loss: -13837.755692229002\n",
            "SigmoidNAG without QG Testing Accuray at 499 iterations is 0.745900000000 with loss: -13836.690633449596\n",
            "SigmoidNAG without QG Testing Accuray at 500 iterations is 0.746200000000 with loss: -13834.476627247892\n",
            "X := \n",
            "[[1.         1.123329   1.9208287  ... 0.32571954 1.445418   0.73536414]\n",
            " [1.         1.7383885  0.77516705 ... 0.9904303  0.24941051 0.59759706]\n",
            " [1.         0.87433124 0.621515   ... 1.6415997  0.60842043 2.8593102 ]\n",
            " ...\n",
            " [1.         2.2696862  1.443867   ... 1.3285578  0.15639909 1.0906104 ]\n",
            " [1.         1.8606675  0.08382182 ... 1.2783895  0.27718595 0.41417325]\n",
            " [1.         1.2330134  1.4370509  ... 0.56655186 0.18923545 1.094511  ]]\n",
            "XTX := \n",
            "[[ 50000.          94306.3047812   38431.55174131 ...  48149.51279078\n",
            "   21158.27855737  40222.32641307]\n",
            " [ 94306.3047812  204471.14316375  70496.82307413 ...  97332.64640204\n",
            "   41290.0856747   76193.89731304]\n",
            " [ 38431.55174131  70496.82307413  52157.80990789 ...  33166.84561299\n",
            "   19595.17876829  28057.21579303]\n",
            " ...\n",
            " [ 48149.51279078  97332.64640204  33166.84561299 ...  76263.00483356\n",
            "   23092.28433182  41246.40917907]\n",
            " [ 21158.27855737  41290.0856747   19595.17876829 ...  23092.28433182\n",
            "   18813.36963922  18970.48126696]\n",
            " [ 40222.32641307  76193.89731304  28057.21579303 ...  41246.40917907\n",
            "   18970.48126696  53165.51802755]]\n",
            "invBrow := \n",
            "[[0.00000032 0.00000017 0.00000042 0.00000186 0.00000042 0.00000037\n",
            "  0.00000328 0.00000092 0.00000069 0.00000072 0.00000024 0.00000069\n",
            "  0.00000196 0.00000099 0.00000755 0.00000157 0.00000076 0.000001\n",
            "  0.00000099 0.0000007  0.00000099 0.00000089 0.00000162 0.0000003\n",
            "  0.00000044 0.00000058 0.00000124 0.00000075 0.00000095 0.00000081\n",
            "  0.0000003  0.00000014 0.00000029 0.00000222 0.00000032 0.00000033\n",
            "  0.00000013 0.00000114 0.0000013  0.00000085 0.00000208 0.00000052\n",
            "  0.00000061 0.00000059 0.00000074 0.00000069 0.00000161 0.00000054\n",
            "  0.00000221 0.00000047 0.00000206 0.0000008  0.00000045 0.00000065\n",
            "  0.00000149 0.00000016 0.00000124 0.0000005  0.00000043 0.00000017\n",
            "  0.0000005  0.00000069 0.00000041 0.00000388 0.00000064 0.00000041\n",
            "  0.00000092 0.0000022  0.00000024 0.00000046 0.00000025 0.00000208\n",
            "  0.00000045 0.00000057 0.00000142 0.00000053 0.00000037 0.0000005\n",
            "  0.00000156 0.00000136 0.00000048 0.00000042 0.00000096 0.0000013\n",
            "  0.00000293 0.00000199 0.00000191 0.00000036 0.0000008  0.00000106\n",
            "  0.00000079 0.00000023 0.00000273 0.00000347 0.00000054 0.00000033\n",
            "  0.00000097 0.00000031 0.00000195 0.00000049 0.00000074 0.00000018\n",
            "  0.00000073 0.00000033 0.0000008  0.00000051 0.00000024 0.00000062\n",
            "  0.00000058 0.00000027 0.00000057 0.00000259 0.00000038 0.00000046\n",
            "  0.00000075 0.00000022 0.00000032 0.00000018 0.00000054 0.00000115\n",
            "  0.00000007 0.00000076 0.00000044 0.00000022 0.00000134 0.00000189\n",
            "  0.00000044 0.00000057 0.00000155 0.00000371 0.00000085 0.00000017\n",
            "  0.00000065 0.00000204 0.00000028 0.00000057 0.00000032 0.00000024\n",
            "  0.00000027 0.0000007  0.00000107 0.00000084 0.00000179 0.00000018\n",
            "  0.00000042 0.00000052 0.00000038 0.00000082 0.00000059 0.00000033\n",
            "  0.00000083 0.00000078 0.00000134 0.00000237 0.00000092 0.00000032\n",
            "  0.00000122 0.00000105 0.00000125 0.00000039 0.00000165 0.00000133\n",
            "  0.00000018 0.0000008  0.00000071 0.00000085 0.00000206 0.00000087\n",
            "  0.00000096 0.00000044 0.00000017 0.0000035  0.00000062 0.00000093\n",
            "  0.00000074 0.00000058 0.00000152 0.0000007  0.00000075 0.00000015\n",
            "  0.00000091 0.00000174 0.00000025 0.00000064 0.00000103 0.00000102\n",
            "  0.00000075 0.00000085 0.0000005  0.00000205 0.00000059 0.00000062\n",
            "  0.00000517 0.00000055 0.00000057 0.00000027 0.0000005  0.00000053\n",
            "  0.00000174 0.00000136 0.00000038 0.00000048 0.00000013 0.00000065\n",
            "  0.00000227 0.00000021 0.00000093 0.00000045 0.00000106 0.00000107\n",
            "  0.00000094 0.00000153 0.000002   0.00000104 0.00000053 0.00000148\n",
            "  0.0000007  0.00000046 0.00000145 0.0000005  0.00000022 0.00000051\n",
            "  0.00000047 0.00000163 0.00000324 0.0000013  0.00000048 0.00000027\n",
            "  0.00000039 0.00000137 0.00000126 0.00000045 0.00000041 0.00000043\n",
            "  0.00000034 0.00000284 0.00000058 0.00000052 0.00000054 0.00000073\n",
            "  0.00000134 0.00000072 0.00000077 0.00000066 0.00000052 0.00000177\n",
            "  0.00000035 0.00000044 0.00000116 0.00000324 0.00000033 0.00000127\n",
            "  0.00000097 0.0000003  0.00000033 0.00000056 0.00000087 0.0000036\n",
            "  0.00000102 0.00000145 0.00000075 0.00000238 0.00000054 0.00000162\n",
            "  0.00000012 0.00000052 0.00000054 0.00000054 0.00000053 0.00000172\n",
            "  0.00000053 0.00000061 0.00000043 0.00000073 0.00000057 0.00000035\n",
            "  0.00000064 0.00000035 0.00000026 0.00000103 0.00000119 0.00000038\n",
            "  0.00000033 0.00000039 0.00000052 0.00000129 0.00000095 0.00000032\n",
            "  0.00000046 0.00000121 0.00000198 0.0000006  0.00000071 0.00000027\n",
            "  0.00000085 0.00000067 0.00000061 0.0000003  0.00000157 0.00000055\n",
            "  0.0000033  0.00000021 0.00000041 0.00000018 0.00000125 0.0000004\n",
            "  0.00000166 0.0000005  0.00000094 0.00000063 0.00000221 0.00000044\n",
            "  0.00000169 0.0000013  0.00000048 0.00000036 0.00000053 0.00000049\n",
            "  0.0000004  0.00000078 0.00000013 0.0000003  0.00000066 0.00000081\n",
            "  0.00000545 0.0000017  0.00000225 0.0000011  0.0000007  0.0000004\n",
            "  0.00000023 0.0000004  0.00000105 0.00000031 0.00000044 0.00000109\n",
            "  0.00000067 0.00000022 0.00000147 0.00000203 0.0000003  0.00000047\n",
            "  0.00000032 0.00000157 0.00000249 0.00000256 0.00000193 0.00000116\n",
            "  0.00000062 0.00000168 0.00000056 0.00000206 0.00000081 0.00000075\n",
            "  0.00000156 0.00000025 0.00000118 0.00000079 0.00000111 0.0000016\n",
            "  0.00000049 0.0000016  0.00000047 0.00000216 0.00000059 0.00000015\n",
            "  0.00000027 0.00000037 0.00000011 0.00000075 0.00000142 0.00000029\n",
            "  0.00000014 0.00000061 0.00000049 0.00000047 0.00000026 0.00000137\n",
            "  0.00000039 0.00000083 0.00000059 0.00000003 0.00000067 0.00000191\n",
            "  0.00000052 0.00000118 0.00000081 0.00000059 0.00000087 0.00000048\n",
            "  0.00000021 0.00000051 0.00000058 0.00000076 0.00000052 0.00000054\n",
            "  0.00000081 0.00000016 0.00000031 0.00000071 0.00000038]]\n",
            "SigmoidNAG with QG Testing Accuray at   1 iterations is 0.321400000000 with loss: -68696.944174062679\n",
            "SigmoidNAG with QG Testing Accuray at   2 iterations is 0.445500000000 with loss: -58312.412220309299\n",
            "SigmoidNAG with QG Testing Accuray at   3 iterations is 0.437400000000 with loss: -33173.496941406716\n",
            "SigmoidNAG with QG Testing Accuray at   4 iterations is 0.438900000000 with loss: -32499.019076081542\n",
            "SigmoidNAG with QG Testing Accuray at   5 iterations is 0.438400000000 with loss: -32309.251983687001\n",
            "SigmoidNAG with QG Testing Accuray at   6 iterations is 0.443300000000 with loss: -31590.205965852481\n",
            "SigmoidNAG with QG Testing Accuray at   7 iterations is 0.453500000000 with loss: -30635.880420469406\n",
            "SigmoidNAG with QG Testing Accuray at   8 iterations is 0.472300000000 with loss: -29762.312099063125\n",
            "SigmoidNAG with QG Testing Accuray at   9 iterations is 0.497200000000 with loss: -29082.634361014494\n",
            "SigmoidNAG with QG Testing Accuray at  10 iterations is 0.526700000000 with loss: -28488.222815670142\n",
            "SigmoidNAG with QG Testing Accuray at  11 iterations is 0.545000000000 with loss: -27836.554677528184\n",
            "SigmoidNAG with QG Testing Accuray at  12 iterations is 0.558800000000 with loss: -27128.805304103036\n",
            "SigmoidNAG with QG Testing Accuray at  13 iterations is 0.562900000000 with loss: -26454.680106701860\n",
            "SigmoidNAG with QG Testing Accuray at  14 iterations is 0.565300000000 with loss: -25857.577742934642\n",
            "SigmoidNAG with QG Testing Accuray at  15 iterations is 0.566700000000 with loss: -25316.467283673330\n",
            "SigmoidNAG with QG Testing Accuray at  16 iterations is 0.568300000000 with loss: -24802.668213190984\n",
            "SigmoidNAG with QG Testing Accuray at  17 iterations is 0.571400000000 with loss: -24313.533117704486\n",
            "SigmoidNAG with QG Testing Accuray at  18 iterations is 0.575000000000 with loss: -23863.263717905265\n",
            "SigmoidNAG with QG Testing Accuray at  19 iterations is 0.578600000000 with loss: -23459.817926307096\n",
            "SigmoidNAG with QG Testing Accuray at  20 iterations is 0.584000000000 with loss: -23095.881553894811\n",
            "SigmoidNAG with QG Testing Accuray at  21 iterations is 0.588100000000 with loss: -22758.322047844253\n",
            "SigmoidNAG with QG Testing Accuray at  22 iterations is 0.590400000000 with loss: -22440.736991485915\n",
            "SigmoidNAG with QG Testing Accuray at  23 iterations is 0.593400000000 with loss: -22144.993472562586\n",
            "SigmoidNAG with QG Testing Accuray at  24 iterations is 0.595300000000 with loss: -21873.706946291448\n",
            "SigmoidNAG with QG Testing Accuray at  25 iterations is 0.597400000000 with loss: -21624.697383025057\n",
            "SigmoidNAG with QG Testing Accuray at  26 iterations is 0.598700000000 with loss: -21392.487997977343\n",
            "SigmoidNAG with QG Testing Accuray at  27 iterations is 0.601900000000 with loss: -21172.846000449899\n",
            "SigmoidNAG with QG Testing Accuray at  28 iterations is 0.603400000000 with loss: -20964.869250359483\n",
            "SigmoidNAG with QG Testing Accuray at  29 iterations is 0.604600000000 with loss: -20769.365737955679\n",
            "SigmoidNAG with QG Testing Accuray at  30 iterations is 0.608300000000 with loss: -20586.079164294912\n",
            "SigmoidNAG with QG Testing Accuray at  31 iterations is 0.611200000000 with loss: -20412.709527038754\n",
            "SigmoidNAG with QG Testing Accuray at  32 iterations is 0.613600000000 with loss: -20246.332478507087\n",
            "SigmoidNAG with QG Testing Accuray at  33 iterations is 0.616500000000 with loss: -20085.350798697062\n",
            "SigmoidNAG with QG Testing Accuray at  34 iterations is 0.620000000000 with loss: -19929.902596444274\n",
            "SigmoidNAG with QG Testing Accuray at  35 iterations is 0.622400000000 with loss: -19780.609020152853\n",
            "SigmoidNAG with QG Testing Accuray at  36 iterations is 0.624000000000 with loss: -19637.253997455176\n",
            "SigmoidNAG with QG Testing Accuray at  37 iterations is 0.625700000000 with loss: -19498.693493108211\n",
            "SigmoidNAG with QG Testing Accuray at  38 iterations is 0.628200000000 with loss: -19363.783651353900\n",
            "SigmoidNAG with QG Testing Accuray at  39 iterations is 0.630300000000 with loss: -19232.216443887668\n",
            "SigmoidNAG with QG Testing Accuray at  40 iterations is 0.632800000000 with loss: -19104.504171237368\n",
            "SigmoidNAG with QG Testing Accuray at  41 iterations is 0.634800000000 with loss: -18981.270509332990\n",
            "SigmoidNAG with QG Testing Accuray at  42 iterations is 0.637700000000 with loss: -18862.575505093966\n",
            "SigmoidNAG with QG Testing Accuray at  43 iterations is 0.640400000000 with loss: -18747.851399628551\n",
            "SigmoidNAG with QG Testing Accuray at  44 iterations is 0.643300000000 with loss: -18636.406620096361\n",
            "SigmoidNAG with QG Testing Accuray at  45 iterations is 0.645900000000 with loss: -18527.956396474023\n",
            "SigmoidNAG with QG Testing Accuray at  46 iterations is 0.648700000000 with loss: -18422.694138421190\n",
            "SigmoidNAG with QG Testing Accuray at  47 iterations is 0.650800000000 with loss: -18320.914324860547\n",
            "SigmoidNAG with QG Testing Accuray at  48 iterations is 0.652700000000 with loss: -18222.607603620356\n",
            "SigmoidNAG with QG Testing Accuray at  49 iterations is 0.655200000000 with loss: -18127.399870401499\n",
            "SigmoidNAG with QG Testing Accuray at  50 iterations is 0.656700000000 with loss: -18034.832108501047\n",
            "SigmoidNAG with QG Testing Accuray at  51 iterations is 0.658400000000 with loss: -17944.681755986963\n",
            "SigmoidNAG with QG Testing Accuray at  52 iterations is 0.661200000000 with loss: -17857.044965631721\n",
            "SigmoidNAG with QG Testing Accuray at  53 iterations is 0.663000000000 with loss: -17772.145222367566\n",
            "SigmoidNAG with QG Testing Accuray at  54 iterations is 0.665700000000 with loss: -17690.063372928325\n",
            "SigmoidNAG with QG Testing Accuray at  55 iterations is 0.667400000000 with loss: -17610.620020992086\n",
            "SigmoidNAG with QG Testing Accuray at  56 iterations is 0.669200000000 with loss: -17533.483965473402\n",
            "SigmoidNAG with QG Testing Accuray at  57 iterations is 0.670700000000 with loss: -17458.381832898041\n",
            "SigmoidNAG with QG Testing Accuray at  58 iterations is 0.671700000000 with loss: -17385.216517697569\n",
            "SigmoidNAG with QG Testing Accuray at  59 iterations is 0.673400000000 with loss: -17314.010033182421\n",
            "SigmoidNAG with QG Testing Accuray at  60 iterations is 0.674700000000 with loss: -17244.752887704031\n",
            "SigmoidNAG with QG Testing Accuray at  61 iterations is 0.675800000000 with loss: -17177.310349026066\n",
            "SigmoidNAG with QG Testing Accuray at  62 iterations is 0.677300000000 with loss: -17111.461398943251\n",
            "SigmoidNAG with QG Testing Accuray at  63 iterations is 0.678400000000 with loss: -17047.019465982255\n",
            "SigmoidNAG with QG Testing Accuray at  64 iterations is 0.679600000000 with loss: -16983.922607048131\n",
            "SigmoidNAG with QG Testing Accuray at  65 iterations is 0.680800000000 with loss: -16922.222177489388\n",
            "SigmoidNAG with QG Testing Accuray at  66 iterations is 0.681800000000 with loss: -16861.990639237705\n",
            "SigmoidNAG with QG Testing Accuray at  67 iterations is 0.682700000000 with loss: -16803.230681003854\n",
            "SigmoidNAG with QG Testing Accuray at  68 iterations is 0.685000000000 with loss: -16745.855968155702\n",
            "SigmoidNAG with QG Testing Accuray at  69 iterations is 0.687100000000 with loss: -16689.747153317418\n",
            "SigmoidNAG with QG Testing Accuray at  70 iterations is 0.687900000000 with loss: -16634.824970138321\n",
            "SigmoidNAG with QG Testing Accuray at  71 iterations is 0.689700000000 with loss: -16581.076177465446\n",
            "SigmoidNAG with QG Testing Accuray at  72 iterations is 0.690300000000 with loss: -16528.517366318403\n",
            "SigmoidNAG with QG Testing Accuray at  73 iterations is 0.691300000000 with loss: -16477.137560836607\n",
            "SigmoidNAG with QG Testing Accuray at  74 iterations is 0.692600000000 with loss: -16426.873614379172\n",
            "SigmoidNAG with QG Testing Accuray at  75 iterations is 0.693400000000 with loss: -16377.637020366859\n",
            "SigmoidNAG with QG Testing Accuray at  76 iterations is 0.694200000000 with loss: -16329.364211993459\n",
            "SigmoidNAG with QG Testing Accuray at  77 iterations is 0.695400000000 with loss: -16282.045558990354\n",
            "SigmoidNAG with QG Testing Accuray at  78 iterations is 0.696000000000 with loss: -16235.710444953786\n",
            "SigmoidNAG with QG Testing Accuray at  79 iterations is 0.696600000000 with loss: -16190.383613531129\n",
            "SigmoidNAG with QG Testing Accuray at  80 iterations is 0.698200000000 with loss: -16146.049397124225\n",
            "SigmoidNAG with QG Testing Accuray at  81 iterations is 0.698700000000 with loss: -16102.650684091121\n",
            "SigmoidNAG with QG Testing Accuray at  82 iterations is 0.699600000000 with loss: -16060.119443019548\n",
            "SigmoidNAG with QG Testing Accuray at  83 iterations is 0.700300000000 with loss: -16018.411032350194\n",
            "SigmoidNAG with QG Testing Accuray at  84 iterations is 0.700400000000 with loss: -15977.514565368630\n",
            "SigmoidNAG with QG Testing Accuray at  85 iterations is 0.701300000000 with loss: -15937.433984608151\n",
            "SigmoidNAG with QG Testing Accuray at  86 iterations is 0.701700000000 with loss: -15898.158771130702\n",
            "SigmoidNAG with QG Testing Accuray at  87 iterations is 0.703300000000 with loss: -15859.649400920218\n",
            "SigmoidNAG with QG Testing Accuray at  88 iterations is 0.704600000000 with loss: -15821.847909543818\n",
            "SigmoidNAG with QG Testing Accuray at  89 iterations is 0.704500000000 with loss: -15784.702755494882\n",
            "SigmoidNAG with QG Testing Accuray at  90 iterations is 0.705300000000 with loss: -15748.187190586053\n",
            "SigmoidNAG with QG Testing Accuray at  91 iterations is 0.705600000000 with loss: -15712.297783878206\n",
            "SigmoidNAG with QG Testing Accuray at  92 iterations is 0.706600000000 with loss: -15677.036473628879\n",
            "SigmoidNAG with QG Testing Accuray at  93 iterations is 0.707300000000 with loss: -15642.391614130418\n",
            "SigmoidNAG with QG Testing Accuray at  94 iterations is 0.707700000000 with loss: -15608.332399788718\n",
            "SigmoidNAG with QG Testing Accuray at  95 iterations is 0.707700000000 with loss: -15574.819333122181\n",
            "SigmoidNAG with QG Testing Accuray at  96 iterations is 0.708900000000 with loss: -15541.821186720497\n",
            "SigmoidNAG with QG Testing Accuray at  97 iterations is 0.708600000000 with loss: -15509.325430694269\n",
            "SigmoidNAG with QG Testing Accuray at  98 iterations is 0.708800000000 with loss: -15477.335703762983\n",
            "SigmoidNAG with QG Testing Accuray at  99 iterations is 0.709400000000 with loss: -15445.860145845634\n",
            "SigmoidNAG with QG Testing Accuray at 100 iterations is 0.710400000000 with loss: -15414.900089611681\n",
            "SigmoidNAG with QG Testing Accuray at 101 iterations is 0.711100000000 with loss: -15384.446358776391\n",
            "SigmoidNAG with QG Testing Accuray at 102 iterations is 0.711900000000 with loss: -15354.483448612527\n",
            "SigmoidNAG with QG Testing Accuray at 103 iterations is 0.712700000000 with loss: -15324.996275114892\n",
            "SigmoidNAG with QG Testing Accuray at 104 iterations is 0.713200000000 with loss: -15295.973813170549\n",
            "SigmoidNAG with QG Testing Accuray at 105 iterations is 0.714000000000 with loss: -15267.407865286670\n",
            "SigmoidNAG with QG Testing Accuray at 106 iterations is 0.714800000000 with loss: -15239.289480791273\n",
            "SigmoidNAG with QG Testing Accuray at 107 iterations is 0.715300000000 with loss: -15211.606828848551\n",
            "SigmoidNAG with QG Testing Accuray at 108 iterations is 0.716200000000 with loss: -15184.346379292036\n",
            "SigmoidNAG with QG Testing Accuray at 109 iterations is 0.717400000000 with loss: -15157.496325151546\n",
            "SigmoidNAG with QG Testing Accuray at 110 iterations is 0.718200000000 with loss: -15131.049756653658\n",
            "SigmoidNAG with QG Testing Accuray at 111 iterations is 0.718200000000 with loss: -15105.005794505791\n",
            "SigmoidNAG with QG Testing Accuray at 112 iterations is 0.718900000000 with loss: -15079.368561328976\n",
            "SigmoidNAG with QG Testing Accuray at 113 iterations is 0.719200000000 with loss: -15054.144984233106\n",
            "SigmoidNAG with QG Testing Accuray at 114 iterations is 0.720000000000 with loss: -15029.342382576839\n",
            "SigmoidNAG with QG Testing Accuray at 115 iterations is 0.720400000000 with loss: -15004.966131025323\n",
            "SigmoidNAG with QG Testing Accuray at 116 iterations is 0.720500000000 with loss: -14981.017317467506\n",
            "SigmoidNAG with QG Testing Accuray at 117 iterations is 0.720900000000 with loss: -14957.490639435702\n",
            "SigmoidNAG with QG Testing Accuray at 118 iterations is 0.721400000000 with loss: -14934.373359056091\n",
            "SigmoidNAG with QG Testing Accuray at 119 iterations is 0.721500000000 with loss: -14911.646172847730\n",
            "SigmoidNAG with QG Testing Accuray at 120 iterations is 0.721200000000 with loss: -14889.286050535959\n",
            "SigmoidNAG with QG Testing Accuray at 121 iterations is 0.721900000000 with loss: -14867.270004506045\n",
            "SigmoidNAG with QG Testing Accuray at 122 iterations is 0.723000000000 with loss: -14845.578317702380\n",
            "SigmoidNAG with QG Testing Accuray at 123 iterations is 0.723800000000 with loss: -14824.196334992619\n",
            "SigmoidNAG with QG Testing Accuray at 124 iterations is 0.724400000000 with loss: -14803.114963534483\n",
            "SigmoidNAG with QG Testing Accuray at 125 iterations is 0.725200000000 with loss: -14782.330587134038\n",
            "SigmoidNAG with QG Testing Accuray at 126 iterations is 0.725800000000 with loss: -14761.844801376830\n",
            "SigmoidNAG with QG Testing Accuray at 127 iterations is 0.726800000000 with loss: -14741.663657679943\n",
            "SigmoidNAG with QG Testing Accuray at 128 iterations is 0.726800000000 with loss: -14721.795793213729\n",
            "SigmoidNAG with QG Testing Accuray at 129 iterations is 0.727200000000 with loss: -14702.249257442907\n",
            "SigmoidNAG with QG Testing Accuray at 130 iterations is 0.728100000000 with loss: -14683.027749166400\n",
            "SigmoidNAG with QG Testing Accuray at 131 iterations is 0.729100000000 with loss: -14664.127609504123\n",
            "SigmoidNAG with QG Testing Accuray at 132 iterations is 0.729000000000 with loss: -14645.536764896124\n",
            "SigmoidNAG with QG Testing Accuray at 133 iterations is 0.729900000000 with loss: -14627.235941928750\n",
            "SigmoidNAG with QG Testing Accuray at 134 iterations is 0.730400000000 with loss: -14609.201474359201\n",
            "SigmoidNAG with QG Testing Accuray at 135 iterations is 0.729900000000 with loss: -14591.408579825686\n",
            "SigmoidNAG with QG Testing Accuray at 136 iterations is 0.730500000000 with loss: -14573.834296819550\n",
            "SigmoidNAG with QG Testing Accuray at 137 iterations is 0.730800000000 with loss: -14556.459921013031\n",
            "SigmoidNAG with QG Testing Accuray at 138 iterations is 0.731700000000 with loss: -14539.273114065569\n",
            "SigmoidNAG with QG Testing Accuray at 139 iterations is 0.732400000000 with loss: -14522.269586291413\n",
            "SigmoidNAG with QG Testing Accuray at 140 iterations is 0.732200000000 with loss: -14505.453738964745\n",
            "SigmoidNAG with QG Testing Accuray at 141 iterations is 0.732100000000 with loss: -14488.837494174533\n",
            "SigmoidNAG with QG Testing Accuray at 142 iterations is 0.732300000000 with loss: -14472.437068554829\n",
            "SigmoidNAG with QG Testing Accuray at 143 iterations is 0.732000000000 with loss: -14456.268391413643\n",
            "SigmoidNAG with QG Testing Accuray at 144 iterations is 0.731800000000 with loss: -14440.342577485264\n",
            "SigmoidNAG with QG Testing Accuray at 145 iterations is 0.731900000000 with loss: -14424.662858590067\n",
            "SigmoidNAG with QG Testing Accuray at 146 iterations is 0.732000000000 with loss: -14409.223652175026\n",
            "SigmoidNAG with QG Testing Accuray at 147 iterations is 0.732300000000 with loss: -14394.011527295077\n",
            "SigmoidNAG with QG Testing Accuray at 148 iterations is 0.732600000000 with loss: -14379.007308232496\n",
            "SigmoidNAG with QG Testing Accuray at 149 iterations is 0.733000000000 with loss: -14364.188660558388\n",
            "SigmoidNAG with QG Testing Accuray at 150 iterations is 0.732900000000 with loss: -14349.532938483369\n",
            "SigmoidNAG with QG Testing Accuray at 151 iterations is 0.733000000000 with loss: -14335.020306599085\n",
            "SigmoidNAG with QG Testing Accuray at 152 iterations is 0.733100000000 with loss: -14320.636909597801\n",
            "SigmoidNAG with QG Testing Accuray at 153 iterations is 0.733400000000 with loss: -14306.377376321800\n",
            "SigmoidNAG with QG Testing Accuray at 154 iterations is 0.733400000000 with loss: -14292.245713370685\n",
            "SigmoidNAG with QG Testing Accuray at 155 iterations is 0.733800000000 with loss: -14278.254014234115\n",
            "SigmoidNAG with QG Testing Accuray at 156 iterations is 0.734000000000 with loss: -14264.419234701305\n",
            "SigmoidNAG with QG Testing Accuray at 157 iterations is 0.734300000000 with loss: -14250.759055579887\n",
            "SigmoidNAG with QG Testing Accuray at 158 iterations is 0.734600000000 with loss: -14237.288065826544\n",
            "SigmoidNAG with QG Testing Accuray at 159 iterations is 0.734600000000 with loss: -14224.015075464480\n",
            "SigmoidNAG with QG Testing Accuray at 160 iterations is 0.734900000000 with loss: -14210.941674401931\n",
            "SigmoidNAG with QG Testing Accuray at 161 iterations is 0.735300000000 with loss: -14198.061729355726\n",
            "SigmoidNAG with QG Testing Accuray at 162 iterations is 0.736000000000 with loss: -14185.361616914595\n",
            "SigmoidNAG with QG Testing Accuray at 163 iterations is 0.735700000000 with loss: -14172.821418793115\n",
            "SigmoidNAG with QG Testing Accuray at 164 iterations is 0.735900000000 with loss: -14160.417507476370\n",
            "SigmoidNAG with QG Testing Accuray at 165 iterations is 0.736500000000 with loss: -14148.126563147012\n",
            "SigmoidNAG with QG Testing Accuray at 166 iterations is 0.736700000000 with loss: -14135.930227330331\n",
            "SigmoidNAG with QG Testing Accuray at 167 iterations is 0.737300000000 with loss: -14123.818913813453\n",
            "SigmoidNAG with QG Testing Accuray at 168 iterations is 0.737500000000 with loss: -14111.793348086043\n",
            "SigmoidNAG with QG Testing Accuray at 169 iterations is 0.737600000000 with loss: -14099.863290143814\n",
            "SigmoidNAG with QG Testing Accuray at 170 iterations is 0.738700000000 with loss: -14088.044113903090\n",
            "SigmoidNAG with QG Testing Accuray at 171 iterations is 0.739700000000 with loss: -14076.352735968756\n",
            "SigmoidNAG with QG Testing Accuray at 172 iterations is 0.740100000000 with loss: -14064.804320652815\n",
            "SigmoidNAG with QG Testing Accuray at 173 iterations is 0.740700000000 with loss: -14053.410363585746\n",
            "SigmoidNAG with QG Testing Accuray at 174 iterations is 0.741000000000 with loss: -14042.177798420902\n",
            "SigmoidNAG with QG Testing Accuray at 175 iterations is 0.741200000000 with loss: -14031.108358802465\n",
            "SigmoidNAG with QG Testing Accuray at 176 iterations is 0.741800000000 with loss: -14020.197804732772\n",
            "SigmoidNAG with QG Testing Accuray at 177 iterations is 0.741600000000 with loss: -14009.435410091244\n",
            "SigmoidNAG with QG Testing Accuray at 178 iterations is 0.741900000000 with loss: -13998.804620328283\n",
            "SigmoidNAG with QG Testing Accuray at 179 iterations is 0.742200000000 with loss: -13988.285525525112\n",
            "SigmoidNAG with QG Testing Accuray at 180 iterations is 0.742400000000 with loss: -13977.858870876904\n",
            "SigmoidNAG with QG Testing Accuray at 181 iterations is 0.743000000000 with loss: -13967.510360081835\n",
            "SigmoidNAG with QG Testing Accuray at 182 iterations is 0.743200000000 with loss: -13957.233668754861\n",
            "SigmoidNAG with QG Testing Accuray at 183 iterations is 0.743200000000 with loss: -13947.031122511920\n",
            "SigmoidNAG with QG Testing Accuray at 184 iterations is 0.743300000000 with loss: -13936.912061294024\n",
            "SigmoidNAG with QG Testing Accuray at 185 iterations is 0.743800000000 with loss: -13926.889850585558\n",
            "SigmoidNAG with QG Testing Accuray at 186 iterations is 0.744300000000 with loss: -13916.978788270659\n",
            "SigmoidNAG with QG Testing Accuray at 187 iterations is 0.744800000000 with loss: -13907.191742353643\n",
            "SigmoidNAG with QG Testing Accuray at 188 iterations is 0.744900000000 with loss: -13897.538645275132\n",
            "SigmoidNAG with QG Testing Accuray at 189 iterations is 0.745200000000 with loss: -13888.025495966196\n",
            "SigmoidNAG with QG Testing Accuray at 190 iterations is 0.745700000000 with loss: -13878.653560982098\n",
            "SigmoidNAG with QG Testing Accuray at 191 iterations is 0.745900000000 with loss: -13869.418866878177\n",
            "SigmoidNAG with QG Testing Accuray at 192 iterations is 0.746000000000 with loss: -13860.312411472110\n",
            "SigmoidNAG with QG Testing Accuray at 193 iterations is 0.746300000000 with loss: -13851.321450791167\n",
            "SigmoidNAG with QG Testing Accuray at 194 iterations is 0.746300000000 with loss: -13842.431758200686\n",
            "SigmoidNAG with QG Testing Accuray at 195 iterations is 0.746400000000 with loss: -13833.630232488835\n",
            "SigmoidNAG with QG Testing Accuray at 196 iterations is 0.746600000000 with loss: -13824.907039873346\n",
            "SigmoidNAG with QG Testing Accuray at 197 iterations is 0.746700000000 with loss: -13816.256731881058\n",
            "SigmoidNAG with QG Testing Accuray at 198 iterations is 0.746700000000 with loss: -13807.678293443858\n",
            "SigmoidNAG with QG Testing Accuray at 199 iterations is 0.746700000000 with loss: -13799.174480516951\n",
            "SigmoidNAG with QG Testing Accuray at 200 iterations is 0.746800000000 with loss: -13790.750872644789\n",
            "SigmoidNAG with QG Testing Accuray at 201 iterations is 0.747000000000 with loss: -13782.414836407102\n",
            "SigmoidNAG with QG Testing Accuray at 202 iterations is 0.747100000000 with loss: -13774.174336560865\n",
            "SigmoidNAG with QG Testing Accuray at 203 iterations is 0.747700000000 with loss: -13766.036501535835\n",
            "SigmoidNAG with QG Testing Accuray at 204 iterations is 0.747800000000 with loss: -13758.006085363746\n",
            "SigmoidNAG with QG Testing Accuray at 205 iterations is 0.747900000000 with loss: -13750.084261195403\n",
            "SigmoidNAG with QG Testing Accuray at 206 iterations is 0.747800000000 with loss: -13742.268253399719\n",
            "SigmoidNAG with QG Testing Accuray at 207 iterations is 0.748000000000 with loss: -13734.552035077624\n",
            "SigmoidNAG with QG Testing Accuray at 208 iterations is 0.748200000000 with loss: -13726.927835958162\n",
            "SigmoidNAG with QG Testing Accuray at 209 iterations is 0.748400000000 with loss: -13719.387832601436\n",
            "SigmoidNAG with QG Testing Accuray at 210 iterations is 0.748800000000 with loss: -13711.925379125629\n",
            "SigmoidNAG with QG Testing Accuray at 211 iterations is 0.748800000000 with loss: -13704.535485402734\n",
            "SigmoidNAG with QG Testing Accuray at 212 iterations is 0.749200000000 with loss: -13697.214713043217\n",
            "SigmoidNAG with QG Testing Accuray at 213 iterations is 0.749300000000 with loss: -13689.960919384341\n",
            "SigmoidNAG with QG Testing Accuray at 214 iterations is 0.749600000000 with loss: -13682.773190584225\n",
            "SigmoidNAG with QG Testing Accuray at 215 iterations is 0.749400000000 with loss: -13675.651971107964\n",
            "SigmoidNAG with QG Testing Accuray at 216 iterations is 0.749600000000 with loss: -13668.599106649441\n",
            "SigmoidNAG with QG Testing Accuray at 217 iterations is 0.749900000000 with loss: -13661.617496892628\n",
            "SigmoidNAG with QG Testing Accuray at 218 iterations is 0.750000000000 with loss: -13654.710315116099\n",
            "SigmoidNAG with QG Testing Accuray at 219 iterations is 0.749900000000 with loss: -13647.880082845213\n",
            "SigmoidNAG with QG Testing Accuray at 220 iterations is 0.750000000000 with loss: -13641.128030164011\n",
            "SigmoidNAG with QG Testing Accuray at 221 iterations is 0.749900000000 with loss: -13634.454014978312\n",
            "SigmoidNAG with QG Testing Accuray at 222 iterations is 0.750200000000 with loss: -13627.856933537239\n",
            "SigmoidNAG with QG Testing Accuray at 223 iterations is 0.750500000000 with loss: -13621.335280122788\n",
            "SigmoidNAG with QG Testing Accuray at 224 iterations is 0.750700000000 with loss: -13614.887487368289\n",
            "SigmoidNAG with QG Testing Accuray at 225 iterations is 0.750600000000 with loss: -13608.511907699798\n",
            "SigmoidNAG with QG Testing Accuray at 226 iterations is 0.751000000000 with loss: -13602.206591456335\n",
            "SigmoidNAG with QG Testing Accuray at 227 iterations is 0.751200000000 with loss: -13595.969161037896\n",
            "SigmoidNAG with QG Testing Accuray at 228 iterations is 0.751200000000 with loss: -13589.796975767113\n",
            "SigmoidNAG with QG Testing Accuray at 229 iterations is 0.751200000000 with loss: -13583.687528199562\n",
            "SigmoidNAG with QG Testing Accuray at 230 iterations is 0.751300000000 with loss: -13577.638814449047\n",
            "SigmoidNAG with QG Testing Accuray at 231 iterations is 0.751000000000 with loss: -13571.649436080826\n",
            "SigmoidNAG with QG Testing Accuray at 232 iterations is 0.751100000000 with loss: -13565.718408677281\n",
            "SigmoidNAG with QG Testing Accuray at 233 iterations is 0.751400000000 with loss: -13559.844890255357\n",
            "SigmoidNAG with QG Testing Accuray at 234 iterations is 0.751400000000 with loss: -13554.028111325379\n",
            "SigmoidNAG with QG Testing Accuray at 235 iterations is 0.751700000000 with loss: -13548.267623920907\n",
            "SigmoidNAG with QG Testing Accuray at 236 iterations is 0.751900000000 with loss: -13542.563710112734\n",
            "SigmoidNAG with QG Testing Accuray at 237 iterations is 0.752000000000 with loss: -13536.917609035805\n",
            "SigmoidNAG with QG Testing Accuray at 238 iterations is 0.752100000000 with loss: -13531.331282339528\n",
            "SigmoidNAG with QG Testing Accuray at 239 iterations is 0.752700000000 with loss: -13525.806708895521\n",
            "SigmoidNAG with QG Testing Accuray at 240 iterations is 0.753000000000 with loss: -13520.345001522410\n",
            "SigmoidNAG with QG Testing Accuray at 241 iterations is 0.752800000000 with loss: -13514.945768447424\n",
            "SigmoidNAG with QG Testing Accuray at 242 iterations is 0.753100000000 with loss: -13509.607010481235\n",
            "SigmoidNAG with QG Testing Accuray at 243 iterations is 0.753300000000 with loss: -13504.325545833435\n",
            "SigmoidNAG with QG Testing Accuray at 244 iterations is 0.753600000000 with loss: -13499.097686517644\n",
            "SigmoidNAG with QG Testing Accuray at 245 iterations is 0.753700000000 with loss: -13493.919821477264\n",
            "SigmoidNAG with QG Testing Accuray at 246 iterations is 0.753700000000 with loss: -13488.788718104082\n",
            "SigmoidNAG with QG Testing Accuray at 247 iterations is 0.753700000000 with loss: -13483.701601661762\n",
            "SigmoidNAG with QG Testing Accuray at 248 iterations is 0.753600000000 with loss: -13478.656227001737\n",
            "SigmoidNAG with QG Testing Accuray at 249 iterations is 0.753500000000 with loss: -13473.651117191121\n",
            "SigmoidNAG with QG Testing Accuray at 250 iterations is 0.753800000000 with loss: -13468.685949422641\n",
            "SigmoidNAG with QG Testing Accuray at 251 iterations is 0.753900000000 with loss: -13463.761869342992\n",
            "SigmoidNAG with QG Testing Accuray at 252 iterations is 0.753700000000 with loss: -13458.881459154756\n",
            "SigmoidNAG with QG Testing Accuray at 253 iterations is 0.753900000000 with loss: -13454.048217028958\n",
            "SigmoidNAG with QG Testing Accuray at 254 iterations is 0.753800000000 with loss: -13449.265645037794\n",
            "SigmoidNAG with QG Testing Accuray at 255 iterations is 0.753700000000 with loss: -13444.536243324887\n",
            "SigmoidNAG with QG Testing Accuray at 256 iterations is 0.753700000000 with loss: -13439.860755459953\n",
            "SigmoidNAG with QG Testing Accuray at 257 iterations is 0.754200000000 with loss: -13435.237892423425\n",
            "SigmoidNAG with QG Testing Accuray at 258 iterations is 0.754500000000 with loss: -13430.664560103482\n",
            "SigmoidNAG with QG Testing Accuray at 259 iterations is 0.754500000000 with loss: -13426.136446624652\n",
            "SigmoidNAG with QG Testing Accuray at 260 iterations is 0.754800000000 with loss: -13421.648760711818\n",
            "SigmoidNAG with QG Testing Accuray at 261 iterations is 0.754900000000 with loss: -13417.196948163997\n",
            "SigmoidNAG with QG Testing Accuray at 262 iterations is 0.755000000000 with loss: -13412.777291516608\n",
            "SigmoidNAG with QG Testing Accuray at 263 iterations is 0.754800000000 with loss: -13408.387358661515\n",
            "SigmoidNAG with QG Testing Accuray at 264 iterations is 0.755000000000 with loss: -13404.026287239340\n",
            "SigmoidNAG with QG Testing Accuray at 265 iterations is 0.755200000000 with loss: -13399.694883346498\n",
            "SigmoidNAG with QG Testing Accuray at 266 iterations is 0.755300000000 with loss: -13395.395507186329\n",
            "SigmoidNAG with QG Testing Accuray at 267 iterations is 0.755300000000 with loss: -13391.131731054069\n",
            "SigmoidNAG with QG Testing Accuray at 268 iterations is 0.755100000000 with loss: -13386.907783790546\n",
            "SigmoidNAG with QG Testing Accuray at 269 iterations is 0.755200000000 with loss: -13382.727834625824\n",
            "SigmoidNAG with QG Testing Accuray at 270 iterations is 0.755000000000 with loss: -13378.595207683558\n",
            "SigmoidNAG with QG Testing Accuray at 271 iterations is 0.755000000000 with loss: -13374.511655741149\n",
            "SigmoidNAG with QG Testing Accuray at 272 iterations is 0.754700000000 with loss: -13370.476847693672\n",
            "SigmoidNAG with QG Testing Accuray at 273 iterations is 0.754900000000 with loss: -13366.488222006177\n",
            "SigmoidNAG with QG Testing Accuray at 274 iterations is 0.754800000000 with loss: -13362.541302065054\n",
            "SigmoidNAG with QG Testing Accuray at 275 iterations is 0.754700000000 with loss: -13358.630453891146\n",
            "SigmoidNAG with QG Testing Accuray at 276 iterations is 0.755100000000 with loss: -13354.749922743527\n",
            "SigmoidNAG with QG Testing Accuray at 277 iterations is 0.755300000000 with loss: -13350.894879540127\n",
            "SigmoidNAG with QG Testing Accuray at 278 iterations is 0.755500000000 with loss: -13347.062200522518\n",
            "SigmoidNAG with QG Testing Accuray at 279 iterations is 0.755800000000 with loss: -13343.250811520529\n",
            "SigmoidNAG with QG Testing Accuray at 280 iterations is 0.756100000000 with loss: -13339.461597750667\n",
            "SigmoidNAG with QG Testing Accuray at 281 iterations is 0.756100000000 with loss: -13335.697021426278\n",
            "SigmoidNAG with QG Testing Accuray at 282 iterations is 0.756200000000 with loss: -13331.960629872281\n",
            "SigmoidNAG with QG Testing Accuray at 283 iterations is 0.756500000000 with loss: -13328.256566953471\n",
            "SigmoidNAG with QG Testing Accuray at 284 iterations is 0.756300000000 with loss: -13324.589088942954\n",
            "SigmoidNAG with QG Testing Accuray at 285 iterations is 0.756300000000 with loss: -13320.962022284652\n",
            "SigmoidNAG with QG Testing Accuray at 286 iterations is 0.756200000000 with loss: -13317.378139912218\n",
            "SigmoidNAG with QG Testing Accuray at 287 iterations is 0.756200000000 with loss: -13313.838551232968\n",
            "SigmoidNAG with QG Testing Accuray at 288 iterations is 0.756400000000 with loss: -13310.342305912116\n",
            "SigmoidNAG with QG Testing Accuray at 289 iterations is 0.756400000000 with loss: -13306.886414977340\n",
            "SigmoidNAG with QG Testing Accuray at 290 iterations is 0.756400000000 with loss: -13303.466362587964\n",
            "SigmoidNAG with QG Testing Accuray at 291 iterations is 0.756500000000 with loss: -13300.076985355485\n",
            "SigmoidNAG with QG Testing Accuray at 292 iterations is 0.756700000000 with loss: -13296.713442759476\n",
            "SigmoidNAG with QG Testing Accuray at 293 iterations is 0.756600000000 with loss: -13293.371984167787\n",
            "SigmoidNAG with QG Testing Accuray at 294 iterations is 0.756600000000 with loss: -13290.050341464159\n",
            "SigmoidNAG with QG Testing Accuray at 295 iterations is 0.756600000000 with loss: -13286.747760364218\n",
            "SigmoidNAG with QG Testing Accuray at 296 iterations is 0.756600000000 with loss: -13283.464815409652\n",
            "SigmoidNAG with QG Testing Accuray at 297 iterations is 0.756800000000 with loss: -13280.203163932711\n",
            "SigmoidNAG with QG Testing Accuray at 298 iterations is 0.756900000000 with loss: -13276.965302029255\n",
            "SigmoidNAG with QG Testing Accuray at 299 iterations is 0.756800000000 with loss: -13273.754276815818\n",
            "SigmoidNAG with QG Testing Accuray at 300 iterations is 0.756900000000 with loss: -13270.573276493760\n",
            "SigmoidNAG with QG Testing Accuray at 301 iterations is 0.756700000000 with loss: -13267.425089631515\n",
            "SigmoidNAG with QG Testing Accuray at 302 iterations is 0.756500000000 with loss: -13264.311547135296\n",
            "SigmoidNAG with QG Testing Accuray at 303 iterations is 0.756800000000 with loss: -13261.233135640652\n",
            "SigmoidNAG with QG Testing Accuray at 304 iterations is 0.756700000000 with loss: -13258.188937728275\n",
            "SigmoidNAG with QG Testing Accuray at 305 iterations is 0.756600000000 with loss: -13255.176919983773\n",
            "SigmoidNAG with QG Testing Accuray at 306 iterations is 0.756700000000 with loss: -13252.194437335693\n",
            "SigmoidNAG with QG Testing Accuray at 307 iterations is 0.756800000000 with loss: -13249.238745810166\n",
            "SigmoidNAG with QG Testing Accuray at 308 iterations is 0.756800000000 with loss: -13246.307357163212\n",
            "SigmoidNAG with QG Testing Accuray at 309 iterations is 0.756800000000 with loss: -13243.398192209706\n",
            "SigmoidNAG with QG Testing Accuray at 310 iterations is 0.756700000000 with loss: -13240.509610423529\n",
            "SigmoidNAG with QG Testing Accuray at 311 iterations is 0.756500000000 with loss: -13237.640432708766\n",
            "SigmoidNAG with QG Testing Accuray at 312 iterations is 0.756600000000 with loss: -13234.790018126667\n",
            "SigmoidNAG with QG Testing Accuray at 313 iterations is 0.756500000000 with loss: -13231.958355713638\n",
            "SigmoidNAG with QG Testing Accuray at 314 iterations is 0.756500000000 with loss: -13229.146072264362\n",
            "SigmoidNAG with QG Testing Accuray at 315 iterations is 0.756300000000 with loss: -13226.354280331016\n",
            "SigmoidNAG with QG Testing Accuray at 316 iterations is 0.756400000000 with loss: -13223.584284844572\n",
            "SigmoidNAG with QG Testing Accuray at 317 iterations is 0.756500000000 with loss: -13220.837257829126\n",
            "SigmoidNAG with QG Testing Accuray at 318 iterations is 0.756600000000 with loss: -13218.114016359197\n",
            "SigmoidNAG with QG Testing Accuray at 319 iterations is 0.756600000000 with loss: -13215.414977738028\n",
            "SigmoidNAG with QG Testing Accuray at 320 iterations is 0.756400000000 with loss: -13212.740262588017\n",
            "SigmoidNAG with QG Testing Accuray at 321 iterations is 0.756300000000 with loss: -13210.089840924144\n",
            "SigmoidNAG with QG Testing Accuray at 322 iterations is 0.756200000000 with loss: -13207.463615927672\n",
            "SigmoidNAG with QG Testing Accuray at 323 iterations is 0.756200000000 with loss: -13204.861408739607\n",
            "SigmoidNAG with QG Testing Accuray at 324 iterations is 0.756200000000 with loss: -13202.282889583876\n",
            "SigmoidNAG with QG Testing Accuray at 325 iterations is 0.756200000000 with loss: -13199.727539097417\n",
            "SigmoidNAG with QG Testing Accuray at 326 iterations is 0.756400000000 with loss: -13197.194693185524\n",
            "SigmoidNAG with QG Testing Accuray at 327 iterations is 0.756500000000 with loss: -13194.683654742552\n",
            "SigmoidNAG with QG Testing Accuray at 328 iterations is 0.756500000000 with loss: -13192.193802175094\n",
            "SigmoidNAG with QG Testing Accuray at 329 iterations is 0.756600000000 with loss: -13189.724627230118\n",
            "SigmoidNAG with QG Testing Accuray at 330 iterations is 0.756600000000 with loss: -13187.275691189137\n",
            "SigmoidNAG with QG Testing Accuray at 331 iterations is 0.756500000000 with loss: -13184.846554259855\n",
            "SigmoidNAG with QG Testing Accuray at 332 iterations is 0.756400000000 with loss: -13182.436756294297\n",
            "SigmoidNAG with QG Testing Accuray at 333 iterations is 0.756100000000 with loss: -13180.045889067656\n",
            "SigmoidNAG with QG Testing Accuray at 334 iterations is 0.756100000000 with loss: -13177.673729233029\n",
            "SigmoidNAG with QG Testing Accuray at 335 iterations is 0.756100000000 with loss: -13175.320348737765\n",
            "SigmoidNAG with QG Testing Accuray at 336 iterations is 0.756300000000 with loss: -13172.986124807245\n",
            "SigmoidNAG with QG Testing Accuray at 337 iterations is 0.756300000000 with loss: -13170.671631734527\n",
            "SigmoidNAG with QG Testing Accuray at 338 iterations is 0.756300000000 with loss: -13168.377470987802\n",
            "SigmoidNAG with QG Testing Accuray at 339 iterations is 0.756200000000 with loss: -13166.104131141567\n",
            "SigmoidNAG with QG Testing Accuray at 340 iterations is 0.756500000000 with loss: -13163.851942915431\n",
            "SigmoidNAG with QG Testing Accuray at 341 iterations is 0.756600000000 with loss: -13161.621127957133\n",
            "SigmoidNAG with QG Testing Accuray at 342 iterations is 0.756600000000 with loss: -13159.411878162782\n",
            "SigmoidNAG with QG Testing Accuray at 343 iterations is 0.756300000000 with loss: -13157.224389989020\n",
            "SigmoidNAG with QG Testing Accuray at 344 iterations is 0.756200000000 with loss: -13155.058819022508\n",
            "SigmoidNAG with QG Testing Accuray at 345 iterations is 0.756300000000 with loss: -13152.915182621633\n",
            "SigmoidNAG with QG Testing Accuray at 346 iterations is 0.756300000000 with loss: -13150.793275907119\n",
            "SigmoidNAG with QG Testing Accuray at 347 iterations is 0.756400000000 with loss: -13148.692653531984\n",
            "SigmoidNAG with QG Testing Accuray at 348 iterations is 0.756600000000 with loss: -13146.612680720964\n",
            "SigmoidNAG with QG Testing Accuray at 349 iterations is 0.756500000000 with loss: -13144.552608479953\n",
            "SigmoidNAG with QG Testing Accuray at 350 iterations is 0.756400000000 with loss: -13142.511618804827\n",
            "SigmoidNAG with QG Testing Accuray at 351 iterations is 0.756700000000 with loss: -13140.488819546203\n",
            "SigmoidNAG with QG Testing Accuray at 352 iterations is 0.756800000000 with loss: -13138.483220367863\n",
            "SigmoidNAG with QG Testing Accuray at 353 iterations is 0.756900000000 with loss: -13136.493749332929\n",
            "SigmoidNAG with QG Testing Accuray at 354 iterations is 0.757000000000 with loss: -13134.519352191997\n",
            "SigmoidNAG with QG Testing Accuray at 355 iterations is 0.757100000000 with loss: -13132.559163386288\n",
            "SigmoidNAG with QG Testing Accuray at 356 iterations is 0.757000000000 with loss: -13130.612686192035\n",
            "SigmoidNAG with QG Testing Accuray at 357 iterations is 0.757000000000 with loss: -13128.679906223610\n",
            "SigmoidNAG with QG Testing Accuray at 358 iterations is 0.756800000000 with loss: -13126.761295497250\n",
            "SigmoidNAG with QG Testing Accuray at 359 iterations is 0.757200000000 with loss: -13124.857719913496\n",
            "SigmoidNAG with QG Testing Accuray at 360 iterations is 0.757300000000 with loss: -13122.970302347070\n",
            "SigmoidNAG with QG Testing Accuray at 361 iterations is 0.757500000000 with loss: -13121.100290910506\n",
            "SigmoidNAG with QG Testing Accuray at 362 iterations is 0.757500000000 with loss: -13119.248943023267\n",
            "SigmoidNAG with QG Testing Accuray at 363 iterations is 0.757400000000 with loss: -13117.417395682925\n",
            "SigmoidNAG with QG Testing Accuray at 364 iterations is 0.757500000000 with loss: -13115.606483224279\n",
            "SigmoidNAG with QG Testing Accuray at 365 iterations is 0.757500000000 with loss: -13113.816500885174\n",
            "SigmoidNAG with QG Testing Accuray at 366 iterations is 0.757400000000 with loss: -13112.046970498586\n",
            "SigmoidNAG with QG Testing Accuray at 367 iterations is 0.757500000000 with loss: -13110.296504091737\n",
            "SigmoidNAG with QG Testing Accuray at 368 iterations is 0.757500000000 with loss: -13108.562851638151\n",
            "SigmoidNAG with QG Testing Accuray at 369 iterations is 0.757500000000 with loss: -13106.843158469208\n",
            "SigmoidNAG with QG Testing Accuray at 370 iterations is 0.757500000000 with loss: -13105.134379171070\n",
            "SigmoidNAG with QG Testing Accuray at 371 iterations is 0.757500000000 with loss: -13103.433738993779\n",
            "SigmoidNAG with QG Testing Accuray at 372 iterations is 0.757300000000 with loss: -13101.739128558938\n",
            "SigmoidNAG with QG Testing Accuray at 373 iterations is 0.757200000000 with loss: -13100.049359433979\n",
            "SigmoidNAG with QG Testing Accuray at 374 iterations is 0.757000000000 with loss: -13098.364265278979\n",
            "SigmoidNAG with QG Testing Accuray at 375 iterations is 0.757100000000 with loss: -13096.684672591948\n",
            "SigmoidNAG with QG Testing Accuray at 376 iterations is 0.756900000000 with loss: -13095.012271942878\n",
            "SigmoidNAG with QG Testing Accuray at 377 iterations is 0.757200000000 with loss: -13093.349403063054\n",
            "SigmoidNAG with QG Testing Accuray at 378 iterations is 0.757200000000 with loss: -13091.698751328371\n",
            "SigmoidNAG with QG Testing Accuray at 379 iterations is 0.757300000000 with loss: -13090.062960540756\n",
            "SigmoidNAG with QG Testing Accuray at 380 iterations is 0.757300000000 with loss: -13088.444197398079\n",
            "SigmoidNAG with QG Testing Accuray at 381 iterations is 0.757600000000 with loss: -13086.843740690647\n",
            "SigmoidNAG with QG Testing Accuray at 382 iterations is 0.757700000000 with loss: -13085.261686814134\n",
            "SigmoidNAG with QG Testing Accuray at 383 iterations is 0.757600000000 with loss: -13083.696849599848\n",
            "SigmoidNAG with QG Testing Accuray at 384 iterations is 0.757800000000 with loss: -13082.146887800754\n",
            "SigmoidNAG with QG Testing Accuray at 385 iterations is 0.757900000000 with loss: -13080.608638651973\n",
            "SigmoidNAG with QG Testing Accuray at 386 iterations is 0.757900000000 with loss: -13079.078590481498\n",
            "SigmoidNAG with QG Testing Accuray at 387 iterations is 0.757900000000 with loss: -13077.553404426972\n",
            "SigmoidNAG with QG Testing Accuray at 388 iterations is 0.757900000000 with loss: -13076.030394487963\n",
            "SigmoidNAG with QG Testing Accuray at 389 iterations is 0.757900000000 with loss: -13074.507890774479\n",
            "SigmoidNAG with QG Testing Accuray at 390 iterations is 0.757800000000 with loss: -13072.985433936126\n",
            "SigmoidNAG with QG Testing Accuray at 391 iterations is 0.757700000000 with loss: -13071.463778129542\n",
            "SigmoidNAG with QG Testing Accuray at 392 iterations is 0.757700000000 with loss: -13069.944711274486\n",
            "SigmoidNAG with QG Testing Accuray at 393 iterations is 0.757700000000 with loss: -13068.430730979924\n",
            "SigmoidNAG with QG Testing Accuray at 394 iterations is 0.757700000000 with loss: -13066.924636521559\n",
            "SigmoidNAG with QG Testing Accuray at 395 iterations is 0.757700000000 with loss: -13065.429102999471\n",
            "SigmoidNAG with QG Testing Accuray at 396 iterations is 0.758000000000 with loss: -13063.946296571163\n",
            "SigmoidNAG with QG Testing Accuray at 397 iterations is 0.758200000000 with loss: -13062.477574645794\n",
            "SigmoidNAG with QG Testing Accuray at 398 iterations is 0.758300000000 with loss: -13061.023302710368\n",
            "SigmoidNAG with QG Testing Accuray at 399 iterations is 0.758300000000 with loss: -13059.582814002832\n",
            "SigmoidNAG with QG Testing Accuray at 400 iterations is 0.758200000000 with loss: -13058.154533511995\n",
            "SigmoidNAG with QG Testing Accuray at 401 iterations is 0.758400000000 with loss: -13056.736272632079\n",
            "SigmoidNAG with QG Testing Accuray at 402 iterations is 0.758400000000 with loss: -13055.325665196893\n",
            "SigmoidNAG with QG Testing Accuray at 403 iterations is 0.758100000000 with loss: -13053.920667437280\n",
            "SigmoidNAG with QG Testing Accuray at 404 iterations is 0.758100000000 with loss: -13052.520005212136\n",
            "SigmoidNAG with QG Testing Accuray at 405 iterations is 0.758000000000 with loss: -13051.123447736614\n",
            "SigmoidNAG with QG Testing Accuray at 406 iterations is 0.757900000000 with loss: -13049.731830651850\n",
            "SigmoidNAG with QG Testing Accuray at 407 iterations is 0.758300000000 with loss: -13048.346831003690\n",
            "SigmoidNAG with QG Testing Accuray at 408 iterations is 0.758400000000 with loss: -13046.970576594653\n",
            "SigmoidNAG with QG Testing Accuray at 409 iterations is 0.758500000000 with loss: -13045.605215556609\n",
            "SigmoidNAG with QG Testing Accuray at 410 iterations is 0.758500000000 with loss: -13044.252559925264\n",
            "SigmoidNAG with QG Testing Accuray at 411 iterations is 0.758600000000 with loss: -13042.913861200390\n",
            "SigmoidNAG with QG Testing Accuray at 412 iterations is 0.758600000000 with loss: -13041.589712535253\n",
            "SigmoidNAG with QG Testing Accuray at 413 iterations is 0.758700000000 with loss: -13040.280037555392\n",
            "SigmoidNAG with QG Testing Accuray at 414 iterations is 0.758600000000 with loss: -13038.984134728116\n",
            "SigmoidNAG with QG Testing Accuray at 415 iterations is 0.758600000000 with loss: -13037.700781488671\n",
            "SigmoidNAG with QG Testing Accuray at 416 iterations is 0.758700000000 with loss: -13036.428430072470\n",
            "SigmoidNAG with QG Testing Accuray at 417 iterations is 0.758600000000 with loss: -13035.165515479433\n",
            "SigmoidNAG with QG Testing Accuray at 418 iterations is 0.758800000000 with loss: -13033.910845577861\n",
            "SigmoidNAG with QG Testing Accuray at 419 iterations is 0.758900000000 with loss: -13032.663980970367\n",
            "SigmoidNAG with QG Testing Accuray at 420 iterations is 0.759200000000 with loss: -13031.425480341581\n",
            "SigmoidNAG with QG Testing Accuray at 421 iterations is 0.758900000000 with loss: -13030.196911144385\n",
            "SigmoidNAG with QG Testing Accuray at 422 iterations is 0.759100000000 with loss: -13028.980601589354\n",
            "SigmoidNAG with QG Testing Accuray at 423 iterations is 0.759100000000 with loss: -13027.779199947670\n",
            "SigmoidNAG with QG Testing Accuray at 424 iterations is 0.759100000000 with loss: -13026.595167862437\n",
            "SigmoidNAG with QG Testing Accuray at 425 iterations is 0.759100000000 with loss: -13025.430338732158\n",
            "SigmoidNAG with QG Testing Accuray at 426 iterations is 0.759200000000 with loss: -13024.285627013742\n",
            "SigmoidNAG with QG Testing Accuray at 427 iterations is 0.759200000000 with loss: -13023.160911217848\n",
            "SigmoidNAG with QG Testing Accuray at 428 iterations is 0.758900000000 with loss: -13022.055068458609\n",
            "SigmoidNAG with QG Testing Accuray at 429 iterations is 0.759000000000 with loss: -13020.966127892105\n",
            "SigmoidNAG with QG Testing Accuray at 430 iterations is 0.759100000000 with loss: -13019.891524066199\n",
            "SigmoidNAG with QG Testing Accuray at 431 iterations is 0.758800000000 with loss: -13018.828442891301\n",
            "SigmoidNAG with QG Testing Accuray at 432 iterations is 0.758700000000 with loss: -13017.774241547453\n",
            "SigmoidNAG with QG Testing Accuray at 433 iterations is 0.758500000000 with loss: -13016.726889417416\n",
            "SigmoidNAG with QG Testing Accuray at 434 iterations is 0.758600000000 with loss: -13015.685342053524\n",
            "SigmoidNAG with QG Testing Accuray at 435 iterations is 0.758500000000 with loss: -13014.649751739089\n",
            "SigmoidNAG with QG Testing Accuray at 436 iterations is 0.758500000000 with loss: -13013.621450937935\n",
            "SigmoidNAG with QG Testing Accuray at 437 iterations is 0.758600000000 with loss: -13012.602707316857\n",
            "SigmoidNAG with QG Testing Accuray at 438 iterations is 0.758800000000 with loss: -13011.596313055023\n",
            "SigmoidNAG with QG Testing Accuray at 439 iterations is 0.758700000000 with loss: -13010.605107060313\n",
            "SigmoidNAG with QG Testing Accuray at 440 iterations is 0.758700000000 with loss: -13009.631526473438\n",
            "SigmoidNAG with QG Testing Accuray at 441 iterations is 0.758600000000 with loss: -13008.677252151814\n",
            "SigmoidNAG with QG Testing Accuray at 442 iterations is 0.758500000000 with loss: -13007.742976764823\n",
            "SigmoidNAG with QG Testing Accuray at 443 iterations is 0.758600000000 with loss: -13006.828302308959\n",
            "SigmoidNAG with QG Testing Accuray at 444 iterations is 0.758500000000 with loss: -13005.931770561527\n",
            "SigmoidNAG with QG Testing Accuray at 445 iterations is 0.758600000000 with loss: -13005.051032067548\n",
            "SigmoidNAG with QG Testing Accuray at 446 iterations is 0.758600000000 with loss: -13004.183150104607\n",
            "SigmoidNAG with QG Testing Accuray at 447 iterations is 0.758700000000 with loss: -13003.325009905720\n",
            "SigmoidNAG with QG Testing Accuray at 448 iterations is 0.758700000000 with loss: -13002.473768587730\n",
            "SigmoidNAG with QG Testing Accuray at 449 iterations is 0.759000000000 with loss: -13001.627258216289\n",
            "SigmoidNAG with QG Testing Accuray at 450 iterations is 0.759200000000 with loss: -13000.784258501631\n",
            "SigmoidNAG with QG Testing Accuray at 451 iterations is 0.759100000000 with loss: -12999.944588474717\n",
            "SigmoidNAG with QG Testing Accuray at 452 iterations is 0.759200000000 with loss: -12999.109014566697\n",
            "SigmoidNAG with QG Testing Accuray at 453 iterations is 0.759300000000 with loss: -12998.279014371949\n",
            "SigmoidNAG with QG Testing Accuray at 454 iterations is 0.759200000000 with loss: -12997.456456871219\n",
            "SigmoidNAG with QG Testing Accuray at 455 iterations is 0.759200000000 with loss: -12996.643259910081\n",
            "SigmoidNAG with QG Testing Accuray at 456 iterations is 0.759200000000 with loss: -12995.841073309439\n",
            "SigmoidNAG with QG Testing Accuray at 457 iterations is 0.759300000000 with loss: -12995.051024390747\n",
            "SigmoidNAG with QG Testing Accuray at 458 iterations is 0.759300000000 with loss: -12994.273555628601\n",
            "SigmoidNAG with QG Testing Accuray at 459 iterations is 0.759500000000 with loss: -12993.508377861664\n",
            "SigmoidNAG with QG Testing Accuray at 460 iterations is 0.759500000000 with loss: -12992.754548723937\n",
            "SigmoidNAG with QG Testing Accuray at 461 iterations is 0.759500000000 with loss: -12992.010661839209\n",
            "SigmoidNAG with QG Testing Accuray at 462 iterations is 0.759500000000 with loss: -12991.275104692086\n",
            "SigmoidNAG with QG Testing Accuray at 463 iterations is 0.759700000000 with loss: -12990.546324758698\n",
            "SigmoidNAG with QG Testing Accuray at 464 iterations is 0.759800000000 with loss: -12989.823044868812\n",
            "SigmoidNAG with QG Testing Accuray at 465 iterations is 0.759800000000 with loss: -12989.104390416333\n",
            "SigmoidNAG with QG Testing Accuray at 466 iterations is 0.759700000000 with loss: -12988.389921505966\n",
            "SigmoidNAG with QG Testing Accuray at 467 iterations is 0.759700000000 with loss: -12987.679587913382\n",
            "SigmoidNAG with QG Testing Accuray at 468 iterations is 0.759800000000 with loss: -12986.973634160253\n",
            "SigmoidNAG with QG Testing Accuray at 469 iterations is 0.759800000000 with loss: -12986.272477371236\n",
            "SigmoidNAG with QG Testing Accuray at 470 iterations is 0.759800000000 with loss: -12985.576571944766\n",
            "SigmoidNAG with QG Testing Accuray at 471 iterations is 0.759700000000 with loss: -12984.886273069676\n",
            "SigmoidNAG with QG Testing Accuray at 472 iterations is 0.759600000000 with loss: -12984.201718653199\n",
            "SigmoidNAG with QG Testing Accuray at 473 iterations is 0.759800000000 with loss: -12983.522758970963\n",
            "SigmoidNAG with QG Testing Accuray at 474 iterations is 0.759700000000 with loss: -12982.848963243498\n",
            "SigmoidNAG with QG Testing Accuray at 475 iterations is 0.759900000000 with loss: -12982.179714749838\n",
            "SigmoidNAG with QG Testing Accuray at 476 iterations is 0.759800000000 with loss: -12981.514376801615\n",
            "SigmoidNAG with QG Testing Accuray at 477 iterations is 0.759900000000 with loss: -12980.852483717794\n",
            "SigmoidNAG with QG Testing Accuray at 478 iterations is 0.759900000000 with loss: -12980.193898585349\n",
            "SigmoidNAG with QG Testing Accuray at 479 iterations is 0.760000000000 with loss: -12979.538891440492\n",
            "SigmoidNAG with QG Testing Accuray at 480 iterations is 0.759900000000 with loss: -12978.888119812853\n",
            "SigmoidNAG with QG Testing Accuray at 481 iterations is 0.760100000000 with loss: -12978.242525071159\n",
            "SigmoidNAG with QG Testing Accuray at 482 iterations is 0.760300000000 with loss: -12977.603177789570\n",
            "SigmoidNAG with QG Testing Accuray at 483 iterations is 0.760200000000 with loss: -12976.971107769774\n",
            "SigmoidNAG with QG Testing Accuray at 484 iterations is 0.760200000000 with loss: -12976.347145079890\n",
            "SigmoidNAG with QG Testing Accuray at 485 iterations is 0.760300000000 with loss: -12975.731787274040\n",
            "SigmoidNAG with QG Testing Accuray at 486 iterations is 0.760300000000 with loss: -12975.125103600829\n",
            "SigmoidNAG with QG Testing Accuray at 487 iterations is 0.760400000000 with loss: -12974.526689563341\n",
            "SigmoidNAG with QG Testing Accuray at 488 iterations is 0.760600000000 with loss: -12973.935688613383\n",
            "SigmoidNAG with QG Testing Accuray at 489 iterations is 0.760700000000 with loss: -12973.350891754410\n",
            "SigmoidNAG with QG Testing Accuray at 490 iterations is 0.760600000000 with loss: -12972.770910250856\n",
            "SigmoidNAG with QG Testing Accuray at 491 iterations is 0.760700000000 with loss: -12972.194395743089\n",
            "SigmoidNAG with QG Testing Accuray at 492 iterations is 0.760800000000 with loss: -12971.620266116366\n",
            "SigmoidNAG with QG Testing Accuray at 493 iterations is 0.760700000000 with loss: -12971.047892308599\n",
            "SigmoidNAG with QG Testing Accuray at 494 iterations is 0.760600000000 with loss: -12970.477212169679\n",
            "SigmoidNAG with QG Testing Accuray at 495 iterations is 0.760600000000 with loss: -12969.908756116272\n",
            "SigmoidNAG with QG Testing Accuray at 496 iterations is 0.760500000000 with loss: -12969.343587245537\n",
            "SigmoidNAG with QG Testing Accuray at 497 iterations is 0.760600000000 with loss: -12968.783170512361\n",
            "SigmoidNAG with QG Testing Accuray at 498 iterations is 0.760700000000 with loss: -12968.229191275386\n",
            "SigmoidNAG with QG Testing Accuray at 499 iterations is 0.760700000000 with loss: -12967.683346240630\n",
            "SigmoidNAG with QG Testing Accuray at 500 iterations is 0.760800000000 with loss: -12967.147132963921\n",
            "TotalEnAdagradTimeDiff = \n",
            "313.4582118988037\n",
            "AveraEnAdagradTimeDiff = \n",
            "0.6269164237976074\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "import csv\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models, datasets\n",
        "import torchvision.transforms as trnsfrms\n",
        "from torchvision.transforms import ToTensor, Resize, Lambda\n",
        "\n",
        "#trnsfrms = trnsfrms.Compose([Resize(224), ToTensor(),  Lambda(lambda x: x.repeat(3, 1, 1) ) ])  # Grayscale Images like MNIST and USPS\n",
        "trnsfrms = trnsfrms.Compose([Resize(224), ToTensor(), ])                                       # Color Images like CIFAR10\n",
        "#trnsfrms = trnsfrms.Compose([ ToTensor(), ]) \n",
        "\n",
        "# Download training data from open datasets.FashionMNIST.MNIST.USPS  / CIFAR10\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform= trnsfrms\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.FashionMNIST.MNIST\n",
        "testing_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform= trnsfrms\n",
        ")\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(testing_data, batch_size=batch_size)\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "#model = models.regnet_x_400mf(pretrained=True)  #Linear(in_features=400,\n",
        "#model = models.regnet_y_400mf(pretrained=True)  #(fc): Linear(in_features=440,\n",
        "#model = models.regnet_x_800mf(pretrained=True)  #Linear(in_features=672,\n",
        "#model = models.regnet_y_800mf(pretrained=True)  #(fc): Linear(in_features=784,\n",
        "#model = models.regnet_y_1_6gf(pretrained=True)  #Linear(in_features=888,\n",
        "#model = models.regnet_x_1_6gf(pretrained=True)  #Linear(in_features=912,\n",
        "#model = models.regnet_x_3_2gf(pretrained=True)  #Linear(in_features=1008,\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "model = models.regnet_x_400mf(pretrained=True)  \n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "model.fc = nn.Sequential(*list(model.fc.children())[:-1])\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "print(model.fc)\n",
        "print(type(model.fc))\n",
        "\n",
        "\n",
        "# Save the raw dataset: USPS MNIST CIFAR10\n",
        "train_dataset = []\n",
        "size = len(train_dataloader.dataset)\n",
        "num_batches = len(train_dataloader)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in train_dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        print(f\"Shape of model(X) [N, C, H, W]: {pred.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "        pred = torch.reshape(pred, (pred.shape[0], -1) )\n",
        "        y = torch.reshape(y, (y.shape[0], -1) )\n",
        "        print(f\"Shape of model(X): {pred.shape} {pred.dtype}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "\n",
        "        train_dataset += torch.cat( (y, pred ), 1)\n",
        "        print(f\"Shape of train_dataset: {len(train_dataset)}, {len(train_dataset[0])}\")\n",
        "\n",
        "print(\"train_dataset :\" + str(len(train_dataset)) + \",\\t\" + str(len(train_dataset[0])) )\n",
        "print(type(train_dataset))\n",
        "with open('REGNET_X_400MF_CIFAR10_TRAINING.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for i in range( len(train_dataset)):                                   #len(train_dataset)):\n",
        "      writer.writerow(train_dataset[i].detach().cpu().numpy())\n",
        "csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "# Save the raw dataset: USPS MNIST CIFAR10\n",
        "test_dataset = []\n",
        "size = len(test_dataloader.dataset)\n",
        "num_batches = len(test_dataloader)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for X, y in test_dataloader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        print(f\"Shape of model(X) [N, C, H, W]: {pred.shape}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "        pred = torch.reshape(pred, (pred.shape[0], -1) )\n",
        "        y = torch.reshape(y, (y.shape[0], -1) )\n",
        "        print(f\"Shape of model(X): {pred.shape} {pred.dtype}\")\n",
        "        print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "\n",
        "        test_dataset += torch.cat( (y, pred ), 1)\n",
        "        print(f\"Shape of test_dataset: {len(test_dataset)}, {len(test_dataset[0])}\")\n",
        "\n",
        "print(\"test_dataset :\" + str(len(test_dataset)) + \",\\t\" + str(len(test_dataset[0])) )\n",
        "print(type(test_dataset))\n",
        "with open('REGNET_X_400MF_CIFAR10_TESTING.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for i in range(len(test_dataset)):\n",
        "      writer.writerow(test_dataset[i].detach().cpu().numpy())\n",
        "csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# coding=utf8\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "\n",
        "from copy import deepcopy\n",
        "from math import log, exp, pow, sqrt\n",
        "\n",
        "import matplotlib\n",
        "#matplotlib.use('pdf')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "\n",
        "\n",
        "#hlambda = lambda x:1.0/(1+exp(-x))\n",
        "#Sigmoid(x) ~ poly3 = 0.5 + 0.10679534503216294.*x + -0.00038503259805075.*x.^3; (lambda = 128)\n",
        "def hlambda(x):\n",
        "    x[x>+8] = +8\n",
        "    x[x<-8] = -8\n",
        "    res = 1 / (1 + np.exp(-x) )\n",
        "    #res = 5.0000e-01  + 0.10679534503216294 * x  - 0.00038503259805075 * np.multiply(np.multiply(x,  x), x)\n",
        "    return res \n",
        "\n",
        "\n",
        "\n",
        "import csv\n",
        "epsilon = 1e-10\n",
        "num_iter = 500\n",
        "\n",
        "\n",
        "with open(\"REGNET_X_400MF_CIFAR10_TRAINING.csv\",'r') as csvfile:\n",
        "#with open(\"REGNET_X_400MF_CIFAR10_TESTING.csv\",'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    traindata = []\n",
        "    for row in reader:\n",
        "        row = [float(x) for x in row]\n",
        "        traindata.append(row)\n",
        "csvfile.close()\n",
        "with open(\"REGNET_X_400MF_CIFAR10_TESTING.csv\", 'r') as csvfile:\n",
        "#with open(\"REGNET_X_400MF_CIFAR10_TRAININGfirst8192.csv\",'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    testdata = []\n",
        "    for row in reader:\n",
        "        row = [float(x) for x in row]\n",
        "        testdata.append(row)\n",
        "csvfile.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#traindata = traindata[:6144]\n",
        "TrainX = [row[1:] for row in traindata[:]]\n",
        "TestX = [row[1:] for row in testdata[:]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = []\n",
        "Xtest  = []\n",
        "\n",
        "\n",
        "for (rowidx, row) in enumerate(TrainX):\n",
        "    #TrainData.append( [ trainy[rowidx] ] + row )\n",
        "    X.append( [ 1.0 ] + row )\n",
        "for (rowidx, row) in enumerate(TestX):\n",
        "    #TestData.append( [ testy[rowidx] ] + row )\n",
        "    Xtest.append( [ 1.0 ] + row )\n",
        "   \n",
        "#X = X[:]\n",
        "X = np.matrix(X)\n",
        "Xtest = np.matrix(Xtest)\n",
        "\n",
        "\n",
        "ytrain = [int(row[0]) for row in traindata[:]]\n",
        "ytest = [int(row[0]) for row in testdata[:]]\n",
        "\n",
        "#y = self.one_hot(y)\n",
        "Y = []\n",
        "for rowidx in range( len(traindata) ):\n",
        "    row = []\n",
        "    for colidx in range( len( set(ytrain + ytest) ) ):\n",
        "        if colidx == ytrain[rowidx]:\n",
        "            row.append( 1 )\n",
        "        else:\n",
        "            row.append( 0 )\n",
        "    Y.append( row )\n",
        "\n",
        "#Y = Y[:]\n",
        "Y = np.matrix(Y)\n",
        "\n",
        "Ytest = []\n",
        "for rowidx in range( len(testdata) ):\n",
        "    row = []\n",
        "    for colidx in range( len( set(ytrain + ytest) ) ):\n",
        "        if colidx == ytest[rowidx]:\n",
        "            row.append( 1 )\n",
        "        else:\n",
        "            row.append( 0 )\n",
        "    Ytest.append( row )\n",
        "Ytest = np.matrix(Ytest)\n",
        "\n",
        "\n",
        "#     Step 2. Extract X and Y from data\n",
        "\n",
        "\n",
        "\n",
        "def precision(vec0, vec1):\n",
        "    if len(vec0) != len(vec1):\n",
        "        return -1\n",
        "    totalnum = len(vec0)\n",
        "    rightnum = 0.0\n",
        "    for idx in range(totalnum):\n",
        "        if vec0[idx] == vec1[idx]:\n",
        "            rightnum += 1\n",
        "    return rightnum / totalnum\n",
        "\n",
        "\n",
        "\n",
        "# ======================================= Raw NAG without QG ======================================= \n",
        "# Build the initial weight matrix\n",
        "velocity = []\n",
        "for rowidx in range( len(set(ytrain)) ):\n",
        "    vrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        vrow.append( 0.0 )\n",
        "    velocity.append(vrow)\n",
        "velocity = np.matrix( velocity )\n",
        "weights = []\n",
        "for rowidx in range( len(set(ytest+ytrain)) ):\n",
        "    wrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        wrow.append( 0.0 )\n",
        "    weights.append(wrow)\n",
        "weights = np.matrix( weights )\n",
        "\n",
        "\n",
        "NAG_result_prec_train = []\n",
        "NAG_result_loss_train = []\n",
        "z = np.dot(X, weights.T).reshape(-1,len(set(ytrain+ytest)))\n",
        "probs = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "loss =   -1 * np.mean(np.multiply(Y,  np.log(probs)) )\n",
        "NAG_result_loss_train.append( loss )\n",
        "NAG_result_prec_train.append( precision(np.argmax(probs, axis=1) ,ytrain) )\n",
        "\n",
        "NAG_result_prec_test = []\n",
        "NAG_result_loss_test = []\n",
        "z = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)))\n",
        "probs = np.exp(z) / np.sum(np.exp(z), axis=1).reshape(-1,1)\n",
        "loss =   -1 * np.mean(np.multiply(Ytest,  np.log(probs)) )\n",
        "NAG_result_loss_test.append( loss )\n",
        "NAG_result_prec_test.append( precision(np.argmax(probs, axis=1) ,ytest) )\n",
        "\n",
        "\n",
        "alpha0 = 0.01\n",
        "alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "start_time = time.time()\n",
        "for it in range(num_iter):\n",
        "    # np.dot(X, np.matrix(weights).T)  #.reshape(-1,len(self.classes))\n",
        "    z = np.dot(X, velocity.T).reshape(-1,len(set(ytrain+ytest)) )\n",
        "    \n",
        "    zi = z - np.max(z,-1)\n",
        "    h = np.exp(zi) / np.sum(np.exp(zi), axis=1)\n",
        "\n",
        "    gradient = -(h - Y).T.dot(X)\n",
        "\n",
        "\n",
        "    eta = (1 - alpha0) / alpha1\n",
        "    gamma = 1.0/(it+1)/ X.shape[0]\n",
        "    \n",
        "    MG = gradient          \n",
        "    # should be 'plus', 'cause to compute the MLE  \n",
        "    MtmpW = weights + (gamma + 0.0) * MG            \n",
        "    weights = (1.0-eta)*MtmpW + np.multiply(eta, velocity)\n",
        "    velocity = MtmpW\n",
        "\n",
        "    alpha0 = alpha1\n",
        "    alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "\n",
        "    zz = np.dot(X, weights.T).reshape(-1,len(set(ytrain)) )\n",
        "    zzi = zz - np.max(zz,-1)\n",
        "    pp = np.exp(zzi) / np.sum(np.exp(zzi), axis=1)\n",
        "    loss =  -1 * np.mean(np.multiply(Y,  np.log(pp)) )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytrain)\n",
        "    NAG_result_loss_train.append( loss )\n",
        "    NAG_result_prec_train.append( prec )\n",
        "    #print(' Training Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "    zz = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)) )\n",
        "    zzi = zz - np.max(zz,-1)\n",
        "    pp = np.exp(zzi) / np.sum(np.exp(zzi), axis=1)\n",
        "    loss =  -1 * np.mean(np.multiply(Ytest,  np.log(pp)) )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytest)\n",
        "    NAG_result_loss_test.append( loss )\n",
        "    NAG_result_prec_test.append( prec )\n",
        "    print(' Testing Accuray at {:2d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "\n",
        "#############################################################################################################3\n",
        "# ======================================= SigmoidNAG without QG ======================================= \n",
        "# Build the initial weight matrix\n",
        "velocity = []\n",
        "for rowidx in range( len(set(ytrain)) ):\n",
        "    vrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        vrow.append( 0.0 )\n",
        "    velocity.append(vrow)\n",
        "velocity = np.matrix( velocity )\n",
        "weights = []\n",
        "for rowidx in range( len(set(ytest+ytrain)) ):\n",
        "    wrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        wrow.append( 0.0 )\n",
        "    weights.append(wrow)\n",
        "weights = np.matrix( weights )\n",
        "\n",
        "\n",
        "\n",
        "SigmoidNAG_result_prec_train = []\n",
        "SigmoidNAG_result_loss_train = []\n",
        "z = np.dot(X, weights.T).reshape(-1,len(set(ytrain+ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =   np.sum( np.log( np.absolute(probs -1 + Y) )  )\n",
        "SigmoidNAG_result_loss_train.append( loss )\n",
        "SigmoidNAG_result_prec_train.append( precision(np.argmax(probs, axis=1) ,ytrain) )\n",
        "\n",
        "SigmoidNAG_result_prec_test = []\n",
        "SigmoidNAG_result_loss_test = []\n",
        "z = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =   np.sum( np.log( np.absolute(probs -1 + Ytest) )  )\n",
        "SigmoidNAG_result_loss_test.append( loss )\n",
        "SigmoidNAG_result_prec_test.append( precision(np.argmax(probs, axis=1) ,ytest) )\n",
        "\n",
        "\n",
        "alpha0 = 0.01\n",
        "alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "start_time = time.time()\n",
        "for it in range(num_iter):\n",
        "\n",
        "    # np.dot(X, np.matrix(weights).T)  #.reshape(-1,len(self.classes))\n",
        "    z = np.dot(X, velocity.T).reshape(-1,len(set(ytest+ytrain)) ) \n",
        "    \n",
        "    #P = 1.0 / ( 1.0 + np.exp(-z) ) \n",
        "    P = hlambda(z)\n",
        "\n",
        "    \n",
        "    gradient = (Y - P).T.dot(X)\n",
        "   \n",
        "\n",
        "    eta = (1 - alpha0) / alpha1\n",
        "    gamma = 1.0/(it+1)/ X.shape[0]\n",
        "            \n",
        "    # should be 'plus', 'cause to compute the MLE\n",
        "    MtmpW = weights + (gamma + 0.0) * gradient               \n",
        "    weights = (1.0-eta)*MtmpW + np.multiply(eta, velocity)\n",
        "    velocity = MtmpW\n",
        "\n",
        "    alpha0 = alpha1\n",
        "    alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "\n",
        "\n",
        "\n",
        "    zz = np.dot(X, weights.T).reshape(-1,len(set(ytest+ytrain)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Y) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytrain)\n",
        "    SigmoidNAG_result_loss_train.append( loss )\n",
        "    SigmoidNAG_result_prec_train.append( prec )\n",
        "    #print('SigmoidNAG without QG Training Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "    zz = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Ytest) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytest)\n",
        "    SigmoidNAG_result_loss_test.append( loss )\n",
        "    SigmoidNAG_result_prec_test.append( prec )\n",
        "    print('SigmoidNAG without QG Testing Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "\n",
        "\n",
        "#############################################################################################################3\n",
        "\n",
        "# ======================================= SigmoidNAG with QG ======================================= \n",
        "# Build the initial weight matrix\n",
        "velocity = []\n",
        "for rowidx in range( len(set(ytrain)) ):\n",
        "    vrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        vrow.append( 0.0 )\n",
        "    velocity.append(vrow)\n",
        "velocity = np.matrix( velocity )\n",
        "weights = []\n",
        "for rowidx in range( len(set(ytest+ytrain)) ):\n",
        "    wrow = []\n",
        "    for colidx in range( X.shape[1] ):\n",
        "        wrow.append( 0.0 )\n",
        "    weights.append(wrow)\n",
        "weights = np.matrix( weights )\n",
        "\n",
        "\n",
        "SigmoidNAGQG_result_prec_train = []\n",
        "SigmoidNAGQG_result_loss_train = []\n",
        "z = np.dot(X, weights.T).reshape(-1,len(set(ytrain+ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =   np.sum( np.log( np.absolute(probs -1 + Y) )  ) \n",
        "SigmoidNAGQG_result_loss_train.append( loss )\n",
        "SigmoidNAGQG_result_prec_train.append( precision(np.argmax(probs, axis=1) ,ytrain) )\n",
        "\n",
        "SigmoidNAGQG_result_prec_test = []\n",
        "SigmoidNAGQG_result_loss_test = []\n",
        "z = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)))\n",
        "probs =  1.0 / ( 1.0 + np.exp(-z) ) \n",
        "loss =    np.sum( np.log( np.absolute(probs -1 + Ytest) )  )  \n",
        "SigmoidNAGQG_result_loss_test.append( loss )\n",
        "SigmoidNAGQG_result_prec_test.append( precision(np.argmax(probs, axis=1) ,ytest) )\n",
        "\n",
        "print('X := ')\n",
        "print(X)\n",
        "start_time = time.time()\n",
        "XTX = X.T.dot(X)\n",
        "print('XTX := ')\n",
        "print(XTX)\n",
        "#B = np.sum((XTX * .5), axis=0) + epsilon\n",
        "invBrow = 1.0 / ( epsilon +  .25 * np.sum(XTX, axis=0) )\n",
        "print('invBrow := ')\n",
        "print(invBrow)\n",
        "\n",
        "alpha0 = 0.01\n",
        "alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "start_time = time.time()\n",
        "for it in range(num_iter):\n",
        "\n",
        "    # np.dot(X, np.matrix(weights).T)  #.reshape(-1,len(self.classes))\n",
        "    z = np.dot(X, velocity.T).reshape(-1,len(set(ytest+ytrain)) ) \n",
        "    \n",
        "    #P = 1.0 / ( 1.0 + np.exp(-z) ) \n",
        "    P = hlambda(z)\n",
        "\n",
        "    \n",
        "    gradient = (Y - P).T.dot(X)\n",
        "  \n",
        "    MG = np.multiply(invBrow, gradient)  \n",
        "\n",
        "    eta = (1 - alpha0) / alpha1\n",
        "    gamma = 1.0/(it+1)/ X.shape[0]\n",
        "            \n",
        "    # should be 'plus', 'cause to compute the MLE\n",
        "    MtmpW = weights + (gamma + 1.0) * MG               \n",
        "    weights = (1.0-eta)*MtmpW + np.multiply(eta, velocity)\n",
        "    velocity = MtmpW\n",
        "\n",
        "    alpha0 = alpha1\n",
        "    alpha1 = (1. + sqrt(1. + 4.0 * alpha0 * alpha0)) / 2.0\n",
        "\n",
        "\n",
        "\n",
        "    zz = np.dot(X, weights.T).reshape(-1,len(set(ytest+ytrain)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Y) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytrain)\n",
        "    SigmoidNAGQG_result_loss_train.append( loss )\n",
        "    SigmoidNAGQG_result_prec_train.append( prec )\n",
        "    #print('SigmoidNAG with QG Training Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "    zz = np.dot(Xtest, weights.T).reshape(-1,len(set(ytest)) )\n",
        "    pp = 1.0 / ( 1.0 + np.exp(-zz) ) \n",
        "    loss =  np.sum( np.log( np.absolute(pp -1 + Ytest) )  )\n",
        "    prec = precision(np.argmax(pp, axis=1) ,ytest)\n",
        "    SigmoidNAGQG_result_loss_test.append( loss )\n",
        "    SigmoidNAGQG_result_prec_test.append( prec )\n",
        "    print('SigmoidNAG with QG Testing Accuray at {:3d} iterations is {:.12f} with loss: {:.12f}'.format(1+it, prec, loss) )\n",
        "\n",
        "\n",
        "EnAdagradTimeDiff = time.time() - start_time\n",
        "print(\"TotalEnAdagradTimeDiff = \"), print(EnAdagradTimeDiff)\n",
        "print(\"AveraEnAdagradTimeDiff = \"), print(EnAdagradTimeDiff/num_iter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "label = [  'NAG', 'SigmoidNAG', 'SigmoidNAGQG' ]\n",
        "plt.plot(range(len(NAG_result_prec_train)), NAG_result_prec_train, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_prec_train)), SigmoidNAG_result_prec_train, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_prec_train)), SigmoidNAGQG_result_prec_train, 'o-r')\n",
        "plt.title('train precision')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "#plt.savefig(\"prec_train_.pdf\")\n",
        "plt.close()\n",
        "plt.plot(range(len(NAG_result_prec_test)), NAG_result_prec_test, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_prec_test)), SigmoidNAG_result_prec_test, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_prec_test)), SigmoidNAGQG_result_prec_test, 'o-r')\n",
        "plt.title('test precision')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "#plt.savefig(\"prec_test_.pdf\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "plt.plot(range(len(NAG_result_loss_train)), NAG_result_loss_train, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_loss_train)), SigmoidNAG_result_loss_train, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_loss_train)), SigmoidNAGQG_result_loss_train, 'o-r')\n",
        "plt.title('train loss')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "plt.close()\n",
        "plt.plot(range(len(NAG_result_loss_test)), NAG_result_loss_test, 'v-b')\n",
        "plt.plot(range(len(SigmoidNAG_result_loss_test)), SigmoidNAG_result_loss_test, 'v-g')\n",
        "plt.plot(range(len(SigmoidNAGQG_result_loss_test)), SigmoidNAGQG_result_loss_test, 'o-r')\n",
        "plt.title('test loss')\n",
        "plt.legend(label, loc = 0, ncol = 1)  \n",
        "plt.grid()\n",
        "plt.show()\n",
        "#plt.savefig(\"loss_test_.pdf\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "\n",
        "# -------------- FILE: LOSS training -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_LOSS_training_CIFAR10.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_loss_train):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_loss_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_loss_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_loss_train[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "# -------------- FILE: LOSS testing -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_LOSS_testing_CIFAR10.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_loss_test):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_loss_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_loss_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_loss_test[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "\n",
        "# -------------- FILE: PREC training -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_PREC_training_CIFAR10.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_prec_train):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_prec_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_prec_train[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_prec_train[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "# -------------- FILE: PREC testing -------------- \n",
        "filePath = \"PythonExperiment_NAGvs.SigmoidNAGvs.SigmoidNAGQG_PREC_testing_CIFAR10.csv\";\n",
        "PythonExperiment =      open(filePath,      'w')\n",
        "PythonExperiment =      open(filePath,      'a+b')\n",
        "\n",
        "PythonExperiment.write(\"Iter\".encode()); \n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('RawNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAG'.encode());\n",
        "PythonExperiment.write(','.encode());\n",
        "PythonExperiment.write('SigmoidNAGQG'.encode());   \n",
        "PythonExperiment.write(\"\\n\".encode());\n",
        "\n",
        "for (idx, ele) in enumerate(NAG_result_prec_test):\n",
        "    PythonExperiment.write(str(idx).encode()); \n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(NAG_result_prec_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAG_result_prec_test[idx]).encode());\n",
        "    PythonExperiment.write(','.encode());\n",
        "    PythonExperiment.write(str(SigmoidNAGQG_result_prec_test[idx]).encode());\n",
        "    PythonExperiment.write(\"\\n\".encode());\n",
        "PythonExperiment.close();\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}