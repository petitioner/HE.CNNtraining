# -*- coding: utf-8 -*-
"""My_CNNtrainingHEtransferlearningPyTorch_2023Mar18CIFAR10_RawData.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1elPd0_7ILs9mogi1rYr_jE8RnLBP-K-b
"""

import csv
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import models, datasets
import torchvision.transforms as trnsfrms
from torchvision.transforms import ToTensor, Resize, Lambda

#trnsfrms = trnsfrms.Compose([Resize(224), ToTensor(),  Lambda(lambda x: x.repeat(3, 1, 1) ) ])  # Grayscale Images like MNIST and USPS
#trnsfrms = trnsfrms.Compose([Resize(224), ToTensor(), ])                                       # Color Images like CIFAR10
trnsfrms = trnsfrms.Compose([ ToTensor(), ]) 

# Download training data from open datasets.FashionMNIST.MNIST.USPS  / CIFAR10
training_data = datasets.CIFAR10(
    root="data",
    train=True,
    download=True,
    transform= trnsfrms
)

# Download test data from open datasets.FashionMNIST.MNIST
testing_data = datasets.CIFAR10(
    root="data",
    train=False,
    download=True,
    transform= trnsfrms
)

batch_size = 512

# Create data loaders.
train_dataloader = DataLoader(training_data, batch_size=batch_size)
test_dataloader = DataLoader(testing_data, batch_size=batch_size)

# Get cpu or gpu device for training.
device = "cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu"
print(f"Using {device} device")

# Save the raw dataset: USPS MNIST CIFAR10
test_dataset = []
for X, y in test_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    X, y = X.to(device), y.to(device)
    X = torch.reshape(X, (X.shape[0], -1) )
    y = torch.reshape(y, (y.shape[0], -1) )
    print(f"Shape of X: {X.shape} {X.dtype}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    
    test_dataset += torch.cat( (y, X ), 1)
    print(f"Shape of test_dataset: {len(test_dataset)}, {len(test_dataset[0])}")

print("test_dataset :" + str(len(test_dataset)) + ",\t" + str(len(test_dataset[0])) )
print(type(test_dataset))
with open('Original_CIFAR10_testdata.csv', 'w') as csvfile:
    writer = csv.writer(csvfile)
    for i in range(len(test_dataset)):
      writer.writerow(test_dataset[i].detach().cpu().numpy())
csvfile.close()

train_dataset = []
for X, y in train_dataloader:
    print(f"Shape of X [N, C, H, W]: {X.shape}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    X, y = X.to(device), y.to(device)
    X = torch.reshape(X, (X.shape[0], -1) )
    y = torch.reshape(y, (y.shape[0], -1) )
    print(f"Shape of X: {X.shape} {X.dtype}")
    print(f"Shape of y: {y.shape} {y.dtype}")
    
    train_dataset += torch.cat( (y, X ), 1)
    print(f"Shape of train_dataset: {len(train_dataset)}, {len(train_dataset[0])}")

print("train_dataset :" + str(len(train_dataset)) + ",\t" + str(len(train_dataset[0])) )
print(type(train_dataset))
with open('Original_CIFAR10_traindata.csv', 'w') as csvfile:
    writer = csv.writer(csvfile)
    for i in range(len(train_dataset)):
      writer.writerow(train_dataset[i].detach().cpu().numpy())
csvfile.close()